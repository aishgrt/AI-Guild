
	/host:CPUP"܂8"8" "8"禍8"࡞8"ɱ"*"	*"ζ	6"	"ܞ	"	"	"ܮ	"ܯ	"	"	"	"	"Ě	"	"	"	"	"	"	"	"	"ন	"௢	"ผ	"	"	"ཻ	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"ࡾ	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"	"
"
"
"ɉ
"쏅
"
"
"ע
"
"ӊ
"͋
"Ԍ
"
"
"
"
"
"
"
"
"
"↗
"
"
"ڟ
"ʛ
"ʜ
"߾
"踞
"
"
"
"
"ࢡ
"
"
"
"Ƨ
"ƨ
"ͩ
"ͪ
"
"
"Մ
"
"
"
"ȑ
"ߑ
"
"
"
"
"ۘ
"䒹
"
"
"
"
"ƍ
"χ
"
"
"
"
"
"̿
"
"
"
"
"
"ĺ
"ں
$"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"""׫""Ą$"Ѕ""""""""""Ɛ"ґ"ߒ"ӓ"Ӕ"ٕ"ٖ"ӗ"""""""""""ۢ"ܣ"֤"ʥ""""""࿠"֠"ߚ"蔮"""š""༉""܃"""""˄"ᄻ"""Ⱦ"¿"ȼ"""""""ɱ""""""""""""๧"ݭ""Ǐ"Ã""""ඐ"ږ"""ĩ""0""""""""""ݱ"""""̲"լ"ަ"""""""""׃"""ܢ"ז"ӊ"銁""""ڄ"˅""""""Ջ"ό"ɍ"Ď""ҙ"虑"և"""""ݖ"˗"ӿ"ϳ"ح"""""""""""ڤ"""""""6""""""""ˍ"ԇ""""""""޼"̽"޾"ؿ""""""""""ƣ""""""ˤ""В""Հ""""""""""""""""""""""""""""""$""""""""""""""""""""޳"̡"⡅""੮"ನ"໢"""Ɋ"ߊ"""""ڑ"""""""݆""""""""""""ޤ"إ"ަ"ҧ"̨"""""ꮭ""""""""̋"Յ"""""""""""""""""""Ĩ"͢"֜"ߖ"""""""""""""""ط6"""ਾ""""ڬ"""""""""""""""˄"""""""""""Հ"Ɂ"ɂ"Ã""ࡁ"Ň"""""""""""""ߓ"""ٖ"ٗ"͘""ǚ"ԛ""Ν""0ω8"  "*EagerKernelExecute 0"9" ٢" "٢"  "8"8"ɿ8"ٚ8g"웛8مg"8"
ٌ8"8"इ8"˲8["8"  "8ـ"  " "٨8"篜8F"ꍻ8"ʻ8"8*"8ݽ"  "Ü8U"  " "ڭ8"ܛ8"஌8Ջ "ǝ8"՝8C"8"Փ8"8*"8"ã8"Ę80"8ǣ"⃚8"嚞8"߻86"ͩ8"  "અ8"  " "8"ß8="íğ8"ӟ8	"8C"8g"8="8"،8൳"8"8"80"睠8"  "8"  " T|
tf_Compute">" ٢"  " "٢"  "=" ٢"  " "٢"  "ܷ"  "  ">čඕX" ٢"  " "٢"  "擎X"  "  "=o" ٢"  " "٢"  "o"  "  "=o" ٢"  " "٢"  "oU"  "  "=oๆ" ٢"  " "٢"  "om"  "  "=ϳo" ٢"  " "٢"  "o؞"  "  "?൓oٷ" ٢"  " "٢"  "̓o"  "  ">Қ" ٢"  " "٢"  "	"  "  ">ࢴ" ٢"  " "٢"  "
"  "  ">" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "a"  "  ">" ٢"  " "٢"  "m"  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "g"  "  ">Ͱ	" ٢"  " "٢"  "U"  "  ""  "  "@" ٢"  " "٢"  "ƾM"  "  "ʱ۝"  "  "?" ٢"  " "٢"  ""  "  "҈"  "  "?" ٢"  " "٢"  "Ƥ"  "  "ǉ"  "  "?߿*" ٢"  " "٢"  ")"  "  "'"  "  "?" ٢"  " "٢"  ""  "  "҇"  "  "Ջ"  "  "̕"  "  "b"  "  "?g" ٢"  " "٢"  " @"  "  "!"  "  "?Z" ٢"  " "٢"  ""C"  "  "#ߘധ"  "  "?" ٢"  " "٢"  "$"  "  "%矯"  "  "?" ٢"  " "٢"  "&¿"  "  "'V"  "  "?ߺ" ٢"  " "٢"  "(͎_"  "  ")θs"  "  "?Ӓ" ٢"  " "٢"  "*	"  "  "?" ٢"  " "٢"  "+"  "  "?渲" ٢"  " "٢"  ",κు"  "  "-ց"  "  ".ƪۛ"  "  "?傿8" ٢"  " "٢"  "/Ǜ3"  "  "0"  "  "1ʥF"  "  "2"  "  "3ȽG"  "  "4޾"  "  "5"  "  "6ꆁ"  "  "7"  "  "8Ƥɲ"  "  ">F" ٢"  " "٢"  "91"  "  ":ܥ"  "  "?ۖ" ٢"  " "٢"  ";Ņ"  "  "<Ą"  "  "?˙ Ň&" ٢"  " "٢"  "=Ƌ "  "  "> "  "  "? " ٢"  " "٢"  "?ĺ "  "  "@ <"  "  "A ȫ"  "  "B ˽"  "  "C ǣ"  "  "? " ٢"  " "٢"  "D "  "  "Eֶ "  "  "F "  "  "? N" ٢"  " "٢"  "G 3"  "  "H!"  "  "?!i" ٢"  " "٢"  "I!"  "  "J!ᔧ"  "  "K̡!୼"  "  "L̈!"  "  "M!"  "  "N!"  "  "O!ҙ<"  "  "PǨ"w"  "  "Q"Ř"  "  "?˽#*" ٢"  " "٢"  "Rͽ#"  "  "S#"  "  "?#r" ٢"  " "٢"  "T#̓"  "  "U#'"  "  "V#J"  "  "W#ݻ"  "  "XѨ#H"  "  "Y#S"  "  "Z$"  "  "?е$ٽU" ٢"  " "٢"  "[$A"  "  "\%h"  "  "]ٱ%΄"  "  "^%"  "  "?ݏ%" ٢"  " "٢"  "_ב%^"  "  "`%"  "  "a%"  "  "b%֞$"  "  "?ߣ%Ƨ," ٢"  " "٢"  "c%Я"  "  "d%"  "  "e%"  "  "f%Ǧ"  "  "g%"  "  "h%δ\"  "  "i%)"  "  "jۜ%ֈU"  "  "k%櫓"  "  "l˶%,"  "  "m%"  "  "nڢ%"  "  "?ڂ&" ٢"  " "٢"  "oŠ܂&"  "  "pК&r"  "  "?&" ٢"  " "٢"  "q&"  "  "r&"  "  "?ğ&" ٢"  " "٢"  "s&Ӣ"  "  "?&" ٢"  " "٢"  "t&"  "  "u'M"  "  "?'" ٢"  " "٢"  "v'"  "  "w'"  "  "?)+" ٢"  " "٢"  "x)գ "  "  "yԵ*"  "  "?*" ٢"  " "٢"  "zۥ*"  "  "{ӡ* "  "  "?Ξ+ʪ" ٢"  " "٢"  "|+"  "  "?+¯" ٢"  " "٢"  "}+"  "  "~ʽ+"  "  "ϖ,ঃ"  "  "?튇,آ" ٢"  " "٢"  "Ð,"  "  ","  "  "?ఴ̡,^" ٢"  " "٢"  "Ρ,"  "  "Ѳ,"  "  "Վ,:"  "  "ຑѺ,-"  "  "Й,."  "  "Ӵ,,"  "  ","  "  ","  "  ","  "  ","  "  ",&"  "  ","  "  ","  "  "?ח," ٢"  " "٢"  ",夽"  "  "-R"  "  "-"  "  "ဈ-6"  "  "-"  "  "-ò"  "  "ޡ-"  "  "ϊ-H"  "  "?-/" ٢"  " "٢"  "-Ү"  "  "ߠ-ݢ."  "  "?-ӵs" ٢"  " "٢"  "-"  "  "֚-"  "  "-"  "  "-٤"  "  "-ح"  "  "-ଗ"  "  ".>"  "  ".S"  "  "."  "  "?ر/ꥴ" ٢"  " "٢"  "봵/"  "  "ɯ/"  "  "?1ڙ" ٢"  " "٢"  "²1˽"  "  "?ܜ1ǚ" ٢"  " "٢"  "1"  "  "Ŀ1"  "  "1"  "  "ӳ1\"  "  "1"  "  "1y"  "  "1"  "  "Լ1:"  "  "?1穩" ٢"  " "٢"  "1"  "  "1"  "  "?1ڕ2" ٢"  " "٢"  "1"  "  "۩1"  "  "1s"  "  "1"  "  "1ɛ"  "  "1݄"  "  "10"  "  "1T"  "  "1"  "  "1"  "  "1"  "  "?џ2" ٢"  " "٢"  "߇2ͽ"  "  "?ŵ2" ٢"  " "٢"  "󠷟2ক"  "  "2"  "  "Ϥ2"  "  "?ܩ2R" ٢"  " "٢"  "ީ25"  "  "2"  "  "?닗3ˎ*" ٢"  " "٢"  "ٍ3)"  "  "Ӑ3*"  "  "?3" ٢"  " "٢"  "ͨ3"  "  "3"  "  "?4*" ٢"  " "٢"  "4"  "  "4֓
"  "  "?ณ4Ť" ٢"  " "٢"  "4"  "  "?4" ٢"  " "٢"  "4I"  "  "4["  "  "4"  "  "4"  "  "?4" ٢"  " "٢"  "4"  "  "ݸ4<"  "  "4"  "  "պ4Í"  "  "4"  "  "߼4>"  "  "?В5ː" ٢"  " "٢"  "ৠ5ЇO"  "  "5"  "  "ų5"  "  @
tf_Compute">b" ٢"  " "٢"  "٤ջH"  "  "]Ň"  "  "m"  "  "t"  "  ">Ϭwz" ٢"  " "٢"  "w٧'"  "  "$"  "  "Բ"  "  "̍*"  "  "?ݜ7" ٢"  " "٢"  "Ϟń0"  "  "쁣"  "  "ξ費"  "  ""  "  "?׻" ٢"  " "٢"  "޼"  "  "d"  "  "޾P"  "  "ڙ"  "  "? " ٢"  " "٢"  ""  "  ""  "  "ں˻a"  "  ""  "  ">" "  " "" "	" "  ">" "  " "" "" "  "9" " "" ">" ٢"  " "٢"  ""  "  "?헷 끉-" ٢"  " "٢"  "Θ &"  "  "ֽ "  "  "?ɽ " ٢"  " "٢"  "೟ ɧ"  "  "ى ϊ"  "  "?Չ"" ٢"  " "٢"  "ۋ""  "  ""ࡃY"  "  """  "  """  "  """  "  "?"" ٢"  " "٢"  "͂""  "  ""J"  "  ""L"  "  "?"Q" ٢"  " "٢"  ""D"  "  "؀""  "  ""ԛ|"  "  """  "  ""7"  "  """  "  "Κ""  "  "念""  "  ""૞"  "  "Ͷ"#"  "  "?Ч#꣤" ٢"  " "٢"  "ҧ#"  "  "ܜ#"  "  "?#	" ٢"  " "٢"  "#	"  "  "?̛#" ٢"  " "٢"  "Ɲ#["  "  "Ʋ#_"  "  "䳅#־"  "  "#P"  "  "?#೤" ٢"  " "٢"  "#"  "  "ެ#V"  "  "#"  "  "#"  "  "⵸#"  "  "#w"  "  "?#Ȇd" ٢"  " "٢"  "ޥ#T"  "  "$ۇ"  "  "?$?" ٢"  " "٢"  "ǡ$7"  "  "㑭%"  "  "?淒%̔" ٢"  " "٢"  "̍%"  "  "?݂& " ٢"  " "٢"  "&"  "  "煞&Ŋ"  "  "@&숔" ٢"  " "٢"  "𔶩&R"  "  "'"  "  "?ړ(Օh" ٢"  " "٢"  "(C"  "  "(̖"  "  "?)" ٢"  " "٢"  "୔)"  "  "ٜ)7"  "  "?)" ٢"  " "٢"  ")ඹ"  "  ")"  "  "?)" ٢"  " "٢"  ")Ӯ"  "  "*"  "  "?*" ٢"  " "٢"  "Ϙ*ֹ"  "  "ˣ*˼"  "  "*g"  "  "ڧ*"  "  "*"  "  "?*R" ٢"  " "٢"  "*D"  "  "Ȯ*>"  "  "ป*ڔT"  "  "ʱ*௥"  "  "*2"  "  "*↵B"  "  "*
"  "  "?¢+རZ" ٢"  " "٢"  "จĢ+B"  "  "+"  "  "?崀,C" ٢"  " "٢"  "뷀,ӹy"  "  "ĳ,!"  "  ",9"  "  "΃,"  "  "Յ,K"  "  ",߆"  "  "Ұ,"  "  "෦¡,"  "  ","  "  ","  "  "?,÷" ٢"  " "٢"  ","  "  ","  "  "?." ٢"  " "٢"  "."  "  "."  "  ".B"  "  ".Ѓ"  "  "ľ./"  "  "?.=" ٢"  " "٢"  "΋.΂	"  "  ".s"  "  "۹.l"  "  "."  "  ".Ѵ9"  "  "Ǔ."  "  "."  "  "쾠."  "  "Œ/"  "  "/"  "  "?ѯ/8" ٢"  " "٢"  "/"  "  "/"  "  "/"  "  "/"  "  "ﯸ/"  "  "?/" ٢"  " "٢"  "/"  "  "/b"  "  "٦/1"  "  "?/[" ٢"  " "٢"  "/Ͽ2"  "  "ԡ/ռ!"  "  "/C"  "  "ൗ/ؑ"  "  "/ş)"  "  "/M"  "  "۔0"  "  "?06" ٢"  " "٢"  "0׮6"  "  "1 "  "  "?1" ٢"  " "٢"  "Ў1"  "  "1!"  "  "?1(" ٢"  " "٢"  "1¬"  "  "̚1"  "  "?2
" ٢"  " "٢"  "׬2"  "  "2h"  "  "ݛ2"  "  "郞2"  "  "à2>"  "  "?2W" ٢"  " "٢"  "2:"  "  "2"  "  "ԥ2ண?"  "  "ݝ2®"  "  "̑Ϩ2,"  "  "ک2D"  "  "پ2"  "  "?؟3W" ٢"  " "٢"  "39"  "  "Ð3"  "  "?ɢ4" ٢"  " "٢"  "ˢ4"  "  "ׅ4"  "  "?4'" ٢"  " "٢"  "4'"  "  "?4
" ٢"  " "٢"  "ݣ4େ"  "  "4"  "  "4§z"  "  "4˼"  "  "﹎4e"  "  "4"  "  "@4" ٢"  " "٢"  "ʀ4ૌG"  "  "򱵀5 "  "  "5@"  "  "5|"  "  "5ঢ\"  "  "5("  "  "5("  "  "Ο5{"  "  "ũ6"  "  "ģ6"  "  "6Ӡ"  "  "6۵z"  "  "ڴ8"  "  "9࢓8$" ٢" "٢"  vU
tf_Compute"?" ٢"  " "٢"  "ܖH"  "  "]"  "  "l͔5"  "  "ћ"  "  "?֥" ٢"  " "٢"  "ೌ٥ǜ"  "  "ԝ"  "  "ཇͪ"  "  ""  "  "?|" ٢"  " "٢"  "H"  "  "«偒"  "  "ݣ"  "  "ܔΡ"  "  "?$" ٢"  " "٢"  "ြ"  "  "ɛ"  "  "g"  "  "ŧ"  "  "?" ٢"  " "٢"  ""  "  "׶"  "  "I"  "  ""  "  "բ#"  "  "?R" ٢"  " "٢"  "˚A"  "  ""  "  "຿B"  "  ""  "  "1"  "  "B"  "  "๽ɿ	"  "  "?ڢI" ٢"  " "٢"  "7"  "  "ߚ"  "  "?Œ" ٢"  " "٢"  "ō"  "  "?Ѧ" ٢"  " "٢"  "Ȏ"  "  "a"  "  ""  "  "S"  "  ""  "  "ӣ"  "  "Ż"  "  "P"  "  "?" ٢"  " "٢"  ""  "  "쁆5"  "  "?S" ٢"  " "٢"  ""  "  ""  "  ""  "  "୪!"  "  "ʌ7"  "  ""  "  "߂ٟM"  "  "2"  "  "¿"  "  "Ӌ"  "  "Ѵ-"  "  "?ڝ" ٢"  " "٢"  ""  "  "ȿ@"  "  "?`" ٢"  " "٢"  ""  "  "<"  "  "Ř"  "  ""  "  ""  "  "୳"  "  ""  "  "H"  "  "&"  "  "Z"  "  "⸗"  "  "="  "  "E"  "  ""  "  "?	" ٢"  " "٢"  ""  "  ""  "  "?" ٢"  " "٢"  "ʸ"  "  "ژ"  "  "f"  "  "ءĸ"  "  "ʋ"  "  "?:" ٢"  " "٢"  "絮6"  "  "*"  "  "J"  "  "Ƛ"  "  "ܲӞG"  "  "瘴ˡ"  "  "ѝ؟"  "  "ԗ"  "  ""  "  ""  "  "?$" ٢"  " "٢"  ""  "  "
"  "  "?܈" ٢"  " "٢"  ""  "  "ߣ"  "  "䑦H"  "  "˿"  "  "ިٗ"  "  "?" ٢"  " "٢"  "腦"  "  ""  "  "1"  "  "?Ƞ໋Q" ٢"  " "٢"  "5"  "  "כ"  "  "?O" ٢"  " "٢"  "3"  "  ""  "  "?ோ" ٢"  " "٢"  "ĝ㜲"  "  ""  "  "?3" ٢"  " "٢"  "С5"  "  "ݣ"  "  "ޅ="  "  "߷"  "  "0"  "  "ڵ"  "  "ӹא"  "  ""  "  "ދ"  "  ""  "  "?ӵϡ-" ٢"  " "٢"  "Ե"  "  ""  "  "?
" ٢"  " "٢"  ""  "  "<"  "  ""  "  "@"  "  ""  "  ""  "  ""  "  "޵>"  "  "?܃b" ٢"  " "٢"  "<"  "  "߼Ɵ"  "  "?࿕" ٢"  " "٢"  ""  "  "ŮD"  "  "?" ٢"  " "٢"  ""  "  ""  "  "?௩/" ٢"  " "٢"  "ު""  "  ""  "  "?̬" ٢"  " "٢"  "Ϭ"  "  "y"  "  "Ĺ+"  "  "?ȧȲa" ٢"  " "٢"  ":"  "  ""  "  "?Ѣ" ٢"  " "٢"  "ɻò"  "  "đߣ"  "  "?ӊ" ٢"  " "٢"  "Ť"  "  "ʳm"  "  "?" ٢"  " "٢"  "՜"  "  "ȋ"  "  ""  "  "?ł " ٢"  " "٢"  "Ƃ "  "  " ͦ"  "  "?̛ D" ٢"  " "٢"  "ࡳϛ "  "  " "  "  "̠ "  "  "  "  "  " ѱn"  "  " '"  "  " "  "  " "  "  "΢ "  "  "ߨ ܟ"  "  " $"  "  "? ߴ" ٢"  " "٢"  "䫻 "  "  "?֫ \" ٢"  " "٢"  " 5"  "  " "  "  "ȱ :"  "  " "  "  "К :"  "  "ٽ N"  "  "!"  "  "?঱!Q" ٢"  " "٢"  "؟!<"  "  "ѣ""  "  "?"" ٢"  " "٢"  ""੣"  "  """  "  "?Ͽ"Ә" ٢"  " "٢"  "ŀ""  "  "Ը#"  "  "?ѧ#ӯ@" ٢"  " "٢"  "ا#1"  "  "#಍
"  "  "?淒%" ٢"  " "٢"  "Е%"  "  "?%>" ٢"  " "٢"  "ݞ%"  "  "%"  "  "%"  "  "%"  "  "ق&؜"  "  "?&A" ٢"  " "٢"  "&"  "  "&"  "  "&5"  "  "?&" ٢"  " "٢"  "ྑ&"  "  "࠹&7"  "  "?&" ٢"  " "٢"  "&༕"  "  "&l"  "  "&޸"  "  "&ﺀ"  "  "ȝ&"  "  "㋾&"  "  "&"  "  "&"  "  "?걁'w" ٢"  " "٢"  "ލ'="  "  "',"  "  "@(" ٢"  " "٢"  "͈("  "  "("  "  "߷(؞"  "  "Þ("  "  "Ԣ("  "  "֤(զ"  "  "ـ(["  "  "ʘ)o"  "  "懈)"  "  "?ݜ)ó" ٢"  " "٢"  "ޜ)"  "  "ԕ)"  "  ")"  "  "ĊΤ);"  "  "ȥ)"  "  "ʥ)"  "  "ǉ)Ϩ"  "  "꣧)D"  "  "?)
" ٢"  " "٢"  ")"  "  ")"  "  "?)։O" ٢"  " "٢"  ")	"  "  ")"  "  "ഠ)J"  "  "͞)>"  "  ")7"  "  "Ҡ)R"  "  ")"  "  ")R"  "  "Ź)"  "  ")ѯ"  "  ")#"  "  "?*" ٢"  " "٢"  "ۼ*鞄"  "  "?թ*" ٢"  " "٢"  "*"  "  "*"  "  "ܶ*"  "  "?㥚*֤'" ٢"  " "٢"  "ޢ*&"  "  "*A"  "  "?*r" ٢"  " "٢"  "*"  "  "ˎ+"  "  "+"  "  "ݕ+"  "  "+"  "  "ƙ+"  "  "ţ+>"  "  "д+^"  "  "+"  "  "?+؞" ٢"  " "٢"  "+ַ"  "  "+l"  "  "+σ"  "  "מ+\"  "  "˟+"  "  "+"  "  "+/"  "  "૏,༦t"  "  "?쇇," ٢"  " "٢"  ","  "  "œ,ŋ"  "  "?ƃ," ٢"  " "٢"  "ӂ,"  "  ",:"  "  "?,=" ٢"  " "٢"  ",ԃ	"  "  "͊,"  "  "ך,"  "  "?œ," ٢"  " "٢"  ","  "  "?Ș-" ٢"  " "٢"  "-"  "  "҆-c"  "  "-2"  "  "?Ҋ-O" ٢"  " "٢"  "Ԋ-P"  "  "-"  "  "-H"  "  "Ǎ-"  "  "ޙ--"  "  "-່@"  "  "-"  "  "?噁.c" ٢"  " "٢"  ".G"  "  ".͡"  "  "?ࡵ." ٢"  " "٢"  "."  "  "܃.H"  "  "?Ĩ.=" ٢"  " "٢"  "."  "  "/"  "  "蟐/У	"  "  "ә/m"  "  "ݮÚ/0"  "  "/9"  "  "/"  "  "ț/?"  "  "߻/"  "  "ɢ/"  "  "/Ð"  "  "?Ը/" ٢"  " "٢"  "Յ/"  "  "?1" ٢"  " "٢"  "ത1"  "  "1"  "  "1"  "  "1"  "  "萩1$"  "  "?1" ٢"  " "٢"  "ި1"  "  "ׂ1ګo"  "  "Ǯ1"  "  "?।17" ٢"  " "٢"  "ߪ1;"  "  "1"  "  "࠭1ǍN"  "  "1"  "  "15"  "  "1"  "  "᭝1"  "  "1"  "  "1"  "  "1"  "  "?1Ĕ#" ٢"  " "٢"  "Ϊ1ప"  "  "1"  "  "?੍2ӻ" ٢"  " "٢"  "஬2"  "  "ݢ2"  "  "?2	" ٢"  " "٢"  "2"  "  "ϐ2D"  "  "2֝"  "  "ˈ2="  "  "ݹ2"  "  "湼2"  "  "ƒ2"  "  "̲27"  "  "?ک2" ٢"  " "٢"  "۩2"  "  "2"  "  "?2w" ٢"  " "٢"  "2"  "  "2"  "  "3"  "  "3ڙ"  "  "ǃȋ3틺"  "  "3"  "  "3C"  "  "3p"  "  "3"  "  "?38" ٢"  " "٢"  "3="  "  "3"  "  "3C"  "  "푩3ָ"  "  "3?"  "  "4"  "  "Ț4"  "  "͜4"  "  "̠4Ē"  "  "濢4ԟ"  "  "4>"  "  "?ܪ4." ٢"  " "٢"  "ɤ4&"  "  "4"  "  "?4ʻ" ٢"  " "٢"  "4Î"  "  "@5" ٢"  " "٢"  "ƹ5%"  "  "5๥K"  "  "5w"  "  "5"  "  '
tf_Compute">ƍb" ٢"  " "٢"  "ЗI"  "  "ق^"  "  "nݵ"  "  "s"  "  ">Ͻvb" ٢"  " "٢"  "ϟv֭("  "  "ř遼#"  "  "ƺ	"  "  ""  "  "?L" ٢"  " "٢"  "<"  "  "Ȗ"  "  "ض
"  "  "Ͱ"  "  "?" ٢"  " "٢"  "ſ"  "  "M"  "  "ޅ͎T"  "  "۸"  "  "?簘ݳ" ٢"  " "٢"  ""  "  ""  "  "֍֛Y"  "  "ъ"  "  "?)" ٢"  " "٢"  ""  "  "	"  "  ""  "  ""  "  "?ڑ`" ٢"  " "٢"  "-"  "  "ி"  "  "ߊ"  "  ""  "  ""  "  ""  "  ""  "  ""  "  ""  "  ""  "  "="  "  "ڮ:"  "  "ЬI"  "  "`"  "  "ಇ"  "  "D"  "  "̬"  "  "m"  "  ""  "  ""  "  "?F" ٢"  " "٢"  "ڬ"  "  "ҷ"  "  "Ԛ"  "  "ͱΪ"  "  ""  "  "ድ"  "  ""  "  "Я"  "  "!"  "  "h"  "  "8"  "  "M"  "  "J"  "  "ð"  "  "A"  "  "砨ๆ"  "  "z"  "  "Ƭ"  "  "དྷ"  "  "?˱A" ٢"  " "٢"  ""  "  ""  "  "ǝ"  "  "Ӽۓन"  "  "Ѓǘ""  "  ""  "  "۹"  "  "䃘"  "  "ŗ"  "  "	"  "  "C"  "  "ө6"  "  "ݪ-"  "  "ڥN"  "  "߼"  "  "8"  "  ""  "  "g"  "  "񽰮"  "  "ླ"  "  "?>" ٢"  " "٢"  ""  "  ""  "  ""  "  "O"  "  "ղ"  "  ""  "  ""  "  "ׅД"  "  "ĕ"  "  "Ɖ،I"  "  "Օ8"  "  "ྏ6"  "  "夗6"  "  "ݗ"  "  "గৱI"  "  "ө"  "  "Ɋa"  "  "͓"  "  ""  "  "?ڷ՟׸" ٢"  " "٢"  "ן"  "  "򰩸"  "  "޹ӱ"  "  "?׀=" ٢"  " "٢"  ""  "  ""  "  "ێ"  "  "Ԩ"  "  "മ"  "  "≫օ"  "  "̶"  "  "ʥʠ"  "  "ʏ"  "  "ರ̋
"  "  "☼I"  "  "3"  "  "Ά2"  "  "4"  "  "ௗ"  "  "ΦJ"  "  "Ɓ"  "  "ȁs"  "  "ʁ"  "  ""  "  "?B" ٢"  " "٢"  "ク"  "  "ڞ"  "  "ɦ"  "  "䫳o"  "  ""  "  "̜"  "  "π"  "  "܌"  "  """  "  "ߤ"  "  "?"  "  ")"  "  "D"  "  "า"  "  "@"  "  "ఌ"  "  "["  "  "{"  "  ""  "  "?ൂ" ٢"  " "٢"  ""  "  "ٍ	"  "  "	"  "  "?	2" ٢"  " "٢"  "	朏"  "  "	D"  "  "	4"  "  "􊢲	੆#"  "  "	"  "  "	"  "  "͏	½"  "  "?Ǚ
$" ٢"  " "٢"  "
ڸ"  "  "
_"  "  "
="  "  "
"  "  "
"  "  "
"  "  "?
2" ٢"  " "٢"  "
"  "  "
Ӛ0"  "  "臽
""  "  "ʣ
ܡ$"  "  "΁"  "  "ƃ"  "  "Ǿ"  "  "?ˤ)" ٢"  " "٢"  "֡꓋"  "  "k"  "  "W"  "  ""  "  ""  "  "Ԃ"  "  "?Α4" ٢"  " "٢"  "Б"  "  "3"  "  "<"  "  "%"  "  "˺"  "  "ԃ"  "  ""  "  "?ׁɤ"" ٢"  " "٢"  ""  "  "ރ5"  "  "ʔ)"  "  ""  "  "ى"  "  ""  "  "?̸8" ٢"  " "٢"  ""  "  "+"  "  "*"  "  "#"  "  "؃"  "  "Ŧ"  "  ""  "  "?"" ٢"  " "٢"  ""  "  "ѫ9"  "  "݋0"  "  ""  "  "z"  "  ""  "  "?ᢢ<" ٢"  " "٢"  "ؿҩ"  "  ""  "  "À"  "  ""  "  ""  "  "Ί"  "  "("  "  ""  "  ""  "  "
"  "  "@"  "  "0"  "  "%"  "  "ԏ:"  "  "ِ"  "  ":"  "  "Ғ"  "  "Ӓ["  "  "Ԓǧ"  "  ""  "  "?ݡᾠ=" ٢"  " "٢"  ""  "  ""  "  ""  "  "N"  "  ""  "  ""  "  "В"  "  "ߴ"  "  "߮!"  "  "E"  "  "ѐ5"  "  "*"  "  "癹4"  "  ""  "  "ΰE"  "  ""  "  "a"  "  "~"  "  "ഏ"  "  "?A" ٢"  " "٢"  "Όڢ"  "  ""  "  "ѝ"  "  ""  "  "*"  "  "і"  "  ""  "  "ɨ൰"  "  ""  "  "α
"  "  "_"  "  "޼F"  "  "?"  "  "ł?"  "  ""  "  "m"  "  "ʾ"  "  "༊ξ"  "  "о"  "  "⣔"  "  "?Ʃ=" ٢"  " "٢"  "ߴ"  "  ""  "  "Ɯ"  "  "Ȉ"  "  ""  "  "ط"  "  "಄Ȉ"  "  ""  "  "ۅ"  "  "ДȤ9"  "  "ÄD"  "  "ʒ1"  "  "Ʀ3"  "  "ැ"  "  "͊="  "  ""  "  "a"  "  ""  "  ""  "  "?ۮB" ٢"  " "٢"  ""  "  "j"  "  ""  "  "͞"  "  ""  "  "ñ"  "  ""  "  ""  "  ""  "  "щ݅"  "  "ܑB"  "  "E"  "  "1"  "  "ۅD"  "  ""  "  "ࢰR"  "  ""  "  "ఌ"  "  "؝"  "  "܋"  "  "?ڠ=" ٢"  " "٢"  "ܠ"  "  ""  "  ""  "  "􊢪j"  "  ""  "  ""  "  "԰"  "  ""  "  ""  "  "ǽߕZ"  "  "A"  "  "0"  "  "֩<"  "  ""  "  "A"  "  ""  "  ""  "  ""  "  ""  "  "?	" ٢"  " "٢"  "Љ"  "  "ߗ"  "  "ԟ!"  "  ""  "  ""  "  "ڤ"  "  ""  "  ""  "  ""  "  ""  "  ""  "  "?×
" ٢"  " "٢"  ""  "  "E"  "  ""  "  "D"  "  ""  "  ""  "  ""  "  "Ɉ"  "  "?g" ٢"  " "٢"  ">"  "  "پ"  "  "?N" ٢"  " "٢"  "6"  "  "Ô"  "  "?å" ٢"  " "٢"  ""  "  ""  "  "?" ٢"  " "٢"  ""  "  ""  "  "?ь" ٢"  " "٢"  "ӂ"  "  ""  "  "?" ٢"  " "٢"  "͖"  "  ""  "  "?" ٢"  " "٢"  ""  "  "£c"  "  "Ҵ;"  "  "?:" ٢"  " "٢"  "ͭ"  "  "ܮ9"  "  "?ϵx" ٢"  " "٢"  "׵ö"  "  ""  "  "ޓ"  "  "̟"  "  "׏"  "  ""  "  ">"  "  "Զ˷J"  "  ""  "  "?
" ٢"  " "٢"  "瘯"  "  "U"  "  "״"  "  "ٶM"  "  ""  "  "٤"  "  "#"  "  "ż,"  "  "?ݾ" ٢"  " "٢"  "ɺ߾ڜ"  "  "P"  "  "?͜D" ٢"  " "٢"  "ת"  "  ""  "  ":"  "  "8"  "  ""  "  ":"  "  ""  "  "¢"  "  ""  "  ""  "  "ঐ "  "  "?" ٢"  " "٢"  ""  "  "? 8" ٢"  " "٢"  " "  "  "з !"  "  "?"" ٢"  " "٢"  """  "  ""
"  "  "?"қ+" ٢"  " "٢"  ""#"  "  "#ଊ"  "  "?#" ٢"  " "٢"  "֯#"  "  "ݤ#"  "  "#"  "  "?#ئ" ٢"  " "٢"  "#	"  "  "	#G"  "  "	#ɫ"  "  "	#ຽ"  "  "	#I"  "  "?#" ٢"  " "٢"  "	#"  "  "	ƌ$Ô"  "  "?Ȋ$ہ" ٢"  " "٢"  "	$"  "  "	$"  "  "	퍶$"  "  "	ʆ$"  "  "	$˥"  "  "	ٗ$Ӹ"  "  "	ק$ș;"  "  "	Ʊ%"  "  "?&3" ٢"  " "٢"  "	&Ѭ3"  "  "	&"  "  "?&ހA" ٢"  " "٢"  "	&"  "  "	&ๆ"  "  "	߱'"  "  "?݌)߂" ٢"  " "٢"  "	)ԥ"  "  "	ڜ)W"  "  "	)"  "  "	)ڝ"  "  "	)$"  "  "?֐)" ٢"  " "٢"  "	)޹"  "  "	)"  "  ">)໭V" ٢"  " "٢"  "	)0"  "  "	)"  "  "?)ۄ3" ٢"  " "٢"  "	)#"  "  "	*ї
"  "  "?ʣ*
" ٢"  " "٢"  "	̣*"  "  "	Ʀ*U"  "  "	*"  "  "	*ħW"  "  "	ۣ*؞"  "  "	*͏"  "  "	ۭ*"  "  "	*ࠊ;"  "  "?*[" ٢"  " "٢"  "	*?"  "  "	٢*פ"  "  "?䣢+<" ٢"  " "٢"  "	+"  "  "	揨+6"  "  "?+" ٢"  " "٢"  "	ۣ+"  "  "	+ɠ"  "  "	+"  "  "	ܞ+ղ"  "  "	+ĔS"  "  "?ѫ," ٢"  " "٢"  "	ۇԫ,"  "  "	м,Ȥ"  "  "?," ٢"  " "٢"  "	,"  "  "	ɮ,֎"  "  "?," ٢"  " "٢"  "	ͷ,ΰ"  "  "	,"  "  "?,բ" ٢"  " "٢"  "	ή,"  "  "	ۣ,"  "  "?,
" ٢"  " "٢"  "	濗,ǲ"  "  "	૦,"  "  "	-w"  "  "	૽-"  "  "	咝-"  "  "?-i" ٢"  " "٢"  "	-<"  "  "	ف-㷑 "  "  "?.;" ٢"  " "٢"  "	ଲ."  "  "	.6"  "  "?.Д" ٢"  " "٢"  "	."  "  "	."  "  "?." ٢"  " "٢"  "	.Ā"  "  "	.9"  "  "	."  "  "	ޢ.t"  "  "	."  "  "	."  "  "	.*"  "  "	.உ"  "  "?/" ٢"  " "٢"  "	/"  "  "	/"  "  "?/" ٢"  " "٢"  "	/"  "  "	ߪ/֞$"  "  ">/`" ٢"  " "٢"  "	ꃳ/C"  "  "	/"  "  "?ջ/ԁ	" ٢"  " "٢"  "	/"  "  "	/ϐ"  "  "	/^"  "  "	/"  "  "	ߧ/+"  "  "?Ǉ/ҮL" ٢"  " "٢"  "	/1"  "  "	ާ0"  "  "?𩲶0b" ٢"  " "٢"  "	Դ0"  "  "	0Ġ"  "  "	0"  "  "	0̝"  "  "	0"  "  "	0"  "  "	߲0ൠ="  "  "	ٍ˔1߳W"  "  "	ס1"  "  "?1" ٢"  " "٢"  "	1"  "  "	1"  "  "?1" ٢"  " "٢"  "	1G"  "  "	1"  "  |Q
tf_Compute"?" ٢"  " "٢"  "	H"  "  "	^"  "  "	n0"  "  "	ө"  "  "?8" ٢"  " "٢"  "	Ͼϲ!"  "  "	ࣔ"  "  "	"  "  "	ș"  "  "?:" ٢"  " "٢"  "	"  "  "	ۗ"  "  "		"  "  "	"  "  "?$" ٢"  " "٢"  "	"  "  "	ތ"  "  "	ਸ"  "  "	٠"  "  "?螻" ٢"  " "٢"  "	㡻ɪ"  "  "	ĕ"  "  "	]"  "  "	"  "  ">" ٢"  " "٢"  "	ఌ"  "  ">" ٢"  " "٢"  "	m"  "  ">" ٢"  " "٢"  "	["  "  ">˘" ٢"  " "٢"  "	I"  "  ">ǌ" ٢"  " "٢"  "	s"  "  ">" ٢"  " "٢"  "	a"  "  ">" ٢"  " "٢"  "	a"  "  ">" ٢"  " "٢"  "	؞"  "  ">ށ" ٢"  " "٢"  "
ۧs"  "  ">" ٢"  " "٢"  "
δ	"  "  "
Ԓ"  "  ">" ٢"  " "٢"  "
ಷg"  "  ">ܗ" ٢"  " "٢"  "
"  "  ">" ٢"  " "٢"  "
Ϛ"  "  "?0" ٢"  " "٢"  "
Ţ"  "  "
"  "  "
"  "  "
џ
"  "  "
ԩ"  "  "
۔"  "  "
˘"  "  "
"  "  "
"  "  "?@" ٢"  " "٢"  "
⧅"  "  "
ູ"  "  "
"  "  "
ປ"  "  "
֑ః/"  "  "
"  "  "
Ń"  "  "?E" ٢"  " "٢"  "
"  "  "
9"  "  "
韨%"  "  "
*"  "  "
Ӡӯ"  "  "
Ǣؠ"  "  "
ࣟ"  "  "?Ȏ'" ٢"  " "٢"  "
"  "  "
3"  "  "
آȺ8"  "  "
"  "  "
"  "  "
䚏"  "  "?̞џӤ<" ٢"  " "٢"  "
ԟ"  "  "
򰩸"  "  "
ӹ"  "  "
Ӿ"  "  "
9"  "  "
ɞӄ"  "  "
"  "  "
ԭ"  "  "
Ƿȉ"  "  "
³	"  "  "
="  "  "
,"  "  "
/"  "  "
ǧ4"  "  "
҆կ"  "  "
1"  "  "
z"  "  "
z"  "  "
"  "  "
Ќ"  "  "??" ٢"  " "٢"  "
ѵ"  "  "
՘Ҫ"  "  "
Ő"  "  "
ѮW"  "  "
ࡢ"  "  "
ں"  "  "
Ŧй"  "  "
޴Ȉ"  "  "
܋"  "  "
7"  "  "
ݽ<"  "  "
؎9"  "  "
膨ǧ4"  "  "
ௐ߿ؙ"  "  "
؈2"  "  "
£˘"  "  "
["  "  "
氦٤"  "  "
"  "  "?" ٢"  " "٢"  "
됹"  "  "
"  "  "
آ"  "  "?و;" ٢"  " "٢"  "
ӕ"  "  "
ߍ	ԅ"  "  "
	͛"  "  "
ɼ	ɕ"  "  "
֘	0"  "  "
퉙	"  "  "
	"  "  "
	"  "  "
	"  "  "
؞	׼	"  "  "
˨	:"  "  "
	0"  "  "
	&"  "  "
꾪	4"  "  "
	ϐ"  "  "
Œ	+"  "  "
	"  "  "
	a"  "  "
أ	"  "  "
ު	"  "  "?	ޚA" ٢"  " "٢"  "
߯	"  "  "
	"  "  "
ߑ	"  "  "
	j"  "  "
	"  "  "
ֆ	㪏"  "  "
߁	"  "  "
	"  "  "
	"  "  "

Y"  "  "

,"  "  "
ـ
/"  "  "
Ⱅ
ܶE"  "  "

"  "  "

:"  "  "
ܑϘ
"  "  "
И
O"  "  "
ј
׼"  "  "
̗
"  "  "?Ɓ
ܩ" ٢"  " "٢"  "

"  "  "

"  "  "
৚
"  "  "?" ٢"  " "٢"  "
öލ"  "  "
ພi"  "  "
ďݺ"  "  "?" ٢"  " "٢"  "
¥Å࿴"  "  "
"  "  "
ꎟ"  "  "?˖ɦ" ٢"  " "٢"  "
˚"  "  "
࿽l"  "  "
ٯ꓋"  "  "?ѱ3" ٢"  " "٢"  "­ً"  "  "7"  "  ")"  "  "#"  "  ""  "  "ܔ"  "  "ӗ"  "  "?#" ٢"  " "٢"  "ٕ"  "  ";"  "  "Q"  "  "۶"  "  "ǂu"  "  ""  "  "?B" ٢"  " "٢"  "Ժ"  "  ""  "  "D"  "  "$"  "  "ļ"  "  "Ԯ"  "  ""  "  "?؊!" ٢"  " "٢"  ""  "  "/"  "  "$"  "  "ҳ"  "  "஍p"  "  "ɬ"  "  "?݇ͮ:" ٢"  " "٢"  ""  "  "C"  "  "֯o"  "  "%"  "  ""  "  ""  "  ""  "  "?꺫덢!" ٢"  " "٢"  ""  "  "ǭ6"  "  "B"  "  "å"  "  "͑"  "  "Ժ"  "  "?<" ٢"  " "٢"  "ൽ"  "  "ۣA"  "  "5"  "  "("  "  "қԠ"  "  ""  "  "ؠȣ"  "  "?ϙ" ٢"  " "٢"  "˾"  "  "F"  "  "4"  "  "	"  "  "൫"  "  "}"  "  ""  "  "ࣷ"  "  "
"  "  ""  "  ""  "  "˘"  "  "ఌ"  "  ""  "  ""  "  ""  "  "ਗ਼"  "  "O"  "  "?Э" ٢"  " "٢"  ""  "  "ڔ"  "  "?ᔧ" ٢"  " "٢"  "ځ_"  "  "Ϩ"  "  "?	" ٢"  " "٢"  "Ô"  "  "씈぀"  "  "ꄋA"  "  "Þԭ"  "  ""  "  "?" ٢"  " "٢"  ""  "  "ǯJ"  "  ""  "  "?6" ٢"  " "٢"  "Q"  "  "Ļ"  "  "B"  "  "̢쉢"  "  "7"  "  "Ϧ"  "  "ى"  "  ""  "  "ཙ"  "  ""  "  "?߿+" ٢"  " "٢"  """  "  "Ѳ"  "  "?" ٢"  " "٢"  ""  "  "?Å" ٢"  " "٢"  "һ"  "  "o"  "  "࿧"  "  ">G" ٢"  " "٢"  "C"  "  "?<" ٢"  " "٢"  "<"  "  "핖D"  "  "?Ŏát" ٢"  " "٢"  "ѡ"  "  ""  "  ""  "  ""  "  ""  "  "ִ"  "  "ܜ?"  "  "G"  "  "΅"  "  "?ݵ" ٢"  " "٢"  "ȿ"  "  ""  "  "Ү"  "  "?" ٢"  " "٢"  "⛴"  "  "϶"  "  ">m" ٢"  " "٢"  "4"  "  "ʠ0"  "  "?䝬1" ٢"  " "٢"  ""  "  ""  "  "ٜ""  "  "?" ٢"  " "٢"  ""  "  "?٭" ٢"  " "٢"  "צ"  "  "?ʀ" ٢"  " "٢"  ""  "  ""  "  "?ҵු" ٢"  " "٢"  "Ե"  "  "뀜/"  "  "?Ӓʔ" ٢"  " "٢"  "టն"  "  ""  "  "h"  "  "⧫"  "  ";"  "  "?׆M" ٢"  " "٢"  "ƹ>"  "  ""  "  "F"  "  "݃"  "  "/"  "  "A"  "  "µɚ"  "  "?ϟU" ٢"  " "٢"  "?"  "  ""  "  "?" ٢"  " "٢"  ""  "  "ީ"  "  "?" ٢"  " "٢"  "ᒧ"  "  "<"  "  "?Ƥ4" ٢"  " "٢"  ""  "  ""  "  """  "  ""  "  ""  "  "?ŗ	" ٢"  " "٢"  ""  "  ""  "  "|"  "  ""  "  "迷"  "  "?خK" ٢"  " "٢"  "/"  "  "+"  "  "Ѳ:"  "  "ꌴ"  "  "B"  "  "="  "  "Ǩ"  "  "?ѢO" ٢"  " "٢"  "ɻ8"  "  "̒"  "  "?ฒ" ٢"  " "٢"  "τ"  "  "?	" ٢"  " "٢"  "ȵ"  "  "դy"  "  ""  "  "5"  "  "z"  "  "ޟ"  "  ""  "  "0"  "  "? Ѕ" ٢"  " "٢"  "Â "  "  "̤ۏ j"  "  "?Ϣ ঃI" ٢"  " "٢"  "Т ޔ"  "  "̩ "  "  " ."  "  "ɋ "  "  "ꨪ "  "  "?׏ Գ
" ٢"  " "٢"  "ͪ "  "  " s"  "  "಍ "  "  " :"  "  "ຓ "  "  " "  "  " ׏"  "  " 1"  "  "? $" ٢"  " "٢"  "Х ڧ "  "  "қ!ܸ"  "  "?঱!ʪ:" ٢"  " "٢"  "!Ң7"  "  "Ɨ""  "  "?Չ"" ٢"  " "٢"  "Ջ""  "  "?ҙ"ܐ" ٢"  " "٢"  """  "  "ỽ"j"  "  """  "  ""g"  "  "ʨ"˘"  "  ""o"  "  "" "  "  ""9"  "  "?"" ٢"  " "٢"  """  "  ""'"  "  "?"z" ٢"  " "٢"  "̧""  "  "ߴ""  "  "񄉑#"  "  "ʹ#·"  "  "ȓ#Y"  "  "맔#"  "  "՘#"  "  "#E"  "  "#"  "  "#"  "  "ΰΧ#"  "  "о#"  "  "#"  "  "#"  "  )$
tf_Compute"?" ٢"  " "٢"  "U"  "  "j繝"  "  "n"  "  "u "  "  "?" ٢"  " "٢"  "㭘݅
"  "  "	"  "  "Ŋ"  "  "̈"  "  "?>" ٢"  " "٢"  ""  "  ""  "  ""  "  "໛Ǭ"  "  "?/" ٢"  " "٢"  "Ϯ"  "  "ق"  "  ""  "  "ڢ"  "  "?Ć" ٢"  " "٢"  "и"  "  ""  "  ""  "  "൫"  "  "?" ٢"  " "٢"  "ѝԾ"  "  ""  "  "샦"  "  "򆍦޲"  "  "?" ٢"  " "٢"  "ڕೆ
"  "  "ٴհZ"  "  "h"  "  "؛	"  "  "?#" ٢"  " "٢"  "ϼ"  "  "Ȝ"  "  "a"  "  ""  "  "?۷" ٢"  " "٢"  "ࡓ"  "  ""  "  "?ű" ٢"  " "٢"  ""  "  "?䵡" ٢"  " "٢"  "Đ"  "  "лѽ"  "  "ૢ"  "  "?'" ٢"  " "٢"  "ට"  "  "ś"  "  "@ۿֿ" ٢"  " "٢"  "ؿ	"  "  ""  "  ""  "  "Ҷ"  "  ""  "  ""  "  "̨L"  "  "پF"  "  ""  "  "?" ٢"  " "٢"  "Π"  "  "˘"  "  "?ި" ٢"  " "٢"  "Ī"  "  ";"  "  "?B" ٢"  " "٢"  ""  "  ""  "  "뽐+"  "  "߼"  "  "θ"  "  "?" ٢"  " "٢"  "Б"  "  "ݘߕƐ"  "  "?*" ٢"  " "٢"  "॑#"  "  "י"  "  "?⦠" ٢"  " "٢"  "֩"  "  ""  "  "?ߖ
" ٢"  " "٢"  "񊨤"  "  ""  "  "¢ൽ"  "  "흫I"  "  "Ϭ"  "  "Ҭɯ"  "  ""  "  "㨮B"  "  "?" ٢"  " "٢"  "ɒ"  "  "Ŭ"  "  "?ӣp" ٢"  " "٢"  "ȉ"  "  ""  "  "Ƀ"  "  "Ԩ"  "  "͘"  "  ""  "  "C"  "  "K"  "  ""  "  "?" ٢"  " "٢"  "߰"  "  "l"  "  ""  "  "2"  "  "˘"  "  "ó"  "  ""  "  "7"  "  "?" ٢"  " "٢"  ""  "  "1"  "  "?㿔L" ٢"  " "٢"  "Ɣ͙"  "  "߷"  "  "ЩE"  "  "롪4"  "  "ת5"  "  "୪!"  "  ""  "  "ū"  "  "ثޫ"  "  "ǲܡ"  "  "ɥѵ"  "  "Ж"  "  "ɹ"  "  "?ฒ" ٢"  " "٢"  "ӵ"  "  ""  "  "j"  "  "ϯ"  "  "ݐ"  "  "?˒;" ٢"  " "٢"  "9"  "  ""  "  "8"  "  "֙ ݗ"  "  " 4"  "  "Â ۼ"  "  "ժ "  "  "ƛ "  "  " "  "  " "  "  
tf_Compute">Ȗb" ٢"  " "٢"  "I"  "  "^"  "  "m"  "  "ʠsۨ"  "  ">壂w5" ٢"  " "٢"  "wങ "  "  "ଓϷ"  "  ""  "  "ī"  "  "?" ٢"  " "٢"  "ߔ"  "  "鶊ݽ"  "  ""  "  "ˁ"  "  "?ࠅ?" ٢"  " "٢"  " "  "  "໏"  "  ""  "  "Ś"  "  "?-" ٢"  " "٢"  "À!"  "  ""  "  ""  "  "׀"  "  "?" ٢"  " "٢"  "ѱ㞺"  "  ""  "  "롽i"  "  ""  "  "?΢-" ٢"  " "٢"  "ԃ"  "  ""  "  ""  "  "ѧ"  "  "?#" ٢"  " "٢"  "ț䟇"  "  "ٺ"  "  "Օ"  "  "?"" ٢"  " "٢"  ""  "  "¾"  "  ""  "  "?;" ٢"  " "٢"  ""  "  "4"  "  "챲("  "  "'"  "  ""  "  "پ"  "  "ͩ"  "  "?"" ٢"  " "٢"  ""  "  "5"  "  "ʍ̞-"  "  "͟"  "  "ݳ"  "  ""  "  "?1" ٢"  " "٢"  "֐"  "  "8"  "  "ฬ-"  "  "ӣ#"  "  "Ԁ"  "  "մ"  "  ""  "  "?!" ٢"  " "٢"  ""  "  "Ě)"  "  "+"  "  ""  "  "|"  "  ""  "  "?8" ٢"  " "٢"  ""  "  "3"  "  "Ǖ'"  "  "#"  "  ""  "  "Ř"  "  ""  "  "?"" ٢"  " "٢"  "ֺ"  "  "ХL"  "  "t"  "  ""  "  "ٍ	ǂ"  "  "	ٲ"  "  "?
=" ٢"  " "٢"  "
"  "  "
Տ"  "  "ः
"  "  "μ
"  "  "
""  "  "԰
"  "  "Š
"  "  "
"  "  "
Ƀ"  "  "
	"  "  "Ѽ
y"  "  "䮊
7"  "  "
್*"  "  "
D"  "  "
Ժ"  "  "
;"  "  "
"  "  "
s"  "  "
߸"  "  "
"  "  "?E" ٢"  " "٢"  ""  "  "೗୼"  "  "ٻ"  "  "ӄ"  "  "ಟ"  "  "Ֆ"  "  "ͭʓ"  "  "ڷ"  "  "ǟ!"  "  "ӄa"  "  "ӌC"  "  "C"  "  "_"  "  ""  "  "͘Y"  "  ""  "  "ېz"  "  ""  "  "ٛ"  "  "?C" ٢"  " "٢"  ""  "  ""  "  "݄"  "  ""  "  " "  "  "ٍ"  "  "և"  "  ""  "  "Ϗ"  "  "
"  "  "ϊA"  "  "Ó௲,"  "  "A"  "  "ϋ9"  "  ""  "  "՗:"  "  "؞"  "  "a"  "  "퉐ۭ"  "  "ɺ"  "  "?B" ٢"  " "٢"  ""  "  ""  "  ""  "  "ԤM"  "  ""  "  "ˈ"  "  ""  "  ""  "  """  "  "ϟ^"  "  "ՔE"  "  "ϵٛ6"  "  "="  "  "ʟ"  "  ","  "  "р"  "  "Ԁ"  "  "ՀӤ"  "  ""  "  "?ɜ=" ٢"  " "٢"  ""  "  "挞"  "  "唟ˡ"  "  "צ"  "  "凩%"  "  "ǝܝ"  "  "ݪ"  "  ""  "  "錎"  "  ""  "  "E"  "  "?"  "  "0"  "  "֙;"  "  ""  "  "ϵ7"  "  ""  "  "a"  "  "ť"  "  "˴"  "  "?=" ٢"  " "٢"  ""  "  "í"  "  ""  "  ""  "  "˨"  "  ""  "  "π"  "  "ܐ"  "  "삉˽"  "  "ҩ@"  "  "ع3"  "  "ʤ'"  "  "8"  "  ""  "  "N"  "  "ﾨ"  "  "m"  "  "¨"  "  "Ǵ"  "  "?؇@" ٢"  " "٢"  "󬘭"  "  ""  "  "ࢡ"  "  ""  "  "ͼ!"  "  "Ì"  "  ""  "  ""  "  "߀"  "  ""  "  "5"  "  "0"  "  "ބ,"  "  "E"  "  ""  "  "7"  "  ""  "  ""  "  "ʶ"  "  ""  "  "?՗?" ٢"  " "٢"  "ח"  "  ""  "  "隤"  "  "s"  "  "ྐ"  "  "ș"  "  "ا{"  "  "җ"  "  ""  "  "="  "  "३>"  "  "ȋ'"  "  "9"  "  "ೣȎ"  "  "ʾ,"  "  "ఌ"  "  "["  "  "෼"  "  "ʅ"  "  "?º" ٢"  " "٢"  ""  "  "`"  "  "ؿ"  "  "?" ٢"  " "٢"  "׆"  "  "ɚr"  "  "؛"  "  "?±ք" ٢"  " "٢"  "ï"  "  "~"  "  "Ŝ"  "  ">ǝ" ٢"  " "٢"  "러"  "  "禱˘"  "  "҈="  "  "߿"  "  "ʃ="  "  "I"  "  ">ٻ" ٢"  " "٢"  "*"  "  "墽s"  "  "?ʐ6" ٢"  " "٢"  "̐/"  "  ""  "  "?" ٢"  " "٢"  "ʸč"  "  "?ژ" ٢"  " "٢"  "ܘ׭"  "  "R"  "  ""  "  "C"  "  ""  "  "Ȇ"  "  "#"  "  "9"  "  "?࢟" ٢"  " "٢"  ""  "  ""  "  "?U" ٢"  " "٢"  "ț"  "  ""  "  "ઓ)"  "  "4"  "  "ຈ4"  "  "ռ2"  "  ""  "  ""  "  ""  "  "媊"  "  "%"  "  "Μѹ"  "  "ɥ"  "  "?X" ٢"  " "٢"  "ʤF"  "  "!"  "  "A"  "  "̷"  "  "ˇڲB"  "  "؄B"  "  ""  "  "?ෛ>" ٢"  " "٢"  "0"  "  "Ţ֪"  "  "?" ٢"  " "٢"  "˨"  "  "޷="  "  ""  "  "φ˻"  "  """  "  "?" ٢"  " "٢"  ""  "  ""  "  "ҡ"  "  "?" ٢"  " "٢"  ""  "  "՜"  "  ">R" ٢"  " "٢"  "2"  "  "㖮ҡ"  "  "?ۆ߫%" ٢"  " "٢"  ""  "  "݄"  "  "ö﵎"  "  "?冽" ٢"  " "٢"  "ޘ"  "  ""  "  "?Â" ٢"  " "٢"  ""  "  "ίh"  "  ""  "  "ˌ"  "  "׃)"  "  "?զ" ٢"  " "٢"  "݆"  "  ""  "  "?*" ٢"  " "٢"  """  "  "ɝ"  "  "?" ٢"  " "٢"  ""  "  "ԦƮ"  "  "?ߣ	" ٢"  " "٢"  "ะ"  "  "y"  "  "뿬"  "  "Q"  "  "؞"  "  ""  "  "昱"  "  "뚭*"  "  "?Ť9" ٢"  " "٢"  "و8"  "  ""  "  "?}" ٢"  " "٢"  ""  "  ""  "  ""  "  "׻"  "  "⠼"  "  "ė"  "  "?"  "  "P"  "  "ꎨ"  "  "? " ٢"  " "٢"  "̉ Ϣ"  "  " і<"  "  "? ٗ" ٢"  " "٢"  " t"  "  " ՙ"  "  "?ܔ%" ٢"  " "٢"  "ז%Ơ"  "  "%鳇"  "  "ۅ%Ð"  "  "%"  "  "%"  "  "%'"  "  ">ܚ%X" ٢"  " "٢"  "%S"  "  "?ܗ%" ٢"  " "٢"  "ᥙ%ѿ"  "  "%"  "  "?%Œq" ٢"  " "٢"  "%ǒ"  "  "ӂ&"  "  "ϿΚ&t"  "  "̛&G"  "  "&M"  "  "&?"  "  "ꮝ&¢"  "  "ǝ&"  "  "&"  "  "&"  "  "̬&6"  "  "Ť&➱"  "  "&"  "  "@&ˡ" ٢"  " "٢"  "&؆"  "  "&"  "  "̌&"  "  "ɮ&"  "  "߂'i"  "  "˃'"  "  "'"  "  "ؔ'n"  "  "'ྭu"  "  "("  "  "?(ٰ$" ٢"  " "٢"  "("  "  "ų("  "  "?)" ٢"  " "٢"  "ލ)ź"  "  "?Ԍ)" ٢"  " "٢"  "ێ)"  "  ")໭V"  "  "Ϥ)"  "  "?ޥ)<" ٢"  " "٢"  "Ń)`"  "  "௹)ր'"  "  ")Y"  "  ")ཉ"  "  "ཕ)?"  "  ")"  "  ")"  "  ")"  "  ")"  "  ")Һ"  "  "?ϲ)Υ=" ٢"  " "٢"  ")"  "  ")ĝ"  "  "͈)౼#"  "  "*ƞ"  "  "ģ*"  "  "?ਟ+බ" ٢"  " "٢"  "+"  "  "+1"  "  "?Ê," ٢"  " "٢"  ","  "  ",и"  "  "?." ٢"  " "٢"  "."  "  "?." ٢"  " "٢"  ".ߊ"  "  "ӥ."  "  ".	"  "  "?." ٢"  " "٢"  "Ԙ.੔"  "  "."  "  ">Γ/_" ٢"  " "٢"  "/="  "  "⬆/"  "  "?/&" ٢"  " "٢"  "/๒"  "  "/"  "  "?海/" ٢"  " "٢"  "྅/Î"  "  "/"  "  "?/
" ٢"  " "٢"  "/"  "  "׹/f"  "  "/"  "  "/;"  "  "/"  "  "۩/"  "  "/"  "  "/3"  "  "?/൞" ٢"  " "٢"  "/\"  "  "/M"  "  "?0W" ٢"  " "٢"  "09"  "  "ͧ1ĝ"  "  "?1爕" ٢"  " "٢"  "1"  "  "ţ1"  "  "?ΰ1" ٢"  " "٢"  "1-"  "  "ʓ1֓"  "  "?17" ٢"  " "٢"  "1"  "  "1Ш"  "  "1"  "  "2૫"  "  "2"  "  "?3" ٢"  " "٢"  "Ꞡ3"  "  "?3ם
" ٢"  " "٢"  "3"  "  "3"  "  "3"  "  "͛3A"  "  "3"  "  "3"  "  "Σ3"  "  "3<"  "  "?4" ٢"  " "٢"  "4"  "  "ӏ4ঃ"  "  "?ɝ4" ٢"  " "٢"  "Ģ4Ɓ"  "  "?ܺ4" ٢"  " "٢"  "ّ4ğ"  "  "4බ"  "  "ͯ4?"  "  "4ʩ"  "  "?ﴅ4." ٢"  " "٢"  "͉4"  "  "Ѣ4"  "  "4ʠ/"  "  "4ɯ?"  "  "4"  "  "4"  "  n
tf_Compute"?" ٢"  " "٢"  "V"  "  "l
"  "  "w'"  "  "%"  "  "?," ٢"  " "٢"  ""  "  "ҡ"  "  "쨄"  "  ""  "  "?8" ٢"  " "٢"  "ϲ"  "  ""  "  "г"  "  "	"  "  "?ƪİ%" ٢"  " "٢"  "КǪ"  "  "꟔"  "  "䒼S"  "  "͎"  "  ">èـ" ٢"  " "٢"  "՜a"  "  ">" ٢"  " "٢"  ""  "  ""  "  ">ۅ" ٢"  " "٢"  "ɇ"  "  ">" ٢"  " "٢"  "ʋs"  "  ">" ٢"  " "٢"  "U"  "  ">恏" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "ˑO"  "  ">ג" ٢"  " "٢"  "["  "  ">Ŕ˘" ٢"  " "٢"  "삕C"  "  ">" ٢"  " "٢"  "O"  "  ">̗" ٢"  " "٢"  "ஃa"  "  ">" ٢"  " "٢"  "ߙU"  "  ">" ٢"  " "٢"  "ӛ"  "  ""  "  "ԣ"  "  ">" ٢"  " "٢"  "էa"  "  ">" ٢"  " "٢"  "I"  "  ">Ϫ" ٢"  " "٢"  "a"  "  ">֬˘" ٢"  " "٢"  "ਖ਼="  "  ">ಓ" ٢"  " "٢"  "a"  "  ">왰" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "a"  "  ">" ٢"  " "٢"  "ݴ["  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "ŸO"  "  ">̹" ٢"  " "٢"  "C"  "  ">؞" ٢"  " "٢"  "C"  "  ">Ǿ" ٢"  " "٢"  "C"  "  ">ఌ" ٢"  " "٢"  "="  "  ">˘" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "࿝O"  "  ">֝" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "O"  "  ">ࡘ" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "="  "  ">؞" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "s"  "  ">" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "g"  "  ">ਿ" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "ޛO"  "  ">" ٢"  " "٢"  "փC"  "  ">" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "I"  "  ">ש" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "ప="  "  "=s" ٢"  " "٢"  "*"  "  ">" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "C"  "  ">؞" ٢"  " "٢"  "0"  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "љ["  "  ">" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "໬a"  "  ">؞" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "m"  "  ">γ˘" ٢"  " "٢"  "="  "  ">" ٢"  " "٢"  "O"  "  ">˘" ٢"  " "٢"  "="  "  ">˘" ٢"  " "٢"  "C"  "  "=z" ٢"  " "٢"  "$"  "  ">ǅ" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "m"  "  ">" ٢"  " "٢"  "ǉ["  "  ">" ٢"  " "٢"  "թz"  "  ">" ٢"  " "٢"  "a"  "  ">Ȏ؞" ٢"  " "٢"  "C"  "  ">ఌ" ٢"  " "٢"  "ϐ6"  "  ">" ٢"  " "٢"  "֞C"  "  ">ߘ˘" ٢"  " "٢"  "ɓO"  "  ">ϔ" ٢"  " "٢"  "䆕O"  "  ">" ٢"  " "٢"  "ʖz"  "  ">" ٢"  " "٢"  "6"  "  ">˘" ٢"  " "٢"  "֙I"  "  ">֚˘" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "˜U"  "  ">ם" ٢"  " "٢"  "๎["  "  ">" ٢"  " "٢"  "ןa"  "  ">" ٢"  " "٢"  "̳["  "  ">آ" ٢"  " "٢"  "Ûm"  "  ">ఌ" ٢"  " "٢"  "="  "  ">؞" ٢"  " "٢"  "ࠨI"  "  ">" ٢"  " "٢"  "6"  "  ">Ө˘" ٢"  " "٢"  "C"  "  ">Đ" ٢"  " "٢"  "Ӫ="  "  ">؞" ٢"  " "٢"  "C"  "  ">턭" ٢"  " "٢"  "ǭO"  "  ">ڮ" ٢"  " "٢"  "ঋg"  "  ">" ٢"  " "٢"  ""  "  ">" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "尴m"  "  ">˘" ٢"  " "٢"  "ϒI"  "  ">" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "нC"  "  ">׾" ٢"  " "٢"  "6"  "  "=z" ٢"  " "٢"  "6"  "  ">њఌ" ٢"  " "٢"  "="  "  ">ఌ" ٢"  " "٢"  "ɂ="  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "כ"  "  ">˘" ٢"  " "٢"  "܉I"  "  ">" ٢"  " "٢"  "ܺ["  "  ">؞" ٢"  " "٢"  "I"  "  ">ܜ" ٢"  " "٢"  "["  "  ">˘" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "ЩU"  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "="  "  ">" ٢"  " "٢"  "z"  "  ">" ٢"  " "٢"  "ੌU"  "  ">ژ؞" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "஫U"  "  ">ఌ" ٢"  " "٢"  "6"  "  ">؞" ٢"  " "٢"  "I"  "  ">˘" ٢"  " "٢"  "I"  "  ">؞" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "C"  "  ">Ϛ" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "I"  "  ">؞" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "a"  "  ">" ٢"  " "٢"  "6"  "  ">˘" ٢"  " "٢"  "="  "  ">ఌ" ٢"  " "٢"  "="  "  ">˘" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "U"  "  ">" ٢"  " "٢"  "ࡋI"  "  ">" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "μO"  "  ">" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "«C"  "  ">Ā" ٢"  " "٢"  "଍C"  "  ">Í" ٢"  " "٢"  "ʂs"  "  ">⇄" ٢"  " "٢"  "фC"  "  ">х" ٢"  " "٢"  "C"  "  ">˘" ٢"  " "٢"  "чC"  "  ">ˈ؞" ٢"  " "٢"  "шO"  "  ">" ٢"  " "٢"  "؊O"  "  ">˘" ٢"  " "٢"  "֧="  "  ">ߡ" ٢"  " "٢"  "؍C"  "  ">؎؞" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "ߐI"  "  ">" ٢"  " "٢"  "["  "  ">" ٢"  " "٢"  "0"  "  ">" ٢"  " "٢"  "ԅC"  "  ">" ٢"  " "٢"  "m"  "  ">" ٢"  " "٢"  "՘C"  "  ">" ٢"  " "٢"  "چI"  "  ">؞" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "O"  "  ">ĥ" ٢"  " "٢"  "I"  "  ">؞" ٢"  " "٢"  "ЧU"  "  ">؞" ٢"  " "٢"  "="  "  ">" ٢"  " "٢"  "I"  "  ">ψ؞" ٢"  " "٢"  "ˬC"  "  ">˭" ٢"  " "٢"  "="  "  "ԧ"  "  "s"  "  "ꉳ˘"  "  "ఌ"  "  "a"  "  ">" ٢"  " "٢"  "¼["  "  ">ɼ" ٢"  " "٢"  "C"  "  ">" ٢"  " "٢"  "Ϊ="  "  ">ʞ" ٢"  " "٢"  "6"  "  ">˘" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "6"  "  ">˘" ٢"  " "٢"  "O"  "  ">" ٢"  " "٢"  "6"  "  ">" ٢"  " "٢"  "I"  "  ">؞" ٢"  " "٢"  "6"  "  ">˘" ٢"  " "٢"  "I"  "  ">" ٢"  " "٢"  "g"  "  ">" ٢"  " "٢"  "C"  "  "C"  "  "ר="  "  "a"  "  "O"  "  ">ʵ" ٢"  " "٢"  "0"  "  "@൸" ٢"  " "٢"  "ഗ%"  "  ""  "  ">	" ٢"  " "٢"  "෭"  "  ""  "  "ҹ"  "  ">ٽ" ٢"  " "٢"  ""  "  "	"  "  "?󯖷 " ٢"  " "٢"  "Η ["  "  " "  "  "?Ϊ#" ٢"  " "٢"  "׆#"  "  "ǒ#"  "  "?#	" ٢"  " "٢"  "ρ#"  "  "#Ø"  "  "?ܪ&z" ٢"  " "٢"  "ݪ&`"  "  "'"  "  "?)" ٢"  " "٢"  ")"  "  "*"  "  "?1" ٢"  " "٢"  "Ԙ1ڿ"  "  "2"  "  "?3	" ٢"  " "٢"  "3"  "  "3"  "  "3J"  "  "3궯"  "  "3"  "  "?3" ٢"  " "٢"  "3ʟ"  "  "3"  "  "3="  "  "?4ۅ" ٢"  " "٢"  "4"  "  "4λ"  "  "?֚Ϝ4G" ٢"  " "٢"  "ќ4"  "  "Ǩ4"  "  "4B"  "  "4J"  "  "鼼4;"  "  "4`"  "  "޶4e"  "  "ŷ4?"  "  "䋸4"  "  "4矷"  "  "4ݨ"  "  "¨4"  "  tf_data_iterator_get_next"+" ٢"  "  "$ǚɯ" ԡx"  "C" ݨ˞" ԡx"8"	8"
 "  "ܘ" "  ̞tf_data_iterator_resource"(" 	"+" ŕӢ" ݨ˞"," ԋ" ŕӢ",І" լ" ԋ"+Ƃҿ" a" ŕӢ"+" ̡" a",ࣷ" ̡" a"Ȇ" "9И" " "" "pkWgradient_tape/model/bert/encoder/layer_1/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"D?5model/bert/encoder/layer_8/attention/self/truediv:Mul"Mul"TO7Adam/Adam/update_13/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"YT@model/bert/encoder/layer_3/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"Y
T
@model/bert/encoder/layer_2/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"ojVgradient_tape/model/bert/encoder/layer_11/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"94*model/bert/encoder/layer_10/output/Add:Add"Add"A<1model/bert/encoder/layer_7/intermediate/Tanh:Tanh"Tanh"d_Jmodel/bert/encoder/layer_10/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"hcVgradient_tape/model/bert/encoder/layer_7/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"<7#Iterator::Model::ParallelMapV2::Zip"Iterator::Zip"^YOgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/sub/Neg:Neg"Neg"ojUmodel/bert/encoder/layer_3/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhSmodel/bert/encoder/layer_8/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"QL?model/bert/encoder/layer_9/output/dense/Tensordot/MatMul:MatMul"MatMul"`	[	Qgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"\~X~Ogradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul/Sum:Sum"Sum"_ZPgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul/Sum:Sum"Sum"ZUKgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/mul_1:Mul"Mul"NI?model/bert/encoder/layer_0/attention/output/LayerNorm/mul_1:Mul"Mul"XSHmodel/bert/encoder/layer_3/attention/output/dropout_11/dropout/Cast:Cast"Cast"+	&	Adam/gradients/AddN_73:AddN"AddN"UP8Adam/Adam/update_118/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?5model/bert/encoder/layer_2/output/LayerNorm/mul_2:Mul"Mul"T	O	7Adam/Adam/update_56/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"to]gradient_tape/model/bert/encoder/layer_7/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"\WMgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/truediv:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/sub:Sub"Sub"A<2model/bert/encoder/layer_11/intermediate/mul_2:Mul"Mul"[VKgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/Tile:Tile"Tile"D?5model/bert/encoder/layer_3/attention/self/truediv:Mul"Mul"ojUmodel/bert/encoder/layer_8/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UPFgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul/Sum:Sum"Sum"FA5model/bert/encoder/layer_9/output/LayerNorm/add:AddV2"AddV2"\WMgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/truediv:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/Mul:Mul"Mul"gbMmodel/bert/encoder/layer_5/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"lgUgradient_tape/model/bert/encoder/layer_8/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"SO8Adam/Adam/update_184/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"GB6model/bert/encoder/layer_11/output/LayerNorm/add:AddV2"AddV2"VQFmodel/bert/encoder/layer_7/attention/self/dropout_22/dropout/Cast:Cast"Cast"JE7model/bert/encoder/layer_9/output/dense/BiasAdd:BiasAdd"BiasAdd"e`Ugradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/Tile:Tile"Tile"XSIgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul_2/Mul_1:Mul"Mul"P
K
Agradient_tape/model/bert/encoder/layer_0/intermediate/Pow/mul:Mul"Mul">9/model/bert/encoder/layer_0/intermediate/Pow:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul/Mul:Mul"Mul"[VKgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/Tile:Tile"Tile"SNDmodel/bert/encoder/layer_3/attention/self/dropout_10/dropout/Mul:Mul"Mul"HC9gradient_tape/model/bert/embeddings/LayerNorm/mul/Sum:Sum"Sum"toWmodel/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"faTgradient_tape/model/bert/encoder/layer_1/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"T	O	7Adam/Adam/update_45/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlXgradient_tape/model/bert/encoder/layer_11/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"SN@model/bert/encoder/layer_10/attention/self/query/BiasAdd:BiasAdd"BiasAdd"S:O:8Adam/Adam/update_133/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B=1model/bert/encoder/layer_7/intermediate/add:AddV2"AddV2"XSIgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/Mul:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_7/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"B=3model/bert/encoder/layer_8/output/LayerNorm/sub:Sub"Sub"ojUmodel/bert/encoder/layer_6/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"@;1model/bert/encoder/layer_9/intermediate/mul_2:Mul"Mul"@
;
1model/bert/encoder/layer_2/intermediate/mul_3:Mul"Mul"NI?model/bert/encoder/layer_6/attention/output/LayerNorm/mul_1:Mul"Mul"OJ?model/bert/encoder/layer_10/output/dropout_33/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_50/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_72/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMAmodel/bert/encoder/layer_0/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"xs_model/bert/encoder/layer_5/output/dropout_18/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"HC7model/bert/encoder/layer_6/output/LayerNorm/add_1:AddV2"AddV2"LG=gradient_tape/model/bert/embeddings/LayerNorm/mul_2/Mul_1:Mul"Mul"snYmodel/bert/encoder/layer_2/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"NI?model/bert/encoder/layer_3/attention/output/LayerNorm/mul_2:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_4/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"XSIgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/sub:Sub"Sub"o$k$_gradient_tape/model/bert/encoder/layer_10/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"T
O
Amodel/bert/encoder/layer_4/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"YTJgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul_1/Mul_1:Mul"Mul"SN>model/bert/encoder/layer_10/attention/self/transpose:Transpose"	Transpose"pkWgradient_tape/model/bert/encoder/layer_5/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"RM@model/bert/encoder/layer_11/intermediate/Tensordot/MatMul:MatMul"MatMul"RM?model/bert/encoder/layer_5/attention/self/query/BiasAdd:BiasAdd"BiasAdd"l	g	Ugradient_tape/model/bert/encoder/layer_5/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"pk^gradient_tape/model/bert/encoder/layer_8/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YKUKGgradient_tape/model/bert/encoder/layer_6/intermediate/TanhGrad:TanhGrad"TanhGrad"TOEgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/sub/Neg:Neg"Neg"UP8Adam/Adam/update_161/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Sgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/sub:Sub"Sub"lgWgradient_tape/model/bert/encoder/layer_6/attention/self/transpose_3/transpose:Transpose"	Transpose"TO7Adam/Adam/update_95/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Sgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"RM?model/bert/encoder/layer_6/attention/self/value/BiasAdd:BiasAdd"BiasAdd"sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:SparseSoftmaxCrossEntropyWithLogits"#SparseSoftmaxCrossEntropyWithLogits"niVmodel/bert/encoder/layer_3/attention/self/dropout_10/dropout/GreaterEqual:GreaterEqual"GreaterEqual"H
C
7model/bert/encoder/layer_4/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"83)model/bert/encoder/layer_7/output/Add:Add"Add"^YOgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/sub/Sum:Sum"Sum"{gmodel/bert/encoder/layer_6/attention/self/dropout_19/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"SNDgradient_tape/model/bert/encoder/layer_10/intermediate/mul_3/Mul:Mul"Mul"h	c	Vgradient_tape/model/bert/encoder/layer_3/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"XuTuKgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/mul_1:Mul"Mul"D?5model/bert/encoder/layer_9/output/LayerNorm/mul_1:Mul"Mul"?:+gradient_tape/model/dense/TanhGrad:TanhGrad"TanhGrad"idOmodel/bert/encoder/layer_6/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"HC7model/bert/encoder/layer_1/output/LayerNorm/add_1:AddV2"AddV2"TO7Adam/Adam/update_57/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VKgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/Tile:Tile"Tile"+&Adam/gradients/AddN_32:AddN"AddN"h	c	Vgradient_tape/model/bert/encoder/layer_1/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_49/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VImodel/bert/encoder/layer_3/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"p	k	^gradient_tape/model/bert/encoder/layer_3/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"RMCgradient_tape/model/bert/encoder/layer_7/intermediate/Pow/mul_1:Mul"Mul"RMAmodel/bert/encoder/layer_6/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"~jmodel/bert/encoder/layer_11/attention/output/dropout_35/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"SNDmodel/bert/encoder/layer_4/attention/self/dropout_13/dropout/Mul:Mul"Mul"SNBmodel/bert/encoder/layer_10/attention/output/LayerNorm/add_1:AddV2"AddV2"TO?model/bert/encoder/layer_6/attention/self/transpose_2:Transpose"	Transpose"V	Q	Ggradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul_2/Sum:Sum"Sum"snYmodel/bert/encoder/layer_8/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Sgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/sub:Sub"Sub"ok_gradient_tape/model/bert/encoder/layer_11/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"a\Rgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"{gmodel/bert/encoder/layer_4/attention/self/dropout_13/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"Adam/Pow_1:Pow"Pow"JE7model/bert/encoder/layer_3/intermediate/BiasAdd:BiasAdd"BiasAdd"XSIgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul_1/Mul_1:Mul"Mul"gbWgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"UP8Adam/Adam/update_190/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_92/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgSgradient_tape/model/bert/encoder/layer_5/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"faTgradient_tape/model/bert/encoder/layer_0/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"~
y
amodel/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"XSIgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/Mul:Mul"Mul"~yamodel/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"HC)AssignAddVariableOp_3:AssignAddVariableOp"AssignAddVariableOp"6
1
'model/bert/embeddings/LayerNorm/sub:Sub"Sub"ojVgradient_tape/model/bert/encoder/layer_10/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"TOEmodel/bert/encoder/layer_10/attention/self/dropout_31/dropout/Mul:Mul"Mul")1%1Adam/gradients/AddN_26:AddN"AddN"HC7model/bert/encoder/layer_5/output/LayerNorm/add_1:AddV2"AddV2"e`Kmodel/bert/encoder/layer_5/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"TOEgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/sub/Sum:Sum"Sum"UP8Adam/Adam/update_158/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B=3model/bert/encoder/layer_7/output/LayerNorm/mul:Mul"Mul"lgUgradient_tape/model/bert/encoder/layer_7/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qlWmodel/bert/encoder/layer_8/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ojUmodel/bert/encoder/layer_1/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Sgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"D?5model/bert/encoder/layer_0/output/LayerNorm/mul_1:Mul"Mul"UP8Adam/Adam/update_182/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?5model/bert/encoder/layer_1/output/LayerNorm/mul_2:Mul"Mul"Q
L
Amodel/bert/encoder/layer_2/output/LayerNorm/moments/variance:Mean"Mean"+&Adam/gradients/AddN_77:AddN"AddN"B=3model/bert/encoder/layer_8/attention/output/Add:Add"Add"JE;gradient_tape/model/bert/embeddings/LayerNorm/mul/Mul_1:Mul"Mul"[VKmodel/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance:Mean"Mean"snYmodel/bert/encoder/layer_0/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"[
V
Kmodel/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance:Mean"Mean"b]Sgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/Mul:Mul"Mul"mhTgradient_tape/model/bert/encoder/layer_11/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"ZUHmodel/bert/encoder/layer_11/attention/self/query/Tensordot/MatMul:MatMul"MatMul"YT@model/bert/encoder/layer_6/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"qlWmodel/bert/encoder/layer_6/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"ID1model/dropout_1/dropout/GreaterEqual:GreaterEqual"GreaterEqual"xs_model/bert/encoder/layer_3/output/dropout_12/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"qlWmodel/bert/encoder/layer_3/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"r	m	[gradient_tape/model/bert/encoder/layer_3/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"SFOF8Adam/Adam/update_114/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mh[gradient_tape/model/bert/encoder/layer_10/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"vq_gradient_tape/model/bert/encoder/layer_2/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"@;1model/bert/encoder/layer_0/intermediate/mul_3:Mul"Mul"/*model/dropout/dropout/Cast:Cast"Cast"^YOgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul/Mul:Mul"Mul"RMAmodel/bert/encoder/layer_3/attention/output/LayerNorm/add_1:AddV2"AddV2"V	Q	Ggradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul_2/Mul:Mul"Mul"TO7Adam/Adam/update_51/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMCgradient_tape/model/bert/encoder/layer_0/intermediate/Pow/mul_1:Mul"Mul"TO7Adam/Adam/update_31/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMBmodel/bert/encoder/layer_11/output/LayerNorm/moments/variance:Mean"Mean"RMCgradient_tape/model/bert/encoder/layer_9/intermediate/mul_1/Mul:Mul"Mul"B=3model/bert/encoder/layer_3/attention/output/Add:Add"Add"SNDgradient_tape/model/bert/encoder/layer_11/intermediate/Pow/mul_1:Mul"Mul"E@6model/bert/encoder/layer_10/attention/self/truediv:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_8/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"OJ@gradient_tape/model/bert/encoder/layer_11/attention/self/sub:Sub"Sub"mhSmodel/bert/encoder/layer_9/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"JE;model/bert/encoder/layer_1/output/dropout_6/dropout/Mul:Mul"Mul"ojUmodel/bert/encoder/layer_9/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"snagradient_tape/model/bert/encoder/layer_10/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"faTgradient_tape/model/bert/encoder/layer_8/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"^`Z`Qgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul_2/Sum:Sum"Sum">9/gradient_tape/model/dropout_1/dropout/Mul_2:Mul"Mul"NI?model/bert/encoder/layer_1/attention/output/LayerNorm/mul_2:Mul"Mul"b]Mgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"lgUgradient_tape/model/bert/encoder/layer_2/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"@
;
1model/bert/encoder/layer_4/intermediate/mul_1:Mul"Mul"QL?model/bert/encoder/layer_0/output/dense/Tensordot/MatMul:MatMul"MatMul"RMCgradient_tape/model/bert/encoder/layer_8/intermediate/mul_1/Mul:Mul"Mul"[VKgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/Tile:Tile"Tile"YTGmodel/bert/encoder/layer_1/attention/self/query/Tensordot/MatMul:MatMul"MatMul"VQ8Adam/Adam/update/ResourceScatterAdd_1:ResourceScatterAdd"ResourceScatterAdd"TO?model/bert/encoder/layer_8/attention/self/transpose_1:Transpose"	Transpose"TOEgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/sub/Neg:Neg"Neg"b	]	Sgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/Mul:Mul"Mul"ojUmodel/bert/encoder/layer_0/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"rmXmodel/bert/encoder/layer_10/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idOmodel/bert/encoder/layer_0/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_178/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"\WJmodel/bert/encoder/layer_10/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"hdPmodel/bert/encoder/layer_10/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"LG9model/bert/encoder/layer_6/attention/self/Softmax:Softmax"Softmax"+&Adam/gradients/AddN_51:AddN"AddN"W
R
Emodel/bert/encoder/layer_2/attention/self/key/Tensordot/MatMul:MatMul"MatMul"UPFmodel/bert/encoder/layer_3/attention/output/dropout_11/dropout/Mul:Mul"Mul"QL?model/bert/encoder/layer_9/intermediate/Tensordot/MatMul:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_1/attention/self/dropout_4/dropout/Mul_2:Mul"Mul"_
Z
Emodel/bert/embeddings/word_embeddings/embedding_lookup:ResourceGather"ResourceGather"RMCgradient_tape/model/bert/encoder/layer_7/intermediate/mul_2/Mul:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_5/attention/self/truediv/RealDiv:Mul"Mul"@;1model/bert/encoder/layer_6/intermediate/mul_3:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/Mul:Mul"Mul"hcVgradient_tape/model/bert/encoder/layer_2/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_78:AddN"AddN"D?3model/bert/encoder/layer_0/intermediate/add_1:AddV2"AddV2"JE7model/bert/encoder/layer_7/intermediate/BiasAdd:BiasAdd"BiasAdd"TO6Adam/Adam/update/UnsortedSegmentSum:UnsortedSegmentSum"UnsortedSegmentSum"B=3model/bert/encoder/layer_3/output/LayerNorm/sub:Sub"Sub"a\Rgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"\,X,Ogradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul/Mul:Mul"Mul"L
G
=model/bert/encoder/layer_4/attention/output/LayerNorm/mul:Mul"Mul"\WHgradient_tape/model/bert/encoder/layer_11/intermediate/TanhGrad:TanhGrad"TanhGrad"UPBmodel/bert/encoder/layer_10/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"b]Mgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad".)model/dropout/dropout/Mul_1:Mul"Mul"gbMmodel/bert/encoder/layer_9/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"[VImodel/bert/encoder/layer_5/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"h	c	Vgradient_tape/model/bert/encoder/layer_5/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_180/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SSOS8Adam/Adam/update_102/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"{gmodel/bert/encoder/layer_7/attention/self/dropout_22/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"]XMgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/Tile_1:Tile"Tile"JE;gradient_tape/model/bert/embeddings/LayerNorm/mul_1/Mul:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/sub/Sum:Sum"Sum"`[Qgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"PKAgradient_tape/model/bert/encoder/layer_6/intermediate/Pow/mul:Mul"Mul"<7-gradient_tape/model/dropout/dropout/Mul_2:Mul"Mul"RM?model/bert/encoder/layer_0/attention/self/query/BiasAdd:BiasAdd"BiasAdd"R
M
=model/bert/encoder/layer_6/attention/self/transpose:Transpose"	Transpose"WREmodel/bert/encoder/layer_8/attention/self/key/Tensordot/MatMul:MatMul"MatMul"a\Rgradient_tape/model/bert/encoder/layer_7/attention/self/dropout_22/dropout/Mul:Mul"Mul"qlWmodel/bert/encoder/layer_3/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/sub:Sub"Sub"h	c	Ygradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"\}X}Ogradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul/Mul:Mul"Mul"ZUAmodel/bert/encoder/layer_10/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"A<2model/bert/encoder/layer_10/intermediate/mul_3:Mul"Mul"JE7model/bert/encoder/layer_2/intermediate/BiasAdd:BiasAdd"BiasAdd"XSIgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/sub:Sub"Sub"RMCgradient_tape/model/bert/encoder/layer_4/intermediate/mul_1/Mul:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul_2/Mul:Mul"Mul"GB/model/dropout/dropout/GreaterEqual:GreaterEqual"GreaterEqual"f	a	Tgradient_tape/model/bert/encoder/layer_1/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"{gmodel/bert/encoder/layer_8/attention/self/dropout_25/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"RMAmodel/bert/encoder/layer_3/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"VQGgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul_1/Mul:Mul"Mul"T	O	Egradient_tape/model/bert/encoder/layer_2/output/LayerNorm/sub/Neg:Neg"Neg"vq_gradient_tape/model/bert/encoder/layer_0/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"D?3model/bert/encoder/layer_6/intermediate/add_1:AddV2"AddV2"RMCgradient_tape/model/bert/encoder/layer_0/intermediate/mul_1/Mul:Mul"Mul"E@4model/bert/encoder/layer_11/intermediate/add_1:AddV2"AddV2"UPFgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul/Mul:Mul"Mul"*%Adam/gradients/AddN_9:AddN"AddN"D?5model/bert/encoder/layer_6/output/LayerNorm/mul_2:Mul"Mul"R	M	Cgradient_tape/model/bert/encoder/layer_1/intermediate/mul_1/Mul:Mul"Mul"HC9gradient_tape/model/bert/embeddings/LayerNorm/sub/Sum:Sum"Sum"lgWgradient_tape/model/bert/encoder/layer_9/attention/self/transpose_2/transpose:Transpose"	Transpose"]YPgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/truediv_1:Mul"Mul"HC)AssignAddVariableOp_4:AssignAddVariableOp"AssignAddVariableOp"C>2model/bert/encoder/layer_11/intermediate/add:AddV2"AddV2"TO7Adam/Adam/update_71/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ql_gradient_tape/model/bert/encoder/layer_10/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"PK9gradient_tape/model/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO?model/bert/encoder/layer_4/attention/self/transpose_2:Transpose"	Transpose"niUgradient_tape/model/bert/encoder/layer_3/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"'"div_no_nan:DivNoNan"DivNoNan"ZUKgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/mul_1:Mul"Mul"UP8Adam/Adam/update_150/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pk^gradient_tape/model/bert/encoder/layer_0/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"ID8model/bert/encoder/layer_10/output/LayerNorm/add_1:AddV2"AddV2"VQFmodel/bert/encoder/layer_3/attention/self/dropout_10/dropout/Cast:Cast"Cast"B=1model/bert/encoder/layer_3/intermediate/add:AddV2"AddV2"PKAgradient_tape/model/bert/encoder/layer_8/intermediate/Pow/mul:Mul"Mul"wr^model/bert/encoder/layer_1/output/dropout_6/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"R
M
Amodel/bert/encoder/layer_0/attention/output/LayerNorm/add_1:AddV2"AddV2"ojUmodel/bert/encoder/layer_0/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhTgradient_tape/model/bert/encoder/layer_10/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"TOEgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/sub/Neg:Neg"Neg"r9n9]gradient_tape/model/bert/encoder/layer_8/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"JE7model/bert/encoder/layer_6/intermediate/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_0/attention/self/transpose_1/transpose:Transpose"	Transpose"\WMgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/truediv:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_9/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"UPFmodel/bert/encoder/layer_8/attention/self/dropout_25/dropout/Mul_1:Mul"Mul"UP8Adam/Adam/update_122/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"b]Sgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/Mul:Mul"Mul"YT@model/bert/encoder/layer_1/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"UPFgradient_tape/model/bert/encoder/layer_10/intermediate/mul_3/Mul_1:Mul"Mul"\WMgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/truediv:Mul"Mul"RMAmodel/bert/encoder/layer_2/attention/output/LayerNorm/add_1:AddV2"AddV2"Y
T
Gmodel/bert/encoder/layer_4/attention/self/query/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_59/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D
?
5model/bert/encoder/layer_2/attention/self/truediv:Mul"Mul">9/model/bert/encoder/layer_8/intermediate/Pow:Mul"Mul"SN6Adam/Adam/update_1/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"@;1model/bert/encoder/layer_3/intermediate/mul_1:Mul"Mul"@
;
1model/bert/encoder/layer_2/intermediate/mul_1:Mul"Mul"LG/Iterator::Model::ParallelMapV2::Zip[0]::FlatMap"Iterator::FlatMap"UP@model/bert/encoder/layer_11/attention/self/transpose_3:Transpose"	Transpose"[VKmodel/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance:Mean"Mean"ojUmodel/bert/encoder/layer_6/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"niVmodel/bert/encoder/layer_4/attention/self/dropout_13/dropout/GreaterEqual:GreaterEqual"GreaterEqual"|hmodel/bert/encoder/layer_10/attention/self/dropout_31/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"PKAgradient_tape/model/bert/encoder/layer_0/attention/self/mul_1:Mul"Mul"ojUmodel/bert/encoder/layer_5/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlWmodel/bert/encoder/layer_8/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"^	Y	Ogradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/truediv_1:Mul"Mul")N%NAdam/gradients/AddN_37:AddN"AddN"VQGgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul_2/Mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_5/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"PKAgradient_tape/model/bert/encoder/layer_2/attention/self/mul_1:Mul"Mul"FA5model/bert/encoder/layer_0/output/LayerNorm/add:AddV2"AddV2"VQFmodel/bert/encoder/layer_5/attention/self/dropout_16/dropout/Cast:Cast"Cast"pk^gradient_tape/model/bert/encoder/layer_6/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"YTGmodel/bert/encoder/layer_4/attention/self/value/Tensordot/MatMul:MatMul"MatMul"+	&	Adam/gradients/AddN_42:AddN"AddN"XSIgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/Mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_0/attention/output/dropout_2/dropout/Mul:Mul"Mul"^YNgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/Tile_1:Tile"Tile"<7-gradient_tape/model/dropout_1/dropout/Mul:Mul"Mul"YTGmodel/bert/encoder/layer_0/attention/self/query/Tensordot/MatMul:MatMul"MatMul">9/model/bert/encoder/layer_3/intermediate/Pow:Mul"Mul"gbMmodel/bert/encoder/layer_9/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/bert/encoder/layer_6/attention/self/dropout_19/dropout/Mul_2:Mul"Mul"C>4model/bert/encoder/layer_10/attention/output/Add:Add"Add"UP8Adam/Adam/update_127/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Iterator::Model"qlWmodel/bert/encoder/layer_6/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"QLBgradient_tape/model/bert/encoder/layer_10/attention/self/mul_1:Mul"Mul"X	S	Igradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/Mul:Mul"Mul"`h\hSgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/Mul:Mul"Mul"(#Adam/gradients/AddN:AddN"AddN"B=3model/bert/encoder/layer_1/output/LayerNorm/sub:Sub"Sub"[VGgradient_tape/model/bert/encoder/layer_4/intermediate/TanhGrad:TanhGrad"TanhGrad"faTgradient_tape/model/bert/encoder/layer_2/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"8
3
)model/bert/encoder/layer_4/output/Add:Add"Add"HC7model/bert/encoder/layer_0/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"b	]	Mgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"b]Sgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"VQDgradient_tape/model/bert/encoder/layer_1/intermediate/Pow/Pow:Square"Square"d_Ugradient_tape/model/bert/encoder/layer_2/attention/output/dropout_8/dropout/Mul_2:Mul"Mul"TOAmodel/bert/encoder/layer_8/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"ZUKgradient_tape/model/bert/encoder/layer_11/output/dropout_36/dropout/Mul:Mul"Mul"V	Q	Ggradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul_2/Mul:Mul"Mul"SNBmodel/bert/encoder/layer_10/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"f
b
Nmodel/bert/encoder/layer_11/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"WRGmodel/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean:Mean"Mean"lgWgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"T
O
?model/bert/encoder/layer_2/attention/self/transpose_3:Transpose"	Transpose",'model/dropout/dropout/Mul:Mul"Mul"SN@model/bert/encoder/layer_10/attention/self/value/BiasAdd:BiasAdd"BiasAdd"ni\gradient_tape/model/bert/encoder/layer_1/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"8
3
)model/bert/embeddings/LayerNorm/mul_1:Mul"Mul"FA5model/bert/encoder/layer_6/output/LayerNorm/add:AddV2"AddV2"+&Adam/gradients/AddN_79:AddN"AddN"NI?gradient_tape/model/bert/encoder/layer_2/attention/self/Sum:Sum"Sum"SN6Adam/Adam/update_8/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toWmodel/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"TO?model/bert/encoder/layer_8/attention/self/transpose_2:Transpose"	Transpose"d_Ugradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/mul_1:Mul"Mul"SN6Adam/Adam/update_3/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WR>model/bert/encoder/layer_5/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"^YOgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul/Sum:Sum"Sum"e`Vgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/mul_1:Mul"Mul"n4j4^gradient_tape/model/bert/encoder/layer_8/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"OJ@model/bert/encoder/layer_11/attention/output/LayerNorm/mul_2:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_6/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"MH>model/bert/encoder/layer_10/attention/output/LayerNorm/mul:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/sub/Sum:Sum"Sum"Equal:Equal"Equal"WR>model/bert/encoder/layer_7/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"`	[	Qgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"gbXgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/truediv:Mul"Mul"d[`[Tgradient_tape/model/bert/encoder/layer_5/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/sub:Sub"Sub"RM?model/bert/encoder/layer_1/attention/self/query/BiasAdd:BiasAdd"BiasAdd"faTgradient_tape/model/bert/encoder/layer_5/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"OJ?gradient_tape/model/bert/embeddings/LayerNorm/moments/Tile:Tile"Tile"^YOgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/truediv_1:Mul"Mul"qlWmodel/bert/encoder/layer_2/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"LG=model/bert/encoder/layer_7/attention/output/LayerNorm/sub:Sub"Sub"NI?model/bert/encoder/layer_10/output/dropout_33/dropout/Mul_1:Mul"Mul"QL?model/bert/encoder/layer_1/intermediate/Tensordot/MatMul:MatMul"MatMul"L
G
=model/bert/encoder/layer_2/output/dropout_9/dropout/Mul_1:Mul"Mul"TO?model/bert/encoder/layer_8/attention/self/transpose_3:Transpose"	Transpose"PKAgradient_tape/model/bert/encoder/layer_4/attention/self/mul_1:Mul"Mul"idOmodel/bert/encoder/layer_2/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"T	O	7Adam/Adam/update_54/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RENEEgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul/Sum:Sum"Sum"\WLmodel/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance:Mean"Mean"GB6model/bert/encoder/layer_10/output/LayerNorm/add:AddV2"AddV2"Adam/mul:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_7/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_46/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"[VLgradient_tape/model/bert/encoder/layer_3/output/dropout_12/dropout/Mul_2:Mul"Mul"niVmodel/bert/encoder/layer_5/attention/self/dropout_16/dropout/GreaterEqual:GreaterEqual"GreaterEqual"% GatherV2:GatherV2"GatherV2"D?3model/bert/encoder/layer_3/intermediate/add_1:AddV2"AddV2"[VKgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/Tile:Tile"Tile"T	O	7Adam/Adam/update_47/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"vq_gradient_tape/model/bert/encoder/layer_5/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"toWmodel/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"+&Adam/gradients/AddN_82:AddN"AddN"upXmodel/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"SNDgradient_tape/model/bert/encoder/layer_11/intermediate/mul_1/Mul:Mul"Mul"UP8Adam/Adam/update_171/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMAmodel/bert/encoder/layer_7/attention/output/LayerNorm/add_1:AddV2"AddV2"idOmodel/bert/encoder/layer_3/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_179/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"dg`gWgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/truediv:Mul"Mul"NI?model/bert/encoder/layer_11/output/dropout_36/dropout/Mul_1:Mul"Mul"UPFgradient_tape/model/bert/encoder/layer_11/intermediate/mul_3/Mul_1:Mul"Mul"Adam/Pow:Pow"Pow"YT@model/bert/encoder/layer_5/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"lgSgradient_tape/model/bert/encoder/layer_3/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"mhXgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"b]Sgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/sub:Sub"Sub"[VGgradient_tape/model/bert/encoder/layer_8/intermediate/TanhGrad:TanhGrad"TanhGrad"niUgradient_tape/model/bert/encoder/layer_1/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"TO7Adam/Adam/update_79/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG=gradient_tape/model/bert/embeddings/LayerNorm/mul_1/Mul_1:Mul"Mul"KF8model/bert/encoder/layer_11/intermediate/BiasAdd:BiasAdd"BiasAdd"RM=model/bert/encoder/layer_0/attention/self/transpose:Transpose"	Transpose"MH>model/bert/encoder/layer_3/output/dropout_12/dropout/Mul_1:Mul"Mul"LG=model/bert/encoder/layer_9/attention/output/LayerNorm/sub:Sub"Sub"NI?gradient_tape/model/bert/encoder/layer_7/attention/self/sub:Sub"Sub"N
I
?model/bert/encoder/layer_4/attention/output/LayerNorm/mul_1:Mul"Mul"YTJgradient_tape/model/bert/encoder/layer_9/output/dropout_30/dropout/Mul:Mul"Mul"hcVgradient_tape/model/bert/encoder/layer_9/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ExecutorState::Process"TO?model/bert/encoder/layer_7/attention/self/transpose_2:Transpose"	Transpose"ojUmodel/bert/encoder/layer_8/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"LG=model/bert/encoder/layer_5/attention/output/LayerNorm/mul:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_4/intermediate/Pow/mul_1:Mul"Mul"kfVgradient_tape/model/bert/encoder/layer_11/attention/self/transpose/transpose:Transpose"	Transpose"~yamodel/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"NI?gradient_tape/model/bert/encoder/layer_4/attention/self/Sum:Sum"Sum"NI2Adam/Adam/update/AssignVariableOp:AssignVariableOp"AssignVariableOp"qlWmodel/bert/encoder/layer_4/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"NI?gradient_tape/model/bert/encoder/layer_1/attention/self/sub:Sub"Sub"VQFmodel/bert/encoder/layer_9/attention/self/dropout_28/dropout/Cast:Cast"Cast"c^Tgradient_tape/model/bert/encoder/layer_7/attention/output/dropout_23/dropout/Mul:Mul"Mul"T
O
?model/bert/encoder/layer_4/attention/self/transpose_3:Transpose"	Transpose"TOEgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul/Sum:Sum"Sum"B
=
3model/bert/encoder/layer_2/attention/output/Add:Add"Add"`[Qgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"TOEmodel/bert/encoder/layer_0/attention/output/dropout_2/dropout/Mul:Mul"Mul"83)model/bert/encoder/layer_3/output/Add:Add"Add"qlWmodel/bert/encoder/layer_2/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"C
>
+Adam/Adam/update/strided_slice:StridedSlice"StridedSlice"lgZgradient_tape/model/bert/encoder/layer_4/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"e`Mmodel/bert/encoder/layer_0/output/dropout_3/dropout/GreaterEqual:GreaterEqual"GreaterEqual"QL@model/bert/encoder/layer_11/attention/output/LayerNorm/add:AddV2"AddV2"@;1model/bert/encoder/layer_6/intermediate/mul_1:Mul"Mul"S#O#8Adam/Adam/update_174/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_119/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_197/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"oj]gradient_tape/model/bert/encoder/layer_10/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"T	O	7Adam/Adam/update_98/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam")V%VAdam/gradients/AddN_43:AddN"AddN"UP8Adam/Adam/update_198/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"train_function"D?5model/bert/encoder/layer_1/attention/self/truediv:Mul"Mul"mhVgradient_tape/model/bert/encoder/layer_11/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"SN6Adam/Adam/update_6/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG9model/bert/encoder/layer_5/attention/self/Softmax:Softmax"Softmax"[	V	Ggradient_tape/model/bert/encoder/layer_5/intermediate/TanhGrad:TanhGrad"TanhGrad"VQGgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul/Sum_1:Sum"Sum"pk^gradient_tape/model/bert/encoder/layer_0/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"SNDgradient_tape/model/bert/encoder/layer_11/intermediate/mul_3/Mul:Mul"Mul"YTJgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul_2/Mul_1:Mul"Mul"RMAmodel/bert/encoder/layer_1/attention/output/LayerNorm/add_1:AddV2"AddV2"QL?model/bert/encoder/layer_3/output/dense/Tensordot/MatMul:MatMul"MatMul"ni\gradient_tape/model/bert/encoder/layer_6/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"?:0model/bert/encoder/layer_10/intermediate/Pow:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_7/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"0+&InstantiatedCapturedFunction::RunAsync"NI?gradient_tape/model/bert/encoder/layer_7/attention/self/mul:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_5/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"idOmodel/bert/encoder/layer_1/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"rmXmodel/bert/encoder/layer_11/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ZUKgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/mul_1:Mul"Mul"g	b	Wgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"RpNp7Adam/Adam/update_89/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMBmodel/bert/encoder/layer_10/output/LayerNorm/moments/variance:Mean"Mean"QL?model/bert/encoder/layer_2/intermediate/Tensordot/MatMul:MatMul"MatMul"PK?model/bert/encoder/layer_5/attention/output/LayerNorm/add:AddV2"AddV2"+&Adam/gradients/AddN_53:AddN"AddN"RMCmodel/bert/encoder/layer_1/attention/self/dropout_4/dropout/Mul:Mul"Mul"W
R
Emodel/bert/encoder/layer_5/attention/self/key/Tensordot/MatMul:MatMul"MatMul"LG9model/bert/encoder/layer_1/attention/self/Softmax:Softmax"Softmax"^	Y	Ogradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/sub/Neg:Neg"Neg"to]gradient_tape/model/bert/encoder/layer_7/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"NI?model/bert/encoder/layer_2/attention/output/LayerNorm/mul_2:Mul"Mul"lgZgradient_tape/model/bert/encoder/layer_2/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"mhSmodel/bert/encoder/layer_5/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"LG=model/bert/encoder/layer_8/attention/output/LayerNorm/mul:Mul"Mul"*%Adam/gradients/AddN_4:AddN"AddN"[	V	Ggradient_tape/model/bert/encoder/layer_1/intermediate/TanhGrad:TanhGrad"TanhGrad"snYmodel/bert/encoder/layer_7/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlWmodel/bert/encoder/layer_4/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"WR=model/bert/embeddings/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"E@4model/bert/encoder/layer_10/intermediate/add_1:AddV2"AddV2"Adam/sub_3:Sub"Sub">9/model/bert/encoder/layer_6/intermediate/mul:Mul"Mul"?:0model/bert/encoder/layer_11/intermediate/mul:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_2/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"P
K
?model/bert/encoder/layer_2/attention/output/LayerNorm/add:AddV2"AddV2"SNDmodel/bert/encoder/layer_5/attention/self/dropout_16/dropout/Mul:Mul"Mul"SNDgradient_tape/model/bert/encoder/layer_10/intermediate/mul_2/Mul:Mul"Mul"TO7Adam/Adam/update_58/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"N
I
?model/bert/encoder/layer_0/attention/output/LayerNorm/mul_2:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul/Sum:Sum"Sum"lgUgradient_tape/model/bert/encoder/layer_4/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"JE7model/bert/encoder/layer_8/output/dense/BiasAdd:BiasAdd"BiasAdd"d_Ugradient_tape/model/bert/encoder/layer_0/attention/output/dropout_2/dropout/Mul_2:Mul"Mul"83.EagerExecute: __inference_train_function_19462"LG=gradient_tape/model/bert/embeddings/LayerNorm/moments/sub:Sub"Sub"TO?model/bert/encoder/layer_1/attention/self/transpose_1:Transpose"	Transpose"B=3model/bert/encoder/layer_3/output/LayerNorm/mul:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_2/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"WRHmodel/bert/encoder/layer_5/attention/output/dropout_17/dropout/Mul_1:Mul"Mul"oj]gradient_tape/model/bert/encoder/layer_11/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"S<O<8Adam/Adam/update_135/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"C>4model/bert/encoder/layer_11/output/LayerNorm/sub:Sub"Sub"lgSgradient_tape/model/bert/encoder/layer_6/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"A<2model/bert/encoder/layer_10/intermediate/mul_2:Mul"Mul"UP8Adam/Adam/update_128/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMAmodel/bert/encoder/layer_8/attention/output/LayerNorm/add_1:AddV2"AddV2"ojUmodel/bert/encoder/layer_0/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"WRHmodel/bert/encoder/layer_7/attention/output/dropout_23/dropout/Mul_1:Mul"Mul"p	k	^gradient_tape/model/bert/encoder/layer_4/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"OJ@gradient_tape/model/bert/encoder/layer_10/attention/self/Sum:Sum"Sum"TO7Adam/Adam/update_38/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"PKAgradient_tape/model/bert/encoder/layer_1/intermediate/Pow/mul:Mul"Mul"TO7Adam/Adam/update_86/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"NI>model/bert/encoder/layer_9/output/dropout_30/dropout/Cast:Cast"Cast"hcVgradient_tape/model/bert/encoder/layer_0/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"pkWgradient_tape/model/bert/encoder/layer_4/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"HC7model/bert/encoder/layer_7/output/LayerNorm/add_1:AddV2"AddV2"E@6model/bert/encoder/layer_10/output/LayerNorm/mul_1:Mul"Mul"RM?model/bert/encoder/layer_2/attention/self/value/BiasAdd:BiasAdd"BiasAdd"D
?
5model/bert/encoder/layer_2/output/LayerNorm/mul_1:Mul"Mul"PK?model/bert/encoder/layer_8/attention/output/LayerNorm/add:AddV2"AddV2"TO7Adam/Adam/update_66/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idOmodel/bert/encoder/layer_5/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"l	g	Ugradient_tape/model/bert/encoder/layer_2/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"PMLMCgradient_tape/model/bert/encoder/layer_6/intermediate/Pow/mul_1:Mul"Mul"A<2model/bert/encoder/layer_10/intermediate/mul_1:Mul"Mul"E@6model/bert/encoder/layer_11/attention/self/truediv:Mul"Mul"KF<model/bert/encoder/layer_4/output/dropout_15/dropout/Mul:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_2/attention/self/sub:Sub"Sub"lgSgradient_tape/model/bert/encoder/layer_2/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"c^Tgradient_tape/model/bert/encoder/layer_3/attention/output/dropout_11/dropout/Mul:Mul"Mul"UP8Adam/Adam/update_194/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/sub/Neg:Neg"Neg"VQGmodel/bert/encoder/layer_1/attention/output/dropout_5/dropout/Mul_1:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_5/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"R	M	Cgradient_tape/model/bert/encoder/layer_5/intermediate/mul_2/Mul:Mul"Mul"+&Adam/gradients/AddN_55:AddN"AddN"@;1model/bert/encoder/layer_8/intermediate/mul_3:Mul"Mul"SN6Adam/Adam/update_9/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam";6)gradient_tape/model/dense_1/MatMul:MatMul"MatMul"a\Rgradient_tape/model/bert/encoder/layer_6/attention/self/dropout_19/dropout/Mul:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_9/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YTGmodel/bert/encoder/layer_8/attention/self/value/Tensordot/MatMul:MatMul"MatMul"VQFmodel/bert/encoder/layer_6/attention/self/dropout_19/dropout/Cast:Cast"Cast"YTJgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/Mul:Mul"Mul"rono]gradient_tape/model/bert/encoder/layer_5/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"E@6model/bert/encoder/layer_11/output/LayerNorm/mul_1:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_0/attention/self/mul:Mul"Mul"vq_gradient_tape/model/bert/encoder/layer_6/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"rm[gradient_tape/model/bert/encoder/layer_0/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"PK=model/bert/encoder/layer_7/attention/self/key/BiasAdd:BiasAdd"BiasAdd"VQGgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul/Sum_1:Sum"Sum"d_Ugradient_tape/model/bert/encoder/layer_10/attention/self/dropout_31/dropout/Mul_2:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_3/attention/self/transpose_2/transpose:Transpose"	Transpose"V	Q	Ggradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul/Sum_1:Sum"Sum"83 model/dense/BiasAdd:_FusedMatMul"_FusedMatMul"JE7model/bert/encoder/layer_1/intermediate/BiasAdd:BiasAdd"BiasAdd"PK?model/bert/encoder/layer_1/attention/output/LayerNorm/add:AddV2"AddV2"HC7model/bert/encoder/layer_9/output/LayerNorm/add_1:AddV2"AddV2"ZUKgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/mul_1:Mul"Mul"qlWmodel/bert/encoder/layer_0/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"@
;
1model/bert/encoder/layer_4/intermediate/mul_3:Mul"Mul"gbMmodel/bert/encoder/layer_2/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_19:AddN"AddN"K	G	3model/dense_1/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"D?5model/bert/encoder/layer_7/output/LayerNorm/mul_2:Mul"Mul"niTmodel/bert/encoder/layer_10/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"@;1model/bert/encoder/layer_5/intermediate/mul_2:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"c^Ngradient_tape/model/bert/encoder/layer_10/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"B=1model/bert/encoder/layer_8/intermediate/add:AddV2"AddV2"TOEgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul/Mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_0/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"TOEgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul/Sum:Sum"Sum"UPEmodel/bert/encoder/layer_0/attention/self/dropout_1/dropout/Cast:Cast"Cast"UP8Adam/Adam/update_117/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"c^Tgradient_tape/model/bert/encoder/layer_5/attention/self/dropout_16/dropout/Mul_2:Mul"Mul"faNmodel/bert/encoder/layer_4/output/dropout_15/dropout/GreaterEqual:GreaterEqual"GreaterEqual"P
K
?model/bert/encoder/layer_4/attention/output/LayerNorm/add:AddV2"AddV2"RMCgradient_tape/model/bert/encoder/layer_2/intermediate/mul_3/Mul:Mul"Mul">
9
/model/bert/encoder/layer_2/intermediate/Pow:Mul"Mul"UP8Adam/Adam/update_154/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMAmodel/bert/encoder/layer_1/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"E
@
5model/bert/embeddings/LayerNorm/moments/variance:Mean"Mean"faNmodel/bert/encoder/layer_7/output/dropout_24/dropout/GreaterEqual:GreaterEqual"GreaterEqual"lgWgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"83)model/bert/encoder/layer_6/output/Add:Add"Add"`+\+Sgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"qlWmodel/bert/encoder/layer_6/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"SNDgradient_tape/model/bert/encoder/layer_11/intermediate/mul_2/Mul:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul/Mul:Mul"Mul"qlWmodel/bert/encoder/layer_9/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhSmodel/bert/encoder/layer_2/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"pkVmodel/bert/encoder/layer_10/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"+	&	Adam/gradients/AddN_44:AddN"AddN"R^N^7Adam/Adam/update_93/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"_ZPgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul/Mul:Mul"Mul"]XMgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/Tile_1:Tile"Tile"% Identity:Identity"Identity"VQGmodel/bert/encoder/layer_11/attention/output/dropout_35/dropout/Mul:Mul"Mul"faWgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/truediv:Mul"Mul"VQAgradient_tape/model/bert/embeddings/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"D?5model/bert/encoder/layer_6/output/LayerNorm/mul_1:Mul"Mul"T	O	Egradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul/Mul:Mul"Mul"+&Adam/gradients/AddN_81:AddN"AddN"mhXgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"upXmodel/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"YTGmodel/bert/encoder/layer_2/attention/self/value/Tensordot/MatMul:MatMul"MatMul"~yamodel/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"qlWmodel/bert/encoder/layer_9/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Jmodel/bert/encoder/layer_11/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"~jmodel/bert/encoder/layer_10/attention/output/dropout_32/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"WR>model/bert/encoder/layer_9/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"NI?gradient_tape/model/bert/encoder/layer_4/attention/self/sub:Sub"Sub"NI>model/bert/encoder/layer_3/output/dropout_12/dropout/Cast:Cast"Cast"idOmodel/bert/encoder/layer_0/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"XSIgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul_1/Mul_1:Mul"Mul"n	i	\gradient_tape/model/bert/encoder/layer_3/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lxhx\gradient_tape/model/bert/encoder/layer_4/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"XS?model/bert/encoder/layer_11/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"e`Vgradient_tape/model/bert/encoder/layer_7/attention/output/dropout_23/dropout/Mul_2:Mul"Mul"A<1model/bert/encoder/layer_5/intermediate/Tanh:Tanh"Tanh"TO7Adam/Adam/update_75/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_115/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"R
M
=model/bert/encoder/layer_7/attention/self/transpose:Transpose"	Transpose"{gmodel/bert/encoder/layer_9/attention/self/dropout_28/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"T	O	7Adam/Adam/update_53/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Vgradient_tape/model/bert/encoder/layer_4/attention/output/dropout_14/dropout/Mul_2:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/mul_1:Mul"Mul"+&Adam/gradients/AddN_71:AddN"AddN"UP8Adam/Adam/update_159/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_187/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"toZmodel/bert/encoder/layer_10/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO?model/bert/encoder/layer_9/attention/self/transpose_3:Transpose"	Transpose"SO8Adam/Adam/update_183/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"JE7model/bert/encoder/layer_6/output/dense/BiasAdd:BiasAdd"BiasAdd"KF8model/bert/encoder/layer_11/output/dense/BiasAdd:BiasAdd"BiasAdd"^YOgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul/Sum:Sum"Sum"A
<
1model/bert/encoder/layer_2/intermediate/Tanh:Tanh"Tanh"UP8Adam/Adam/update_193/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"_ZPgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul/Mul:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_3/attention/self/truediv/RealDiv:Mul"Mul"B
=
3model/bert/encoder/layer_0/output/LayerNorm/sub:Sub"Sub"B=3model/bert/encoder/layer_8/output/LayerNorm/mul:Mul"Mul"SN6Adam/Adam/update_4/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam""TFE_Py_FastPathExecute_C"*%Adam/Adam/update/Sqrt:Sqrt"Sqrt"qlYmodel/bert/encoder/layer_11/attention/output/dropout_35/dropout/GreaterEqual:GreaterEqual"GreaterEqual"QL?model/bert/encoder/layer_4/intermediate/Tensordot/MatMul:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_7/attention/self/Sum:Sum"Sum"TO7Adam/Adam/update_34/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SNDmodel/bert/encoder/layer_6/attention/self/dropout_19/dropout/Mul:Mul"Mul"LG9model/bert/encoder/layer_7/attention/self/Softmax:Softmax"Softmax"ojUmodel/bert/encoder/layer_7/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"ojUmodel/bert/encoder/layer_0/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhVgradient_tape/model/bert/encoder/layer_10/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"hdPmodel/bert/encoder/layer_11/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"0+model/dense_1/Softmax:Softmax"Softmax"WRGmodel/bert/encoder/layer_1/attention/output/dropout_5/dropout/Cast:Cast"Cast"[VImodel/bert/encoder/layer_9/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"T
O
?model/bert/encoder/layer_2/attention/self/transpose_1:Transpose"	Transpose"rm`gradient_tape/model/bert/encoder/layer_7/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YTGmodel/bert/encoder/layer_9/attention/self/value/Tensordot/MatMul:MatMul"MatMul"NI?model/bert/encoder/layer_7/attention/output/LayerNorm/mul_1:Mul"Mul"w	r	^model/bert/encoder/layer_2/output/dropout_9/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"VQGgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul_1/Mul:Mul"Mul"faWgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/truediv:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_7/intermediate/mul_1/Mul:Mul"Mul"LG=model/bert/encoder/layer_2/attention/output/LayerNorm/sub:Sub"Sub"TO7Adam/Adam/update_69/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"~yamodel/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"NI>model/bert/encoder/layer_5/output/dropout_18/dropout/Cast:Cast"Cast"HC9gradient_tape/model/bert/embeddings/LayerNorm/mul/Mul:Mul"Mul"c^Imodel/bert/encoder/layer_1/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"QLAmodel/bert/encoder/layer_3/output/LayerNorm/moments/variance:Mean"Mean"ZUAmodel/bert/encoder/layer_11/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"hcYgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"q&m&\gradient_tape/model/bert/encoder/layer_10/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"D
?
5model/bert/encoder/layer_4/attention/self/truediv:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_9/intermediate/mul_3/Mul:Mul"Mul"+&Adam/gradients/AddN_58:AddN"AddN"gbMmodel/bert/encoder/layer_4/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"T	O	Egradient_tape/model/bert/encoder/layer_5/intermediate/mul_3/Mul_1:Mul"Mul"XUTUKgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/mul_1:Mul"Mul"UPFmodel/bert/encoder/layer_9/attention/self/dropout_28/dropout/Mul_1:Mul"Mul"C>4model/bert/encoder/layer_11/attention/output/Add:Add"Add"VQGgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul_2/Sum:Sum"Sum"<7-model/bert/embeddings/dropout/dropout/Mul:Mul"Mul""TFE_Py_ExecuteCancelable"hcYgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"TO7Adam/Adam/update_52/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"*%Adam/gradients/AddN_2:AddN"AddN"b]Sgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/sub:Sub"Sub"NI?model/bert/encoder/layer_1/attention/output/LayerNorm/mul_1:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_4/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"T	O	7Adam/Adam/update_85/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgZgradient_tape/model/bert/encoder/layer_1/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"FA5model/bert/encoder/layer_8/output/LayerNorm/add:AddV2"AddV2"72-TensorHandle::GetResourceHandleInfo WaitReady"WRHgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul_1/Mul:Mul"Mul"jeUgradient_tape/model/bert/encoder/layer_6/attention/self/transpose/transpose:Transpose"	Transpose"^YOgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/truediv_1:Mul"Mul"FA5model/bert/encoder/layer_3/output/LayerNorm/add:AddV2"AddV2"mhSmodel/bert/encoder/layer_0/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni\gradient_tape/model/bert/encoder/layer_7/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_175/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RwNw7Adam/Adam/update_81/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam":5+gradient_tape/model/dropout/dropout/Mul:Mul"Mul"PKAgradient_tape/model/bert/encoder/layer_6/attention/self/mul_1:Mul"Mul"[VImodel/bert/encoder/layer_7/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"RMCgradient_tape/model/bert/encoder/layer_2/intermediate/mul_2/Mul:Mul"Mul"oj]gradient_tape/model/bert/encoder/layer_10/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"hcYgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"T	O	7Adam/Adam/update_63/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni\gradient_tape/model/bert/encoder/layer_0/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"lgUgradient_tape/model/bert/encoder/layer_7/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"Cast_3:Cast"Cast"TO?model/bert/encoder/layer_2/attention/self/transpose_2:Transpose"	Transpose"A<1model/bert/encoder/layer_1/intermediate/Tanh:Tanh"Tanh"B=3model/bert/encoder/layer_5/attention/output/Add:Add"Add"KF8model/bert/encoder/layer_10/intermediate/BiasAdd:BiasAdd"BiasAdd"rm`gradient_tape/model/bert/encoder/layer_6/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"F
A
5model/bert/encoder/layer_4/output/LayerNorm/add:AddV2"AddV2"pk^gradient_tape/model/bert/encoder/layer_9/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"A=)Adam/Cast_3/ReadVariableOp:ReadVariableOp"ReadVariableOp"MH=model/bert/encoder/layer_3/output/LayerNorm/moments/mean:Mean"Mean"UP8Adam/Adam/update_103/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"QLAmodel/bert/encoder/layer_5/output/LayerNorm/moments/variance:Mean"Mean"jeUgradient_tape/model/bert/encoder/layer_2/attention/self/transpose/transpose:Transpose"	Transpose"gbUgradient_tape/model/bert/encoder/layer_10/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"gbWgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"RMCgradient_tape/model/bert/encoder/layer_3/intermediate/mul_1/Mul:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_3/attention/self/dropout_10/dropout/Mul_2:Mul"Mul"TOEmodel/bert/encoder/layer_0/attention/self/dropout_1/dropout/Mul_1:Mul"Mul"WR?model/bert/embeddings/dropout/dropout/GreaterEqual:GreaterEqual"GreaterEqual"SN@model/bert/encoder/layer_11/attention/self/value/BiasAdd:BiasAdd"BiasAdd"NI?gradient_tape/model/bert/encoder/layer_2/attention/self/mul:Mul"Mul"Q
L
?model/bert/encoder/layer_2/output/dense/Tensordot/MatMul:MatMul"MatMul"^YOgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/sub/Neg:Neg"Neg"D?3model/bert/encoder/layer_1/intermediate/add_1:AddV2"AddV2"MH=model/bert/encoder/layer_1/output/dropout_6/dropout/Cast:Cast"Cast">
9
/model/bert/embeddings/dropout/dropout/Mul_1:Mul"Mul"TO7Adam/Adam/update_36/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WRHgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul_2/Mul:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_8/attention/self/dropout_25/dropout/Mul_2:Mul"Mul"D?3model/bert/encoder/layer_8/intermediate/add_1:AddV2"AddV2"c3_3Vgradient_tape/model/bert/encoder/layer_8/attention/output/dropout_26/dropout/Mul_2:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul/Mul:Mul"Mul"UP8Adam/Adam/update_107/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_157/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^	Y	Ogradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/sub/Neg:Neg"Neg"+&Adam/gradients/AddN_74:AddN"AddN"ql_gradient_tape/model/bert/encoder/layer_11/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"*% EagerExecute: FlushSummaryWriter"TOEmodel/bert/encoder/layer_11/attention/self/dropout_34/dropout/Mul:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_6/attention/self/Sum:Sum"Sum"faNmodel/bert/encoder/layer_9/output/dropout_30/dropout/GreaterEqual:GreaterEqual"GreaterEqual"YT@model/bert/encoder/layer_7/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"r	m	`gradient_tape/model/bert/encoder/layer_4/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"snYmodel/bert/encoder/layer_1/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"d_Ugradient_tape/model/bert/encoder/layer_11/attention/self/dropout_34/dropout/Mul_2:Mul"Mul"SN>model/bert/encoder/layer_11/attention/self/transpose:Transpose"	Transpose"VQDgradient_tape/model/bert/encoder/layer_2/intermediate/Pow/Pow:Square"Square"B=1model/bert/encoder/layer_1/intermediate/add:AddV2"AddV2"}imodel/bert/encoder/layer_3/attention/output/dropout_11/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"WRHmodel/bert/encoder/layer_9/attention/output/dropout_29/dropout/Mul_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul/Sum:Sum"Sum"WRGmodel/bert/encoder/layer_10/attention/self/dropout_31/dropout/Cast:Cast"Cast"hcVgradient_tape/model/bert/encoder/layer_6/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"niUgradient_tape/model/bert/encoder/layer_0/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"qlWmodel/bert/encoder/layer_8/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idOmodel/bert/encoder/layer_5/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"T	O	7Adam/Adam/update_48/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"T@P@Ggradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul_2/Mul:Mul"Mul"XSImodel/bert/encoder/layer_11/attention/output/dropout_35/dropout/Mul_1:Mul"Mul"NI>model/bert/encoder/layer_4/output/dropout_15/dropout/Cast:Cast"Cast"MH=model/bert/encoder/layer_5/output/LayerNorm/moments/mean:Mean"Mean"gbWgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"UP8Adam/Adam/update_108/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"t
o
Wmodel/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"zfmodel/bert/encoder/layer_0/attention/self/dropout_1/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"]	X	Mgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/Tile_1:Tile"Tile"TO7Adam/Adam/update_33/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni\gradient_tape/model/bert/encoder/layer_7/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_29/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlWmodel/bert/encoder/layer_5/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_156/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VLgradient_tape/model/bert/encoder/layer_11/attention/self/truediv/RealDiv:Mul"Mul"e`Kmodel/bert/encoder/layer_6/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"mhSmodel/bert/encoder/layer_5/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"faNmodel/bert/encoder/layer_8/output/dropout_27/dropout/GreaterEqual:GreaterEqual"GreaterEqual"PK?model/bert/encoder/layer_9/attention/output/LayerNorm/add:AddV2"AddV2"fbbbYgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"@;1model/bert/encoder/layer_8/intermediate/mul_1:Mul"Mul"C>4model/bert/encoder/layer_11/output/LayerNorm/mul:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_1/attention/self/transpose_3/transpose:Transpose"	Transpose"j
e
Pmodel/bert/encoder/layer_11/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Sgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/Mul:Mul"Mul"mhXgradient_tape/model/bert/encoder/layer_10/attention/self/transpose_1/transpose:Transpose"	Transpose"VQGgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul/Mul_1:Mul"Mul"D
?
3model/bert/encoder/layer_4/intermediate/add_1:AddV2"AddV2"TO7Adam/Adam/update_25/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"XSIgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/Mul:Mul"Mul"XSFmodel/bert/encoder/layer_11/attention/self/key/Tensordot/MatMul:MatMul"MatMul"C>%FlushSummaryWriter:FlushSummaryWriter"FlushSummaryWriter"lgWgradient_tape/model/bert/encoder/layer_2/attention/self/transpose_3/transpose:Transpose"	Transpose"ojWmodel/bert/encoder/layer_11/attention/self/dropout_34/dropout/GreaterEqual:GreaterEqual"GreaterEqual"RM?model/bert/encoder/layer_5/attention/self/value/BiasAdd:BiasAdd"BiasAdd"XSIgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/sub:Sub"Sub"lgUgradient_tape/model/bert/encoder/layer_1/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"WRGmodel/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean:Mean"Mean"hdPmodel/bert/encoder/layer_10/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"FA,div_no_nan_1/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"OJ?model/bert/encoder/layer_11/output/dropout_36/dropout/Cast:Cast"Cast"RMAmodel/bert/encoder/layer_9/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"T
O
Amodel/bert/encoder/layer_2/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"NI?gradient_tape/model/bert/encoder/layer_4/attention/self/mul:Mul"Mul"VQDgradient_tape/model/bert/encoder/layer_9/intermediate/Pow/Pow:Square"Square"ojUmodel/bert/encoder/layer_3/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"@;1model/bert/encoder/layer_7/intermediate/mul_3:Mul"Mul"	}	imodel/bert/encoder/layer_7/attention/output/dropout_23/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"NI?gradient_tape/model/bert/encoder/layer_1/attention/self/Sum:Sum"Sum"+&Adam/gradients/AddN_33:AddN"AddN"ZUKgradient_tape/model/bert/encoder/layer_0/output/dropout_3/dropout/Mul_2:Mul"Mul"B=1model/bert/encoder/layer_5/intermediate/add:AddV2"AddV2")$Adam/Adam/update/mul_3:Mul"Mul"rm`gradient_tape/model/bert/encoder/layer_2/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"NI?model/bert/encoder/layer_4/attention/output/LayerNorm/mul_2:Mul"Mul"\WLmodel/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance:Mean"Mean"pkWgradient_tape/model/bert/encoder/layer_7/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"S.O.8Adam/Adam/update_140/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B
=
3model/bert/encoder/layer_4/attention/output/Add:Add"Add"^YOgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul/Mul:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"t	o	]gradient_tape/model/bert/encoder/layer_5/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"\]X]Ogradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/sub/Sum:Sum"Sum"~yamodel/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"b]Sgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"UPFmodel/bert/encoder/layer_9/attention/output/dropout_29/dropout/Mul:Mul"Mul"convert_to_tensor"d_Ugradient_tape/model/bert/encoder/layer_1/attention/output/dropout_5/dropout/Mul_2:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_6/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_6/attention/self/mul:Mul"Mul"vq_gradient_tape/model/bert/encoder/layer_7/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgUgradient_tape/model/bert/encoder/layer_0/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"@;1model/bert/encoder/layer_1/intermediate/mul_3:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/mul_1:Mul"Mul"h	c	Ygradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/sub/Sum:Sum"Sum"QL>model/bert/encoder/layer_10/attention/self/key/BiasAdd:BiasAdd"BiasAdd"NI>model/bert/encoder/layer_10/output/LayerNorm/moments/mean:Mean"Mean"TOEmodel/bert/encoder/layer_1/attention/output/dropout_5/dropout/Mul:Mul"Mul"_ZPgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/sub/Neg:Neg"Neg"LG=model/bert/encoder/layer_4/attention/output/LayerNorm/sub:Sub"Sub"RMCgradient_tape/model/bert/encoder/layer_6/intermediate/mul_3/Mul:Mul"Mul"ojUmodel/bert/encoder/layer_3/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_12:AddN"AddN"RN7Adam/Adam/update_60/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"KF8model/bert/encoder/layer_10/output/dense/BiasAdd:BiasAdd"BiasAdd"gbMmodel/bert/encoder/layer_7/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"|hmodel/bert/encoder/layer_1/attention/output/dropout_5/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"]XMgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/Tile_1:Tile"Tile"RMAmodel/bert/encoder/layer_7/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"VQFmodel/bert/encoder/layer_8/attention/self/dropout_25/dropout/Cast:Cast"Cast"VQGgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul_2/Sum:Sum"Sum"t	o	]gradient_tape/model/bert/encoder/layer_3/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"QL?model/bert/encoder/layer_8/intermediate/Tensordot/MatMul:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/sub:Sub"Sub"MH=model/bert/encoder/layer_1/output/LayerNorm/moments/mean:Mean"Mean">9/model/bert/encoder/layer_5/intermediate/Pow:Mul"Mul"+&Adam/gradients/AddN_10:AddN"AddN"lgWgradient_tape/model/bert/encoder/layer_5/attention/self/transpose_3/transpose:Transpose"	Transpose"c^Imodel/bert/encoder/layer_6/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"R
M
?model/bert/encoder/layer_6/attention/self/query/BiasAdd:BiasAdd"BiasAdd"xs_model/bert/encoder/layer_8/output/dropout_27/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"*%Adam/gradients/AddN_7:AddN"AddN"qm\gradient_tape/model/bert/encoder/layer_11/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"PK=model/bert/encoder/layer_4/attention/self/key/BiasAdd:BiasAdd"BiasAdd"UP8Adam/Adam/update_199/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WR>model/bert/encoder/layer_6/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"^YOgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul/Mul:Mul"Mul"idZgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"UP8Adam/Adam/update_153/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"niTmodel/bert/encoder/layer_10/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ni\gradient_tape/model/bert/encoder/layer_3/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"~yamodel/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"TOEgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/sub/Neg:Neg"Neg"hcVgradient_tape/model/bert/encoder/layer_1/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_50:AddN"AddN"pkXmodel/bert/encoder/layer_9/attention/output/dropout_29/dropout/GreaterEqual:GreaterEqual"GreaterEqual"QLBgradient_tape/model/bert/encoder/layer_11/intermediate/Pow/mul:Mul"Mul"=83EagerLocalExecute: __inference_train_function_19462"0
+
model/bert/embeddings/add:AddV2"AddV2"UP8Adam/Adam/update_132/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faWgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/truediv:Mul"Mul"toWmodel/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"J
E
7model/bert/encoder/layer_0/intermediate/BiasAdd:BiasAdd"BiasAdd"VQGgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul_2/Sum:Sum"Sum"ni\gradient_tape/model/bert/encoder/layer_8/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"toWmodel/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"p;l;[gradient_tape/model/bert/encoder/layer_8/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ojUmodel/bert/encoder/layer_9/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ZUKgradient_tape/model/bert/encoder/layer_6/attention/self/truediv/RealDiv:Mul"Mul"pkWgradient_tape/model/bert/encoder/layer_9/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2")$div_no_nan_1:DivNoNan"DivNoNan"ojUmodel/bert/encoder/layer_5/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"rm[gradient_tape/model/bert/encoder/layer_4/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"T	O	7Adam/Adam/update_73/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_27/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPFgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul/Mul:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul_2/Mul_1:Mul"Mul"KF<model/bert/encoder/layer_6/output/dropout_21/dropout/Mul:Mul"Mul"WR>model/bert/encoder/layer_0/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"TOEgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/sub/Neg:Neg"Neg"R
M
?model/bert/encoder/layer_1/attention/self/value/BiasAdd:BiasAdd"BiasAdd"faNmodel/bert/encoder/layer_5/output/dropout_18/dropout/GreaterEqual:GreaterEqual"GreaterEqual"[VKmodel/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance:Mean"Mean"t	o	]gradient_tape/model/bert/encoder/layer_1/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgWgradient_tape/model/bert/encoder/layer_4/attention/self/transpose_3/transpose:Transpose"	Transpose"PK1Adam/Adam/AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"UPBmodel/bert/encoder/layer_11/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_7/attention/self/transpose_3/transpose:Transpose"	Transpose"S%O%8Adam/Adam/update_168/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG=model/bert/encoder/layer_1/output/dropout_6/dropout/Mul_1:Mul"Mul"hcNmodel/bert/encoder/layer_11/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idOmodel/bert/encoder/layer_7/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_18:AddN"AddN"NI?model/bert/encoder/layer_9/attention/output/LayerNorm/mul_1:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_3/intermediate/Pow/mul_1:Mul"Mul"UP8Adam/Adam/update_166/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhSmodel/bert/encoder/layer_3/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Sgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"T	O	7Adam/Adam/update_97/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SHOH8Adam/Adam/update_112/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"OJ@model/bert/encoder/layer_11/attention/output/LayerNorm/mul_1:Mul"Mul"?:/model/bert/embeddings/dropout/dropout/Cast:Cast"Cast"PK=model/bert/encoder/layer_6/attention/self/key/BiasAdd:BiasAdd"BiasAdd"b]Sgradient_tape/model/bert/encoder/layer_1/attention/output/dropout_5/dropout/Mul:Mul"Mul"pkWgradient_tape/model/bert/encoder/layer_6/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"T
O
?model/bert/encoder/layer_3/attention/self/transpose_1:Transpose"	Transpose"D?5model/bert/encoder/layer_0/attention/self/truediv:Mul"Mul"T	O	Egradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul/Sum:Sum"Sum"^YOgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul/Mul:Mul"Mul"UPFmodel/bert/encoder/layer_4/attention/output/dropout_14/dropout/Mul:Mul"Mul"YTJgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/sub:Sub"Sub"TOEgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/sub/Sum:Sum"Sum"`[?Iterator::Model::ParallelMapV2::Zip[0]::FlatMap[0]::TensorSlice"Iterator::TensorSlice"A<'Adam/Cast/ReadVariableOp:ReadVariableOp"ReadVariableOp"A<1model/bert/encoder/layer_9/intermediate/Tanh:Tanh"Tanh")j%jAdam/gradients/AddN_47:AddN"AddN"83)model/bert/encoder/layer_8/output/Add:Add"Add"94'gradient_tape/model/dense/MatMul:MatMul"MatMul"XSIgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul_2/Mul_1:Mul"Mul":
5
)model/bert/embeddings/LayerNorm/add:AddV2"AddV2"NI?gradient_tape/model/bert/encoder/layer_6/attention/self/sub:Sub"Sub"TOEgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/sub/Neg:Neg"Neg"TOEgradient_tape/model/bert/encoder/layer_2/intermediate/mul_3/Mul_1:Mul"Mul"t
o
Wmodel/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"D?*div_no_nan/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"faNmodel/bert/encoder/layer_6/output/dropout_21/dropout/GreaterEqual:GreaterEqual"GreaterEqual"VQGgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul_1/Mul:Mul"Mul"PK=model/bert/encoder/layer_0/attention/self/key/BiasAdd:BiasAdd"BiasAdd"PKAgradient_tape/model/bert/encoder/layer_5/intermediate/Pow/mul:Mul"Mul"UP8Adam/Adam/update_110/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WRHgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul_2/Sum:Sum"Sum"mhSmodel/bert/encoder/layer_4/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp">9/model/bert/encoder/layer_7/intermediate/mul:Mul"Mul"mhSmodel/bert/encoder/layer_9/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbMmodel/bert/encoder/layer_0/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"NJ4Adam/Adam/update/AssignVariableOp_1:AssignVariableOp"AssignVariableOp"D?5model/bert/encoder/layer_8/output/LayerNorm/mul_2:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"D?3model/bert/encoder/layer_9/intermediate/add_1:AddV2"AddV2"L
G
=model/bert/encoder/layer_2/attention/output/LayerNorm/mul:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul_1/Mul_1:Mul"Mul"OJ@model/bert/encoder/layer_10/attention/output/LayerNorm/mul_2:Mul"Mul"TOAmodel/bert/encoder/layer_6/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"	z	fmodel/bert/encoder/layer_2/attention/self/dropout_7/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"TOEgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul/Mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/sub:Sub"Sub"jeUgradient_tape/model/bert/encoder/layer_5/attention/self/transpose/transpose:Transpose"	Transpose"xs_model/bert/encoder/layer_4/output/dropout_15/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"HC9gradient_tape/model/bert/embeddings/LayerNorm/sub/Neg:Neg"Neg"MH>model/bert/encoder/layer_5/output/dropout_18/dropout/Mul_1:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_2/attention/output/dropout_8/dropout/Mul:Mul"Mul"SN6Adam/Adam/update_5/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"B=3model/bert/encoder/layer_4/output/LayerNorm/sub:Sub"Sub"`[Qgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"pkXmodel/bert/encoder/layer_4/attention/output/dropout_14/dropout/GreaterEqual:GreaterEqual"GreaterEqual"n6j6Wgradient_tape/model/bert/encoder/layer_8/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"E@6model/bert/encoder/layer_10/output/LayerNorm/mul_2:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_9/attention/self/transpose_1/transpose:Transpose"	Transpose"VQGgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul/Sum_1:Sum"Sum"ojUmodel/bert/encoder/layer_1/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"g	b	Wgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"b]Sgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"B=1model/bert/encoder/layer_9/intermediate/add:AddV2"AddV2"vq_gradient_tape/model/bert/encoder/layer_8/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"+&Adam/gradients/AddN_54:AddN"AddN"/*%EagerLocalExecute: FlushSummaryWriter"TOEgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/sub/Sum:Sum"Sum"VQGgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul/Mul_1:Mul"Mul"+&Adam/gradients/AddN_41:AddN"AddN"+&Adam/gradients/AddN_35:AddN"AddN"JE;gradient_tape/model/bert/embeddings/LayerNorm/mul_2/Sum:Sum"Sum"FA5model/bert/encoder/layer_1/output/LayerNorm/add:AddV2"AddV2"pk^gradient_tape/model/bert/encoder/layer_0/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+	&	Adam/gradients/AddN_56:AddN"AddN"jeUgradient_tape/model/bert/encoder/layer_0/attention/self/transpose/transpose:Transpose"	Transpose"FA'AssignAddVariableOp:AssignAddVariableOp"AssignAddVariableOp"SN@model/bert/encoder/layer_11/attention/self/query/BiasAdd:BiasAdd"BiasAdd"LG=model/bert/encoder/layer_11/output/dropout_36/dropout/Mul:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/sub:Sub"Sub"HC7model/bert/encoder/layer_4/output/LayerNorm/add_1:AddV2"AddV2"gbMmodel/bert/encoder/layer_3/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_100/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"fGbGVgradient_tape/model/bert/encoder/layer_6/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"C>4model/bert/encoder/layer_10/output/LayerNorm/mul:Mul"Mul"yt`model/bert/encoder/layer_11/output/dropout_36/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"RMCgradient_tape/model/bert/encoder/layer_3/intermediate/mul_3/Mul:Mul"Mul"D?3model/bert/encoder/layer_7/intermediate/add_1:AddV2"AddV2"ExecutorDoneCallback"XSIgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/Mul:Mul"Mul"V	Q	Ggradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul_2/Sum:Sum"Sum"^YOgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/sub/Sum:Sum"Sum"b]Sgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"RM?model/bert/encoder/layer_9/attention/self/value/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_7/attention/self/transpose_2/transpose:Transpose"	Transpose"RM?model/bert/encoder/layer_2/attention/self/query/BiasAdd:BiasAdd"BiasAdd"QL?model/bert/encoder/layer_5/output/dense/Tensordot/MatMul:MatMul"MatMul"UP8Adam/Adam/update_169/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"VQGgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul/Sum_1:Sum"Sum"J
E
7model/bert/encoder/layer_2/output/dense/BiasAdd:BiasAdd"BiasAdd"*%Adam/gradients/AddN_8:AddN"AddN"eaaaWgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"PKAgradient_tape/model/bert/encoder/layer_4/intermediate/Pow/mul:Mul"Mul"TO7Adam/Adam/update_12/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO?model/bert/encoder/layer_3/attention/self/transpose_2:Transpose"	Transpose"pk^gradient_tape/model/bert/encoder/layer_1/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"+&Adam/gradients/AddN_49:AddN"AddN"[VKgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/Tile:Tile"Tile"LG9model/bert/encoder/layer_3/attention/self/Softmax:Softmax"Softmax"YTJgradient_tape/model/bert/encoder/layer_3/output/dropout_12/dropout/Mul:Mul"Mul"0+!model/dropout_1/dropout/Mul_1:Mul"Mul""EagerExecute: LogicalAnd"8
3
)model/bert/embeddings/LayerNorm/mul_2:Mul"Mul"+&Adam/gradients/AddN_11:AddN"AddN"VQGgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul_1/Mul:Mul"Mul"RM=model/bert/encoder/layer_2/attention/self/transpose:Transpose"	Transpose"qlWmodel/bert/encoder/layer_1/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp">
9
/model/bert/encoder/layer_4/intermediate/mul:Mul"Mul"gbMmodel/bert/encoder/layer_0/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"hcVgradient_tape/model/bert/encoder/layer_9/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"niUgradient_tape/model/bert/encoder/layer_6/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"RM=model/bert/encoder/layer_9/attention/self/transpose:Transpose"	Transpose"HD0Adam/Adam/update/ReadVariableOp_2:ReadVariableOp"ReadVariableOp"<7"Adam/ReadVariableOp:ReadVariableOp"ReadVariableOp"ojWmodel/bert/encoder/layer_1/attention/output/dropout_5/dropout/GreaterEqual:GreaterEqual"GreaterEqual"UPFgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/sub/Sum:Sum"Sum"T	O	7Adam/Adam/update_23/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ZUKgradient_tape/model/bert/encoder/layer_1/attention/self/truediv/RealDiv:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_5/attention/self/Sum:Sum"Sum"[VGgradient_tape/model/bert/encoder/layer_0/intermediate/TanhGrad:TanhGrad"TanhGrad"VQGmodel/bert/encoder/layer_0/attention/output/dropout_2/dropout/Mul_1:Mul"Mul"YTImodel/bert/encoder/layer_10/attention/output/dropout_32/dropout/Cast:Cast"Cast"T
O
Emodel/bert/encoder/layer_2/attention/self/dropout_7/dropout/Mul_1:Mul"Mul"@;1model/bert/encoder/layer_7/intermediate/mul_1:Mul"Mul"	}	imodel/bert/encoder/layer_8/attention/output/dropout_26/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"ojUmodel/bert/encoder/layer_3/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"XS5Iterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat"Iterator::ForeverRepeat"MH>model/bert/encoder/layer_11/attention/output/LayerNorm/mul:Mul"Mul"}imodel/bert/encoder/layer_4/attention/output/dropout_14/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"\-X-Ogradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul/Sum:Sum"Sum"D?5model/bert/encoder/layer_1/output/LayerNorm/mul_1:Mul"Mul"UP8Adam/Adam/update_155/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"@;1model/bert/encoder/layer_9/intermediate/mul_3:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"UP8Adam/Adam/update_162/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_21:AddN"AddN"Adam/Sqrt:Sqrt"Sqrt"gbMmodel/bert/encoder/layer_3/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhSmodel/bert/encoder/layer_7/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"T	O	7Adam/Adam/update_94/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam")P%PAdam/gradients/AddN_38:AddN"AddN"LG=model/bert/encoder/layer_0/attention/output/LayerNorm/mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/Mul:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_5/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"XSHmodel/bert/encoder/layer_9/attention/output/dropout_29/dropout/Cast:Cast"Cast"YTGmodel/bert/encoder/layer_3/attention/self/value/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_20/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Sgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/Mul:Mul"Mul"JE;gradient_tape/model/bert/embeddings/LayerNorm/mul_2/Mul:Mul"Mul"Y
T
@model/bert/encoder/layer_4/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"B=3model/bert/encoder/layer_0/attention/output/Add:Add"Add"R	M	Cgradient_tape/model/bert/encoder/layer_5/intermediate/Pow/mul_1:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"TOEmodel/bert/encoder/layer_2/attention/output/dropout_8/dropout/Mul:Mul"Mul"UP8Adam/Adam/update_191/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ojUmodel/bert/encoder/layer_4/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_136/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"wr^model/bert/encoder/layer_0/output/dropout_3/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"idOmodel/bert/encoder/layer_1/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"rm[gradient_tape/model/bert/encoder/layer_7/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"gbMmodel/bert/embeddings/position_embeddings/Slice/ReadVariableOp:ReadVariableOp"ReadVariableOp"MH=model/bert/encoder/layer_9/output/LayerNorm/moments/mean:Mean"Mean"RrNr7Adam/Adam/update_87/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"YTGmodel/bert/encoder/layer_9/attention/self/query/Tensordot/MatMul:MatMul"MatMul"RM@model/bert/encoder/layer_10/output/dense/Tensordot/MatMul:MatMul"MatMul"vq_gradient_tape/model/bert/encoder/layer_3/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"Y
T
Gmodel/bert/encoder/layer_0/attention/self/value/Tensordot/MatMul:MatMul"MatMul"XSIgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul_2/Mul_1:Mul"Mul"@;1model/bert/encoder/layer_0/intermediate/mul_1:Mul"Mul"=8+gradient_tape/model/dense_1/MatMul_1:MatMul"MatMul"niVmodel/bert/encoder/layer_8/attention/self/dropout_25/dropout/GreaterEqual:GreaterEqual"GreaterEqual"T
O
?model/bert/encoder/layer_5/attention/self/transpose_1:Transpose"	Transpose"TO7Adam/Adam/update_11/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/sub/Neg:Neg"Neg"HC7model/bert/encoder/layer_7/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"TOEgradient_tape/model/bert/encoder/layer_0/intermediate/mul_3/Mul_1:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_1/output/dropout_6/dropout/Mul_2:Mul"Mul"[VImodel/bert/encoder/layer_0/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"pkVmodel/bert/encoder/layer_10/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ZUHmodel/bert/encoder/layer_10/attention/self/query/Tensordot/MatMul:MatMul"MatMul"pk^gradient_tape/model/bert/encoder/layer_5/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"gbUgradient_tape/model/bert/encoder/layer_11/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"JE7model/bert/encoder/layer_7/output/dense/BiasAdd:BiasAdd"BiasAdd"UQHgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul_2/Mul:Mul"Mul"RMAmodel/bert/encoder/layer_9/attention/output/LayerNorm/add_1:AddV2"AddV2"b]Sgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/Mul:Mul"Mul"toWmodel/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"@
;
1model/bert/encoder/layer_2/intermediate/mul_2:Mul"Mul"[VGgradient_tape/model/bert/encoder/layer_3/intermediate/TanhGrad:TanhGrad"TanhGrad"SNDgradient_tape/model/bert/encoder/layer_10/intermediate/mul_1/Mul:Mul"Mul"LG=model/bert/encoder/layer_6/attention/output/LayerNorm/mul:Mul"Mul"i	d	Omodel/bert/encoder/layer_8/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"a\Rgradient_tape/model/bert/encoder/layer_3/attention/self/dropout_10/dropout/Mul:Mul"Mul"A<1model/bert/encoder/layer_0/intermediate/Tanh:Tanh"Tanh"idPmodel/bert/embeddings/dropout/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"+&Adam/gradients/AddN_85:AddN"AddN"D?5model/bert/encoder/layer_5/output/LayerNorm/mul_1:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_2/attention/self/transpose_1/transpose:Transpose"	Transpose"idOmodel/bert/encoder/layer_4/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"yt`gradient_tape/model/bert/embeddings/word_embeddings/embedding_lookup/VariableShape:VariableShape"VariableShape"QL?model/bert/encoder/layer_5/intermediate/Tensordot/MatMul:MatMul"MatMul"a\Rgradient_tape/model/bert/encoder/layer_8/attention/self/dropout_25/dropout/Mul:Mul"Mul"ojWmodel/bert/encoder/layer_2/attention/output/dropout_8/dropout/GreaterEqual:GreaterEqual"GreaterEqual"S>O>8Adam/Adam/update_116/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"SNBmodel/bert/encoder/layer_11/attention/output/LayerNorm/add_1:AddV2"AddV2"hcYgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_4/intermediate/mul_2/Mul:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"X	S	Igradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul_2/Mul_1:Mul"Mul"vq_gradient_tape/model/bert/encoder/layer_1/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"MH>model/bert/encoder/layer_9/output/dropout_30/dropout/Mul_1:Mul"Mul"PKAgradient_tape/model/bert/encoder/layer_8/attention/self/mul_1:Mul"Mul"NI>model/bert/encoder/layer_6/output/dropout_21/dropout/Cast:Cast"Cast"faWgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/truediv:Mul"Mul"lgUgradient_tape/model/bert/encoder/layer_5/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"qlYmodel/bert/encoder/layer_10/attention/output/dropout_32/dropout/GreaterEqual:GreaterEqual"GreaterEqual">9/model/bert/encoder/layer_0/intermediate/mul:Mul"Mul"UP8Adam/Adam/update_113/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG=gradient_tape/model/bert/embeddings/LayerNorm/moments/Mul:Mul"Mul"YTGmodel/bert/encoder/layer_6/attention/self/value/Tensordot/MatMul:MatMul"MatMul"SN6Adam/Adam/update_2/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"J	E	;model/bert/encoder/layer_2/output/dropout_9/dropout/Mul:Mul"Mul"ojUmodel/bert/encoder/layer_1/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"QLAmodel/bert/encoder/layer_7/output/LayerNorm/moments/variance:Mean"Mean"\WJmodel/bert/encoder/layer_11/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"mhXgradient_tape/model/bert/encoder/layer_11/attention/self/transpose_2/transpose:Transpose"	Transpose"JE7model/bert/encoder/layer_5/intermediate/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_5/attention/self/transpose_1/transpose:Transpose"	Transpose"qlWmodel/bert/encoder/layer_5/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"dO`OTgradient_tape/model/bert/encoder/layer_6/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"VQGmodel/bert/encoder/layer_11/attention/self/dropout_34/dropout/Mul_1:Mul"Mul"a\Rgradient_tape/model/bert/encoder/layer_5/attention/self/dropout_16/dropout/Mul:Mul"Mul")$Adam/Adam/update/mul_1:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_9/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"pk^gradient_tape/model/bert/encoder/layer_3/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"TO?model/bert/encoder/layer_6/attention/self/transpose_3:Transpose"	Transpose"`[Qgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"ni\gradient_tape/model/bert/encoder/layer_5/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"T	O	Egradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul/Mul:Mul"Mul"PKAgradient_tape/model/bert/encoder/layer_9/intermediate/Pow/mul:Mul"Mul"XSHmodel/bert/encoder/layer_4/attention/output/dropout_14/dropout/Cast:Cast"Cast"RMAmodel/bert/encoder/layer_6/attention/output/LayerNorm/add_1:AddV2"AddV2"HC7model/bert/encoder/layer_5/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"to]gradient_tape/model/bert/encoder/layer_9/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UP8Adam/Adam/update_143/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"snYmodel/bert/encoder/layer_6/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"B
=
3model/bert/encoder/layer_2/output/LayerNorm/mul:Mul"Mul"b]Pmodel/bert/embeddings/position_embeddings/assert_less_equal/Assert/Assert:Assert"Assert"a\Rgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"bi^iUgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/mul_1:Mul"Mul"LG=model/bert/encoder/layer_5/attention/output/LayerNorm/sub:Sub"Sub"D?5model/bert/encoder/layer_3/output/LayerNorm/mul_2:Mul"Mul"TO7Adam/Adam/update_19/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_131/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_80/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RM;gradient_tape/model/dense_1/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"RMCgradient_tape/model/bert/encoder/layer_2/intermediate/mul_1/Mul:Mul"Mul"WRGmodel/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean:Mean"Mean"+&Adam/gradients/AddN_61:AddN"AddN"lgWgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"VQGgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul/Mul_1:Mul"Mul"HC)AssignAddVariableOp_2:AssignAddVariableOp"AssignAddVariableOp"$EagerExecute: WriteSummary"L
G
=model/bert/encoder/layer_0/attention/output/LayerNorm/sub:Sub"Sub"UP8Adam/Adam/update_170/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"XSIgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/Mul:Mul"Mul"QL?model/bert/encoder/layer_6/intermediate/Tensordot/MatMul:MatMul"MatMul"J
E
7model/bert/encoder/layer_4/output/dense/BiasAdd:BiasAdd"BiasAdd"e`Vgradient_tape/model/bert/encoder/layer_9/attention/output/dropout_29/dropout/Mul_2:Mul"Mul"]XNgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/truediv:Mul"Mul"PK<sparse_categorical_crossentropy/weighted_loss/value:DivNoNan"DivNoNan"lhTmodel/bert/encoder/layer_11/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_99/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gbOmodel/bert/encoder/layer_11/output/dropout_36/dropout/GreaterEqual:GreaterEqual"GreaterEqual"]XNgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/truediv:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_0/attention/self/dropout_1/dropout/Mul_2:Mul"Mul"U	P	Fmodel/bert/encoder/layer_8/attention/output/dropout_26/dropout/Mul:Mul"Mul"hcVgradient_tape/model/bert/encoder/layer_0/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"faTgradient_tape/model/bert/encoder/layer_7/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"d_Ugradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/mul_1:Mul"Mul"RM=model/bert/encoder/layer_3/attention/self/transpose:Transpose"	Transpose"RMCgradient_tape/model/bert/encoder/layer_9/intermediate/Pow/mul_1:Mul"Mul"~
y
amodel/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"UPFmodel/bert/encoder/layer_6/attention/self/dropout_19/dropout/Mul_1:Mul"Mul"	}	imodel/bert/encoder/layer_5/attention/output/dropout_17/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"TO7Adam/Adam/update_44/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"JE;model/bert/encoder/layer_0/output/dropout_3/dropout/Mul:Mul"Mul"faWgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/truediv:Mul"Mul"|hmodel/bert/encoder/layer_2/attention/output/dropout_8/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"j5f5Wgradient_tape/model/bert/encoder/layer_8/attention/self/transpose_3/transpose:Transpose"	Transpose"NI?model/bert/encoder/layer_6/attention/output/LayerNorm/mul_2:Mul"Mul"TO7Adam/Adam/update_22/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlWmodel/bert/encoder/layer_7/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ZUKgradient_tape/model/bert/encoder/layer_9/attention/self/truediv/RealDiv:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul/Mul_1:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/mul_1:Mul"Mul"UP8Adam/Adam/update_144/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`	[	Qgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"YXUXLgradient_tape/model/bert/encoder/layer_5/output/dropout_18/dropout/Mul_2:Mul"Mul"@;1model/bert/encoder/layer_0/intermediate/mul_2:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_8/attention/self/sub:Sub"Sub"VQDgradient_tape/model/bert/encoder/layer_3/intermediate/Pow/Pow:Square"Square"[VKgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/Tile:Tile"Tile"XSIgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul_2/Mul_1:Mul"Mul"PKAgradient_tape/model/bert/embeddings/LayerNorm/moments/truediv:Mul"Mul"[
V
Kmodel/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance:Mean"Mean"WR>model/bert/encoder/layer_3/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"T	O	7Adam/Adam/update_82/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"idOmodel/bert/encoder/layer_2/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"gbXgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/truediv:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"xs_model/bert/encoder/layer_7/output/dropout_24/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"lgZgradient_tape/model/bert/encoder/layer_7/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"ojUmodel/bert/encoder/layer_6/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"RzNzEgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/sub/Sum:Sum"Sum"UP@model/bert/encoder/layer_11/attention/self/transpose_1:Transpose"	Transpose"ID8model/bert/encoder/layer_10/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"TOEgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul/Mul:Mul"Mul"V
Q
Dgradient_tape/model/bert/encoder/layer_0/intermediate/Pow/Pow:Square"Square"VQGmodel/bert/encoder/layer_10/attention/output/dropout_32/dropout/Mul:Mul"Mul"83)model/bert/encoder/layer_0/output/Add:Add"Add"idZgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"'"GatherV2_1:GatherV2"GatherV2"R
M
?model/bert/encoder/layer_8/attention/self/query/BiasAdd:BiasAdd"BiasAdd"LG9model/bert/encoder/layer_8/attention/self/Softmax:Softmax"Softmax"`[Qgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"TO7Adam/Adam/update_24/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"YTGmodel/bert/encoder/layer_3/attention/self/query/Tensordot/MatMul:MatMul"MatMul"UP@model/bert/encoder/layer_10/attention/self/transpose_3:Transpose"	Transpose"VQGgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul/Mul_1:Mul"Mul"a\Rgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"c^Imodel/bert/encoder/layer_5/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"B=3model/bert/encoder/layer_6/attention/output/Add:Add"Add"qlWmodel/bert/encoder/layer_9/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_83:AddN"AddN"^dZdQgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"ZUHmodel/bert/encoder/layer_10/attention/self/value/Tensordot/MatMul:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_9/attention/self/sub:Sub"Sub"w
r
gsparse_categorical_crossentropy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_1:Cast"Cast"+&Adam/gradients/AddN_60:AddN"AddN"UP8Adam/Adam/update_172/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"@;1model/bert/encoder/layer_6/intermediate/mul_2:Mul"Mul"`	[	Qgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"jeUgradient_tape/model/bert/encoder/layer_3/attention/self/transpose/transpose:Transpose"	Transpose"MH=model/bert/encoder/layer_0/output/LayerNorm/moments/mean:Mean"Mean"lgWgradient_tape/model/bert/encoder/layer_1/attention/self/transpose_1/transpose:Transpose"	Transpose"b]Sgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"}imodel/bert/encoder/layer_9/attention/output/dropout_29/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"3. Adam/Adam/update/truediv:RealDiv"RealDiv"B=3model/bert/encoder/layer_2/output/LayerNorm/sub:Sub"Sub"e`Ugradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/Tile:Tile"Tile"ZUKgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/mul_1:Mul"Mul"pkXmodel/bert/encoder/layer_6/attention/output/dropout_20/dropout/GreaterEqual:GreaterEqual"GreaterEqual"HC7model/bert/encoder/layer_9/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"jeUgradient_tape/model/bert/encoder/layer_8/attention/self/transpose/transpose:Transpose"	Transpose"fbNmodel/bert/encoder/layer_10/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"?:'model/lambda/strided_slice:StridedSlice"StridedSlice"ql_gradient_tape/model/bert/encoder/layer_11/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_7/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"qlWmodel/bert/encoder/layer_0/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"M	H	=model/bert/encoder/layer_2/output/dropout_9/dropout/Cast:Cast"Cast"PKAgradient_tape/model/bert/encoder/layer_1/attention/self/mul_1:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/sub/Sum:Sum"Sum"+&Adam/gradients/AddN_30:AddN"AddN"RMCgradient_tape/model/bert/encoder/layer_0/intermediate/mul_2/Mul:Mul"Mul"lgZgradient_tape/model/bert/encoder/layer_3/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"TO7Adam/Adam/update_78/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"pkXmodel/bert/encoder/layer_3/attention/output/dropout_11/dropout/GreaterEqual:GreaterEqual"GreaterEqual"JE7model/bert/encoder/layer_0/output/dense/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"|hmodel/bert/encoder/layer_0/attention/output/dropout_2/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"VQDgradient_tape/model/bert/encoder/layer_6/intermediate/Pow/Pow:Square"Square"JE0Adam/Adam/update/ReadVariableOp_3:ReadVariableOp"ReadVariableOp"U	P	Fmodel/bert/encoder/layer_7/attention/output/dropout_23/dropout/Mul:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/sub/Sum:Sum"Sum"WR>model/bert/encoder/layer_8/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"SNBmodel/bert/encoder/layer_11/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"g c Wgradient_tape/model/bert/encoder/layer_10/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"vq_gradient_tape/model/bert/encoder/layer_9/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"YTJgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/sub:Sub"Sub"B=3model/bert/encoder/layer_9/output/LayerNorm/mul:Mul"Mul"hcVgradient_tape/model/bert/encoder/layer_8/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"WWSWJgradient_tape/model/bert/encoder/layer_5/output/dropout_18/dropout/Mul:Mul"Mul"P
K
=model/bert/encoder/layer_2/attention/self/key/BiasAdd:BiasAdd"BiasAdd"zbmodel/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"e`Ugradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/Tile:Tile"Tile"`[Qgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"PK?model/bert/encoder/layer_6/attention/output/LayerNorm/add:AddV2"AddV2"+&Adam/gradients/AddN_40:AddN"AddN"to]gradient_tape/model/bert/encoder/layer_4/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"R	M	Cgradient_tape/model/bert/encoder/layer_5/intermediate/mul_1/Mul:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul_2/Mul_1:Mul"Mul"rm`gradient_tape/model/bert/encoder/layer_1/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"MH>model/bert/encoder/layer_10/attention/output/LayerNorm/sub:Sub"Sub"WRGmodel/bert/encoder/layer_2/attention/output/dropout_8/dropout/Cast:Cast"Cast"YTGmodel/bert/encoder/layer_7/attention/self/value/Tensordot/MatMul:MatMul"MatMul"PKAgradient_tape/model/bert/encoder/layer_2/intermediate/Pow/mul:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/mul_1:Mul"Mul"hcVgradient_tape/model/bert/encoder/layer_7/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"W
R
>model/bert/encoder/layer_4/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"faWgradient_tape/model/bert/encoder/layer_10/attention/output/dropout_32/dropout/Mul_2:Mul"Mul"pqlq[gradient_tape/model/bert/encoder/layer_5/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"QLAmodel/bert/encoder/layer_9/output/LayerNorm/moments/variance:Mean"Mean" Adam/Cast_1:Cast"Cast"RM=model/bert/encoder/layer_5/attention/self/transpose:Transpose"	Transpose"b]Sgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/Mul:Mul"Mul"a\Rgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"+&Adam/gradients/AddN_52:AddN"AddN"XSIgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/sub:Sub"Sub"zfmodel/bert/encoder/layer_1/attention/self/dropout_4/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform">9/model/bert/encoder/layer_3/intermediate/mul:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_3/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"VQDgradient_tape/model/bert/encoder/layer_8/intermediate/Pow/Pow:Square"Square"xs_model/bert/encoder/layer_6/output/dropout_21/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"H
C
7model/bert/encoder/layer_0/output/LayerNorm/add_1:AddV2"AddV2"[VLgradient_tape/model/bert/encoder/layer_10/attention/self/truediv/RealDiv:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"RM?model/bert/encoder/layer_7/attention/self/value/BiasAdd:BiasAdd"BiasAdd"e`Kmodel/bert/encoder/layer_7/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"B
=
3model/bert/encoder/layer_4/output/LayerNorm/mul:Mul"Mul"qlWmodel/bert/encoder/layer_0/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"XSIgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul_2/Mul_1:Mul"Mul"up^gradient_tape/model/bert/encoder/layer_11/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"MH=model/bert/encoder/layer_7/output/LayerNorm/moments/mean:Mean"Mean"'#Adam/Adam/update/mul_4:Mul"Mul"pkVmodel/bert/encoder/layer_11/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_17:AddN"AddN"mhVgradient_tape/model/bert/encoder/layer_10/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"U	P	Fmodel/bert/encoder/layer_5/attention/output/dropout_17/dropout/Mul:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_3/attention/self/Sum:Sum"Sum"[VLgradient_tape/model/bert/encoder/layer_4/output/dropout_15/dropout/Mul_2:Mul"Mul"to]gradient_tape/model/bert/encoder/layer_0/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TOAmodel/bert/encoder/layer_3/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"`[Qgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"B
=
1model/bert/encoder/layer_2/intermediate/add:AddV2"AddV2"~yamodel/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"g	b	Mmodel/bert/encoder/layer_6/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"}imodel/bert/encoder/layer_6/attention/output/dropout_20/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"KF<model/bert/encoder/layer_7/output/dropout_24/dropout/Mul:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_8/attention/self/Sum:Sum"Sum"{gmodel/bert/encoder/layer_3/attention/self/dropout_10/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"n=j=^gradient_tape/model/bert/encoder/layer_7/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"B=3model/bert/encoder/layer_6/output/LayerNorm/sub:Sub"Sub"`[Qgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"TOEgradient_tape/model/bert/encoder/layer_4/intermediate/mul_3/Mul_1:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_9/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"TOEgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul/Sum:Sum"Sum"'"Adam/truediv:RealDiv"RealDiv"UP8Adam/Adam/update_123/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ojUmodel/bert/encoder/layer_2/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"rm[gradient_tape/model/bert/encoder/layer_6/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"T	O	7Adam/Adam/update_68/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_66:AddN"AddN"QLAmodel/bert/encoder/layer_0/output/LayerNorm/moments/variance:Mean"Mean"UP8Adam/Adam/update_120/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul/Mul:Mul"Mul"YTGmodel/bert/encoder/layer_5/attention/self/query/Tensordot/MatMul:MatMul"MatMul"lgWgradient_tape/model/bert/encoder/layer_3/attention/self/transpose_1/transpose:Transpose"	Transpose"lgUgradient_tape/model/bert/encoder/layer_6/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"KF<model/bert/encoder/layer_9/output/dropout_30/dropout/Mul:Mul"Mul"ZUHmodel/bert/encoder/layer_11/attention/self/value/Tensordot/MatMul:MatMul"MatMul"WRHmodel/bert/encoder/layer_3/attention/output/dropout_11/dropout/Mul_1:Mul"Mul"t	o	]gradient_tape/model/bert/encoder/layer_4/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"lgWgradient_tape/model/bert/encoder/layer_4/attention/self/transpose_2/transpose:Transpose"	Transpose"OJ@gradient_tape/model/bert/encoder/layer_11/attention/self/Sum:Sum"Sum"mhSmodel/bert/encoder/layer_4/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"ojUmodel/bert/encoder/layer_7/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Tgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/Mul:Mul"Mul"UPFgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/sub/Neg:Neg"Neg"ojUmodel/bert/encoder/layer_4/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"[VKgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/Tile:Tile"Tile"hcYgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"gbMmodel/bert/encoder/layer_4/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"[BWBMgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/Tile_1:Tile"Tile"MH>model/bert/encoder/layer_7/output/dropout_24/dropout/Mul_1:Mul"Mul"MH:model/bert/encoder/layer_11/attention/self/Softmax:Softmax"Softmax"faTgradient_tape/model/bert/encoder/layer_2/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"B
=
1model/bert/encoder/layer_4/intermediate/add:AddV2"AddV2"+&Adam/gradients/AddN_16:AddN"AddN"WREmodel/bert/encoder/layer_1/attention/self/key/Tensordot/MatMul:MatMul"MatMul"faWgradient_tape/model/bert/encoder/layer_11/attention/output/dropout_35/dropout/Mul_2:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"F
A
5model/bert/encoder/layer_2/output/LayerNorm/add:AddV2"AddV2"VQGgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul_1/Mul:Mul"Mul"TO7Adam/Adam/update_30/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WRGmodel/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean:Mean"Mean"pkWgradient_tape/model/bert/encoder/layer_0/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"*%Adam/gradients/AddN_1:AddN"AddN"TO?model/bert/encoder/layer_3/attention/self/transpose_3:Transpose"	Transpose"niTmodel/bert/encoder/layer_11/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"QL@model/bert/encoder/layer_10/attention/output/LayerNorm/add:AddV2"AddV2"lgUgradient_tape/model/bert/encoder/layer_8/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"b]Sgradient_tape/model/bert/encoder/layer_11/attention/self/dropout_34/dropout/Mul:Mul"Mul">9/model/bert/encoder/layer_6/intermediate/Pow:Mul"Mul"idOmodel/bert/encoder/layer_9/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"cl_lVgradient_tape/model/bert/encoder/layer_5/attention/output/dropout_17/dropout/Mul_2:Mul"Mul"WREgradient_tape/model/bert/encoder/layer_10/intermediate/Pow/Pow:Square"Square"^YOgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/sub/Neg:Neg"Neg"6
1
'model/bert/embeddings/LayerNorm/mul:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul_2/Mul_1:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul_1/Mul_1:Mul"Mul"QLAmodel/bert/encoder/layer_6/output/LayerNorm/moments/variance:Mean"Mean"t	o	]gradient_tape/model/bert/encoder/layer_2/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"b]Mgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"PK=model/bert/encoder/layer_1/attention/self/key/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_2/attention/self/transpose_2/transpose:Transpose"	Transpose"QL?model/bert/encoder/layer_3/intermediate/Tensordot/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_34:AddN"AddN"^YOgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/sub/Sum:Sum"Sum"pkVmodel/bert/encoder/layer_10/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"qlWmodel/bert/encoder/layer_1/attention/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"MH:model/bert/encoder/layer_10/attention/self/Softmax:Softmax"Softmax"UP8Adam/Adam/update_104/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"eaMmodel/bert/encoder/layer_7/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"Cast_2:Cast"Cast"faVgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/Tile:Tile"Tile"vq_gradient_tape/model/bert/encoder/layer_4/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"VQGgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul/Sum_1:Sum"Sum"X	S	Hmodel/bert/encoder/layer_7/attention/output/dropout_23/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_18/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WRHgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul/Mul_1:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_5/attention/self/mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/sub:Sub"Sub"XSIgradient_tape/model/bert/encoder/layer_2/output/dropout_9/dropout/Mul:Mul"Mul"]XMgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/Tile_1:Tile"Tile"`[Qgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"B=3model/bert/encoder/layer_0/output/LayerNorm/mul:Mul"Mul"rm`gradient_tape/model/bert/encoder/layer_8/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"NI?model/bert/encoder/layer_7/attention/output/LayerNorm/mul_2:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_2/attention/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"R	M	Cmodel/bert/encoder/layer_2/attention/self/dropout_7/dropout/Mul:Mul"Mul"ojUmodel/bert/encoder/layer_1/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"WRHmodel/bert/encoder/layer_8/attention/output/dropout_26/dropout/Mul_1:Mul"Mul"e`Ugradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/Tile:Tile"Tile"p(l([gradient_tape/model/bert/encoder/layer_9/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"PKAgradient_tape/model/bert/encoder/layer_9/attention/self/mul_1:Mul"Mul"VQGmodel/bert/encoder/layer_10/attention/self/dropout_31/dropout/Mul_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul/Mul:Mul"Mul"mhSmodel/bert/encoder/layer_2/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"^_Z_Qgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"[
V
Imodel/bert/encoder/layer_2/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/truediv_1:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_9/attention/self/mul:Mul"Mul"UP8Adam/Adam/update_101/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"A<1model/bert/encoder/layer_6/intermediate/Tanh:Tanh"Tanh"^YOgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/sub/Sum:Sum"Sum"XSIgradient_tape/model/bert/encoder/layer_0/output/dropout_3/dropout/Mul:Mul"Mul"T	O	Egradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul/Sum:Sum"Sum"SNDgradient_tape/model/bert/encoder/layer_10/intermediate/Pow/mul_1:Mul"Mul"VQDgradient_tape/model/bert/encoder/layer_7/intermediate/Pow/Pow:Square"Square"LG=model/bert/encoder/layer_3/attention/output/LayerNorm/sub:Sub"Sub"a\Rgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"UP8Adam/Adam/update_124/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlWmodel/bert/encoder/layer_5/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWgradient_tape/model/bert/encoder/layer_7/attention/self/transpose_1/transpose:Transpose"	Transpose"W
R
Hmodel/bert/encoder/layer_4/attention/output/dropout_14/dropout/Mul_1:Mul"Mul"snYmodel/bert/encoder/layer_4/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"RyNy7Adam/Adam/update_70/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"XS?model/bert/encoder/layer_10/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"TOAmodel/bert/encoder/layer_5/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"XSIgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul_1/Mul_1:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_10/attention/self/dropout_31/dropout/Mul:Mul"Mul"faWgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/truediv:Mul"Mul"TO7Adam/Adam/update_62/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ni\gradient_tape/model/bert/encoder/layer_7/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"JE7model/bert/encoder/layer_3/output/dense/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_6/attention/self/transpose_2/transpose:Transpose"	Transpose"ni\gradient_tape/model/bert/encoder/layer_4/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"NI?model/bert/encoder/layer_9/attention/output/LayerNorm/mul_2:Mul"Mul"TO7Adam/Adam/update_17/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"@
;
1model/bert/encoder/layer_4/intermediate/mul_2:Mul"Mul"+&Adam/gradients/AddN_15:AddN"AddN"hcVgradient_tape/model/bert/encoder/layer_8/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"PKAgradient_tape/model/bert/encoder/layer_7/intermediate/Pow/mul:Mul"Mul"Y
T
Gmodel/bert/encoder/layer_7/attention/self/query/Tensordot/MatMul:MatMul"MatMul"RMAmodel/bert/encoder/layer_5/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"WRHgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul/Sum_1:Sum"Sum"UP8Adam/Adam/update_146/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"PK=model/bert/encoder/layer_8/attention/self/key/BiasAdd:BiasAdd"BiasAdd"SOFgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/sub/Neg:Neg"Neg"TO7Adam/Adam/update_10/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faWgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/truediv:Mul"Mul"e`Vgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/mul_1:Mul"Mul"mhSmodel/bert/encoder/layer_7/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"o	j	Umodel/bert/encoder/layer_8/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"VQGgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/mul_1/Mul:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul_2/Sum:Sum"Sum"b]Mgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad")$Adam/Adam/update/mul_5:Mul"Mul"LG=model/bert/encoder/layer_3/attention/output/LayerNorm/mul:Mul"Mul"a\Rgradient_tape/model/bert/encoder/layer_9/attention/self/dropout_28/dropout/Mul:Mul"Mul"0
+
Adam/Adam/update/Unique:Unique"Unique"B=1model/bert/encoder/layer_6/intermediate/add:AddV2"AddV2"jeUgradient_tape/model/bert/encoder/layer_7/attention/self/transpose/transpose:Transpose"	Transpose"^	Y	Ogradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/sub/Sum:Sum"Sum"qlWmodel/bert/encoder/layer_1/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"mhXgradient_tape/model/bert/encoder/layer_10/attention/self/transpose_2/transpose:Transpose"	Transpose"pk^gradient_tape/model/bert/encoder/layer_7/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"plXmodel/bert/encoder/layer_11/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"QL?model/bert/encoder/layer_7/intermediate/Tensordot/MatMul:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_0/attention/self/sub:Sub"Sub"e`Kmodel/bert/encoder/layer_9/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_185/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"YTJgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul_2/Mul_1:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul/Mul:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul/Mul_1:Mul"Mul"e	`	Mmodel/bert/encoder/layer_2/output/dropout_9/dropout/GreaterEqual:GreaterEqual"GreaterEqual"`[Qgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"WR>model/bert/encoder/layer_1/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"XSIgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul_1/Mul_1:Mul"Mul"TO?model/bert/encoder/layer_5/attention/self/transpose_3:Transpose"	Transpose"+&Adam/gradients/AddN_64:AddN"AddN"`[Qgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"KF<model/bert/encoder/layer_5/output/dropout_18/dropout/Mul:Mul"Mul"WREgradient_tape/model/bert/encoder/layer_11/intermediate/Pow/Pow:Square"Square"NI?model/bert/encoder/layer_3/attention/output/LayerNorm/mul_1:Mul"Mul"r	m	[gradient_tape/model/bert/encoder/layer_1/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ojUmodel/bert/encoder/layer_2/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"A<Iterator::Model::ParallelMapV2"Iterator::ParallelMapV2"S'O'8Adam/Adam/update_167/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"OJ@gradient_tape/model/bert/encoder/layer_10/attention/self/sub:Sub"Sub"VQGgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul_2/Mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"ojUmodel/bert/encoder/layer_8/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"PJLJCgradient_tape/model/bert/encoder/layer_6/intermediate/mul_2/Mul:Mul"Mul"D?5model/bert/encoder/layer_7/output/LayerNorm/mul_1:Mul"Mul"XSHmodel/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean:Mean"Mean"VQGgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul_1/Mul:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_2/attention/self/dropout_7/dropout/Mul_2:Mul"Mul"M
H
>model/bert/encoder/layer_4/output/dropout_15/dropout/Mul_1:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"TO?model/bert/encoder/layer_1/attention/self/transpose_3:Transpose"	Transpose"YTJgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul_1/Mul_1:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/mul_1:Mul"Mul"R
M
?model/bert/encoder/layer_4/attention/self/query/BiasAdd:BiasAdd"BiasAdd"Y
T
Gmodel/bert/encoder/layer_1/attention/self/value/Tensordot/MatMul:MatMul"MatMul">9/model/bert/encoder/layer_8/intermediate/mul:Mul"Mul"TO6Adam/Adam/update/ResourceScatterAdd:ResourceScatterAdd"ResourceScatterAdd"c^Tgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"PK?model/bert/encoder/layer_3/attention/output/LayerNorm/add:AddV2"AddV2"B=2model/bert/encoder/layer_10/intermediate/Tanh:Tanh"Tanh"UP8Adam/Adam/update_130/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WR8Adam/Adam/update/AssignSubVariableOp:AssignSubVariableOp"AssignSubVariableOp"e`Kmodel/bert/encoder/layer_2/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"QL?model/bert/encoder/layer_6/output/dense/Tensordot/MatMul:MatMul"MatMul"ZUKgradient_tape/model/bert/encoder/layer_7/attention/self/truediv/RealDiv:Mul"Mul"pkVmodel/bert/encoder/layer_11/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"UPFmodel/bert/encoder/layer_6/attention/output/dropout_20/dropout/Mul:Mul"Mul"VtRtIgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/moments/sub:Sub"Sub"a\Rgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"UP8Adam/Adam/update_186/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"T
O
?model/bert/encoder/layer_0/attention/self/transpose_2:Transpose"	Transpose"hcVgradient_tape/model/bert/encoder/layer_4/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"VQGgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul_2/Sum:Sum"Sum"QL?model/bert/encoder/layer_8/output/dense/Tensordot/MatMul:MatMul"MatMul"^	Y	Ogradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/truediv_1:Mul"Mul"[VGgradient_tape/model/bert/encoder/layer_2/intermediate/TanhGrad:TanhGrad"TanhGrad"[VImodel/bert/encoder/layer_1/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"lgSgradient_tape/model/bert/encoder/layer_0/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_129/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TOEgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul/Sum:Sum"Sum"RM?model/bert/encoder/layer_4/attention/self/value/BiasAdd:BiasAdd"BiasAdd"ojUmodel/bert/encoder/layer_9/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"\WMgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/truediv:Mul"Mul"_ZPgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/truediv_1:Mul"Mul"c^Imodel/bert/encoder/layer_7/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"XSHmodel/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean:Mean"Mean"\WLgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/Tile:Tile"Tile"SO8Adam/Adam/update_196/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG=model/bert/encoder/layer_8/attention/output/LayerNorm/sub:Sub"Sub"OJ@gradient_tape/model/bert/encoder/layer_10/attention/self/mul:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"UP8Adam/Adam/update_111/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"U	P	Emodel/bert/encoder/layer_2/attention/self/dropout_7/dropout/Cast:Cast"Cast"NI?gradient_tape/model/bert/encoder/layer_3/attention/self/mul:Mul"Mul"idWgradient_tape/model/bert/encoder/layer_11/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO7Adam/Adam/update_91/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"lgWgradient_tape/model/bert/encoder/layer_0/attention/self/transpose_2/transpose:Transpose"	Transpose"niUgradient_tape/model/bert/encoder/layer_2/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"RMCgradient_tape/model/bert/encoder/layer_0/intermediate/mul_3/Mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_9/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"TOEmodel/bert/encoder/layer_1/attention/self/dropout_4/dropout/Mul_1:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul_1/Mul:Mul"Mul"B=3model/bert/encoder/layer_7/output/LayerNorm/sub:Sub"Sub"+&Adam/gradients/AddN_69:AddN"AddN"p	k	Vmodel/bert/encoder/layer_10/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"toZmodel/bert/encoder/layer_11/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"VQGgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul/Mul_1:Mul"Mul"NI?model/bert/encoder/layer_8/attention/output/LayerNorm/mul_1:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_8/attention/self/mul:Mul"Mul"b0^0Ugradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/mul_1:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"zbmodel/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"UP8Adam/Adam/update_125/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"`[Qgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"R
M
Amodel/bert/encoder/layer_2/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"niUgradient_tape/model/bert/encoder/layer_8/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_20:AddN"AddN"b]Mgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"MH=model/bert/encoder/layer_6/output/LayerNorm/moments/mean:Mean"Mean"RMCgradient_tape/model/bert/embeddings/LayerNorm/moments/truediv_1:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_0/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"T	O	7Adam/Adam/update_74/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhSmodel/bert/encoder/layer_0/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"faWgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/truediv:Mul"Mul"wr`gradient_tape/model/bert/encoder/layer_10/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"WREmodel/bert/encoder/layer_9/attention/self/key/Tensordot/MatMul:MatMul"MatMul"HC7model/bert/encoder/layer_3/output/LayerNorm/add_1:AddV2"AddV2"*%Adam/gradients/AddN_5:AddN"AddN"c^Tgradient_tape/model/bert/encoder/layer_4/attention/self/dropout_13/dropout/Mul_2:Mul"Mul"b]Mgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"QLBgradient_tape/model/bert/encoder/layer_10/intermediate/Pow/mul:Mul"Mul"TAPAGgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul_2/Sum:Sum"Sum"XSImodel/bert/encoder/layer_10/attention/output/dropout_32/dropout/Mul_1:Mul"Mul"C>)Adam/Cast_2/ReadVariableOp:ReadVariableOp"ReadVariableOp"D?5model/bert/encoder/layer_7/attention/self/truediv:Mul"Mul"ZUKgradient_tape/model/bert/encoder/layer_2/output/dropout_9/dropout/Mul_2:Mul"Mul"kfVgradient_tape/model/bert/encoder/layer_10/attention/self/transpose/transpose:Transpose"	Transpose"^YOgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/sub/Neg:Neg"Neg"pkWgradient_tape/model/bert/encoder/layer_3/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"hcYgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"[VKmodel/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance:Mean"Mean"^YOgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/truediv_1:Mul"Mul"B=3model/bert/encoder/layer_9/output/LayerNorm/sub:Sub"Sub"+&Adam/gradients/AddN_80:AddN"AddN"Q
L
Amodel/bert/encoder/layer_4/output/LayerNorm/moments/variance:Mean"Mean"lgZgradient_tape/model/bert/encoder/layer_8/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"PK=model/bert/encoder/layer_9/attention/self/key/BiasAdd:BiasAdd"BiasAdd"qlWmodel/bert/encoder/layer_3/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"8
3
)model/bert/encoder/layer_2/output/Add:Add"Add"NI>model/bert/encoder/layer_8/output/dropout_27/dropout/Cast:Cast"Cast"D?3model/bert/encoder/layer_5/intermediate/add_1:AddV2"AddV2"\WMgradient_tape/model/bert/encoder/layer_10/output/dropout_33/dropout/Mul_2:Mul"Mul"+&Adam/gradients/AddN_23:AddN"AddN"[VImodel/bert/encoder/layer_8/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"^cZcQgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"NI?gradient_tape/model/bert/encoder/layer_9/attention/self/Sum:Sum"Sum"+	&	Adam/gradients/AddN_67:AddN"AddN"XSIgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/Mul:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_3/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"b]Mgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"@;1model/bert/encoder/layer_3/intermediate/mul_2:Mul"Mul"jeUgradient_tape/model/bert/encoder/layer_9/attention/self/transpose/transpose:Transpose"	Transpose"h
c
Kmodel/bert/embeddings/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"MH>model/bert/encoder/layer_6/output/dropout_21/dropout/Mul_1:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_6/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"f	a	Wgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/truediv:Mul"Mul"ojUmodel/bert/encoder/layer_2/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/truediv_1:Mul"Mul"lgZgradient_tape/model/bert/encoder/layer_6/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"eaMmodel/bert/encoder/layer_8/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"RM?model/bert/encoder/layer_8/attention/self/value/BiasAdd:BiasAdd"BiasAdd"ql_gradient_tape/model/bert/encoder/layer_10/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"b]Sgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/Mul:Mul"Mul"[VLgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/mul_1:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_4/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"lgUgradient_tape/model/bert/encoder/layer_6/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"snYmodel/bert/encoder/layer_5/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul/Sum:Sum"Sum"p	k	Xmodel/bert/encoder/layer_7/attention/output/dropout_23/dropout/GreaterEqual:GreaterEqual"GreaterEqual"`[Qgradient_tape/model/bert/encoder/layer_1/attention/self/dropout_4/dropout/Mul:Mul"Mul"YTImodel/bert/encoder/layer_11/attention/output/dropout_35/dropout/Cast:Cast"Cast"UP8Adam/Adam/update_192/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TOEgradient_tape/model/bert/encoder/layer_7/intermediate/mul_3/Mul_1:Mul"Mul"TO?model/bert/encoder/layer_7/attention/self/transpose_1:Transpose"	Transpose"TO7Adam/Adam/update_43/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_142/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"% model/dense/Tanh:Tanh"Tanh"@;1model/bert/encoder/layer_3/intermediate/mul_3:Mul"Mul"X	S	Hmodel/bert/encoder/layer_8/attention/output/dropout_26/dropout/Cast:Cast"Cast"TO7Adam/Adam/update_42/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"FunctionRun"`/\/Sgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/moments/sub:Sub"Sub"`[Qgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"idOmodel/bert/encoder/layer_8/intermediate/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"XSIgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/sub:Sub"Sub"UP8Adam/Adam/update_160/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"faTgradient_tape/model/bert/encoder/layer_8/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"JE0model/dense/MatMul/ReadVariableOp:ReadVariableOp"ReadVariableOp"snYmodel/bert/encoder/layer_9/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"[VKmodel/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance:Mean"Mean"lRhR\gradient_tape/model/bert/encoder/layer_6/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YT@model/bert/encoder/layer_8/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_25:AddN"AddN"EagerKernelExecute"D
?
5model/bert/encoder/layer_4/output/LayerNorm/mul_1:Mul"Mul"c^Tgradient_tape/model/bert/encoder/layer_9/attention/self/dropout_28/dropout/Mul_2:Mul"Mul"SNDmodel/bert/encoder/layer_9/attention/self/dropout_28/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_15/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[
V
Imodel/bert/encoder/layer_4/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_35/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"L
G
9model/bert/encoder/layer_2/attention/self/Softmax:Softmax"Softmax"e`Ugradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/Tile:Tile"Tile"`[Qgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"wr`gradient_tape/model/bert/encoder/layer_11/attention/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"A<1model/bert/encoder/layer_3/intermediate/Tanh:Tanh"Tanh"ojUmodel/bert/encoder/layer_5/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"YT@model/bert/encoder/layer_9/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2"^YOgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul/Sum:Sum"Sum"a\AIterator::Model::ParallelMapV2::Zip[1]::ForeverRepeat::FromTensor"Iterator::FromTensor"HC7model/bert/encoder/layer_6/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"YTJgradient_tape/model/bert/encoder/layer_6/output/dropout_21/dropout/Mul:Mul"Mul"rmXmodel/bert/encoder/layer_11/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"`|\|Sgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"ojVgradient_tape/model/bert/encoder/layer_10/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"_ZPgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/sub/Sum:Sum"Sum"D
?
5model/bert/encoder/layer_0/output/LayerNorm/mul_2:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_4/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"UPFgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/sub/Sum:Sum"Sum"HC7model/bert/encoder/layer_8/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"+	&	Adam/gradients/AddN_72:AddN"AddN"SNDmodel/bert/encoder/layer_8/attention/self/dropout_25/dropout/Mul:Mul"Mul"|hmodel/bert/encoder/layer_11/attention/self/dropout_34/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"RMCgradient_tape/model/bert/encoder/layer_1/intermediate/mul_3/Mul:Mul"Mul"B=2model/bert/encoder/layer_11/intermediate/Tanh:Tanh"Tanh"UPFmodel/bert/encoder/layer_5/attention/self/dropout_16/dropout/Mul_1:Mul"Mul"+&Adam/gradients/AddN_39:AddN"AddN"mhVgradient_tape/model/bert/encoder/layer_11/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"c^Imodel/bert/encoder/layer_9/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"LG=gradient_tape/model/bert/embeddings/dropout/dropout/Mul_2:Mul"Mul"?:0model/bert/encoder/layer_10/intermediate/mul:Mul"Mul"UP8Adam/Adam/update_189/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"\XNgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/Tile_1:Tile"Tile"HC7model/bert/encoder/layer_8/output/LayerNorm/add_1:AddV2"AddV2"+&Adam/gradients/AddN_13:AddN"AddN"+&Adam/gradients/AddN_75:AddN"AddN"YTJgradient_tape/model/bert/encoder/layer_8/output/dropout_27/dropout/Mul:Mul"Mul"r	m	Xmodel/bert/encoder/layer_10/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"+&Adam/gradients/AddN_62:AddN"AddN"WRGmodel/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean:Mean"Mean"ni\gradient_tape/model/bert/encoder/layer_9/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"YTJgradient_tape/model/bert/encoder/layer_4/output/dropout_15/dropout/Mul:Mul"Mul"JE0Adam/Adam/update/ReadVariableOp_1:ReadVariableOp"ReadVariableOp")$EagerCopyToDeviceAndAddCacheKey"+&Adam/gradients/AddN_84:AddN"AddN"lgSgradient_tape/model/bert/encoder/layer_9/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"niVmodel/bert/encoder/layer_9/attention/self/dropout_28/dropout/GreaterEqual:GreaterEqual"GreaterEqual"+&Adam/gradients/AddN_29:AddN"AddN"toWmodel/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"lgSgradient_tape/model/bert/encoder/layer_7/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"XSIgradient_tape/model/bert/encoder/layer_1/output/dropout_6/dropout/Mul:Mul"Mul"e	`	Ugradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/Tile:Tile"Tile"KF<model/bert/encoder/layer_8/output/dropout_27/dropout/Mul:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/sub/Neg:Neg"Neg"XSIgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul_1/Mul_1:Mul"Mul"l8h8\gradient_tape/model/bert/encoder/layer_8/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"up^gradient_tape/model/bert/encoder/layer_11/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"C>2model/bert/encoder/layer_10/intermediate/add:AddV2"AddV2"c^Tgradient_tape/model/bert/encoder/layer_7/attention/self/dropout_22/dropout/Mul_2:Mul"Mul"mhSmodel/bert/encoder/layer_1/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"niUgradient_tape/model/bert/encoder/layer_1/attention/self/MatMul_1/MatMul:BatchMatMulV2"BatchMatMulV2"D
?
3model/bert/encoder/layer_2/intermediate/add_1:AddV2"AddV2"lgSgradient_tape/model/bert/encoder/layer_8/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_28:AddN"AddN"a\Rgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"@;1model/bert/encoder/layer_8/intermediate/mul_2:Mul"Mul"NI?gradient_tape/model/bert/embeddings/position_embeddings/Pad:Pad"Pad"NI?gradient_tape/model/bert/embeddings/LayerNorm/moments/mul_1:Mul"Mul"T	O	7Adam/Adam/update_21/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Sgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"D?5model/bert/encoder/layer_3/output/LayerNorm/mul_1:Mul"Mul"D?5model/bert/encoder/layer_5/attention/self/truediv:Mul"Mul"oj]gradient_tape/model/bert/encoder/layer_11/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"ni\gradient_tape/model/bert/encoder/layer_4/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"c^Imodel/bert/encoder/layer_3/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"b]Sgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"MH>model/bert/encoder/layer_11/attention/output/LayerNorm/sub:Sub"Sub"e`Kmodel/bert/encoder/layer_8/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"RINIEgradient_tape/model/bert/encoder/layer_6/intermediate/mul_3/Mul_1:Mul"Mul"OJ@model/bert/encoder/layer_10/attention/output/LayerNorm/mul_1:Mul"Mul"B=3model/bert/encoder/layer_7/attention/output/Add:Add"Add"`[Qgradient_tape/model/bert/encoder/layer_2/attention/self/dropout_7/dropout/Mul:Mul"Mul"[VLgradient_tape/model/bert/encoder/layer_9/output/dropout_30/dropout/Mul_2:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/sub:Sub"Sub"gbWgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"e`Vgradient_tape/model/bert/encoder/layer_6/attention/output/dropout_20/dropout/Mul_2:Mul"Mul"@;1model/bert/encoder/layer_1/intermediate/mul_1:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_5/intermediate/mul_3/Mul:Mul"Mul"to]gradient_tape/model/bert/encoder/layer_2/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"NI?model/bert/encoder/layer_5/attention/output/LayerNorm/mul_1:Mul"Mul"\WMgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/truediv:Mul"Mul"RM@model/bert/encoder/layer_10/intermediate/Tensordot/MatMul:MatMul"MatMul"lgWgradient_tape/model/bert/encoder/layer_0/attention/self/transpose_3/transpose:Transpose"	Transpose"Y
T
Gmodel/bert/encoder/layer_6/attention/self/query/Tensordot/MatMul:MatMul"MatMul"XSIgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/sub:Sub"Sub"WREmodel/bert/encoder/layer_4/attention/self/key/Tensordot/MatMul:MatMul"MatMul"W
R
Emodel/bert/encoder/layer_3/attention/self/key/Tensordot/MatMul:MatMul"MatMul"toWmodel/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"hcXgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"\	W	Mgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/truediv:Mul"Mul"RMAmodel/bert/encoder/layer_8/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"ak]kTgradient_tape/model/bert/encoder/layer_5/attention/output/dropout_17/dropout/Mul:Mul"Mul"Adam/sub:Sub"Sub"VQGgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul_1/Mul:Mul"Mul"Adam/sub_2:Sub"Sub"T	O	7Adam/Adam/update_40/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_65:AddN"AddN"e`Vgradient_tape/model/bert/encoder/layer_3/attention/output/dropout_11/dropout/Mul_2:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul_1/Mul:Mul"Mul"B=3model/bert/encoder/layer_1/attention/output/Add:Add"Add"gbUgradient_tape/model/bert/encoder/layer_11/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"<
7
+model/bert/embeddings/LayerNorm/add_1:AddV2"AddV2"A<1model/bert/encoder/layer_8/intermediate/Tanh:Tanh"Tanh"pk^gradient_tape/model/bert/encoder/layer_6/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"T	O	Egradient_tape/model/bert/encoder/layer_1/output/LayerNorm/sub/Neg:Neg"Neg"e`Kmodel/bert/encoder/layer_0/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/sub/Sum:Sum"Sum"idWgradient_tape/model/bert/encoder/layer_11/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"95)gradient_tape/model/dense/MatMul_1:MatMul"MatMul"HC7model/bert/encoder/layer_3/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"gbMmodel/bert/encoder/layer_8/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"TO7Adam/Adam/update_84/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"b]Mgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"`[Qgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"_ZPgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/sub/Neg:Neg"Neg"lgSgradient_tape/model/bert/encoder/layer_4/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"e`Ugradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/Tile:Tile"Tile"m	h	Umodel/bert/encoder/layer_2/attention/self/dropout_7/dropout/GreaterEqual:GreaterEqual"GreaterEqual"jeUgradient_tape/model/bert/encoder/layer_1/attention/self/transpose/transpose:Transpose"	Transpose"WRGmodel/bert/encoder/layer_11/attention/self/dropout_34/dropout/Cast:Cast"Cast"UP8Adam/Adam/update_165/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"VQGgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul_2/Mul:Mul"Mul"TOAmodel/bert/encoder/layer_7/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"ZUKgradient_tape/model/bert/encoder/layer_2/attention/self/truediv/RealDiv:Mul"Mul"+&Adam/gradients/AddN_27:AddN"AddN"	Sum_2:Sum"Sum"WRGmodel/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean:Mean"Mean"X	S	Hmodel/bert/encoder/layer_5/attention/output/dropout_17/dropout/Cast:Cast"Cast"lgZgradient_tape/model/bert/encoder/layer_0/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"faNmodel/bert/encoder/layer_3/output/dropout_12/dropout/GreaterEqual:GreaterEqual"GreaterEqual"j7f7Wgradient_tape/model/bert/encoder/layer_8/attention/self/transpose_2/transpose:Transpose"	Transpose"c^Tgradient_tape/model/bert/encoder/layer_9/attention/output/dropout_29/dropout/Mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_8/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"TOEgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/sub/Sum:Sum"Sum"@;1model/bert/encoder/layer_5/intermediate/mul_1:Mul"Mul"RZNZ7Adam/Adam/update_96/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VKmodel/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance:Mean"Mean"UP8Adam/Adam/update_139/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO7Adam/Adam/update_76/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"'"EagerLocalExecute: LogicalAnd"R
M
?model/bert/encoder/layer_7/attention/self/query/BiasAdd:BiasAdd"BiasAdd"ni\gradient_tape/model/bert/encoder/layer_9/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"RMCmodel/bert/encoder/layer_0/attention/self/dropout_1/dropout/Mul:Mul"Mul"QLAgradient_tape/model/bert/embeddings/LayerNorm/moments/Tile_1:Tile"Tile"R
M
Amodel/bert/encoder/layer_4/attention/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"W
R
Gmodel/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean:Mean"Mean"to]gradient_tape/model/bert/encoder/layer_9/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"QLBgradient_tape/model/bert/encoder/layer_11/attention/self/mul_1:Mul"Mul"TOAmodel/bert/encoder/layer_1/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"rmXmodel/bert/encoder/layer_10/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"[VKmodel/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance:Mean"Mean"a\Rgradient_tape/model/bert/encoder/layer_4/attention/self/dropout_13/dropout/Mul:Mul"Mul"MH=model/bert/encoder/layer_0/output/dropout_3/dropout/Cast:Cast"Cast"gbMmodel/bert/encoder/layer_1/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"MH>model/bert/encoder/layer_8/output/dropout_27/dropout/Mul_1:Mul"Mul"to]gradient_tape/model/bert/encoder/layer_6/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"ni\gradient_tape/model/bert/encoder/layer_1/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"mhSmodel/bert/encoder/layer_6/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"RDNDEgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/mul/Mul:Mul"Mul"UP8Adam/Adam/update_149/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"VQGgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul/Mul_1:Mul"Mul"A
<
1model/bert/encoder/layer_4/intermediate/Tanh:Tanh"Tanh"e`Ugradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/Tile:Tile"Tile"_ZPgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul/Sum:Sum"Sum"UP@model/bert/encoder/layer_10/attention/self/transpose_1:Transpose"	Transpose"LG2model/dense_1/MatMul/ReadVariableOp:ReadVariableOp"ReadVariableOp"WREmodel/bert/encoder/layer_0/attention/self/key/Tensordot/MatMul:MatMul"MatMul"TO7Adam/Adam/update_61/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_46:AddN"AddN"VQGgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul_2/Mul:Mul"Mul"NI>model/bert/encoder/layer_11/output/LayerNorm/moments/mean:Mean"Mean"WREmodel/bert/encoder/layer_7/attention/self/key/Tensordot/MatMul:MatMul"MatMul"faLmodel/bert/encoder/layer_10/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"RMCgradient_tape/model/bert/encoder/layer_8/intermediate/mul_3/Mul:Mul"Mul"faVgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/Tile:Tile"Tile"mhSmodel/bert/encoder/layer_3/attention/self/key/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"D?5model/bert/encoder/layer_9/attention/self/truediv:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul/Sum:Sum"Sum"cf_fUgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/moments/Tile:Tile"Tile"JE7model/bert/encoder/layer_9/intermediate/BiasAdd:BiasAdd"BiasAdd"pk^gradient_tape/model/bert/encoder/layer_1/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"to]gradient_tape/model/bert/encoder/layer_8/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"l	g	Wgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"\WMgradient_tape/model/bert/encoder/layer_2/output/LayerNorm/moments/truediv:Mul"Mul">9/model/bert/encoder/layer_5/intermediate/mul:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_8/intermediate/mul_2/Mul:Mul"Mul"+&Adam/gradients/AddN_76:AddN"AddN"tf.constant")$Adam/Adam/update/mul_2:Mul"Mul"gbWgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"mhUmodel/bert/encoder/layer_0/attention/self/dropout_1/dropout/GreaterEqual:GreaterEqual"GreaterEqual"b]Sgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"TO?model/bert/encoder/layer_4/attention/self/transpose_1:Transpose"	Transpose"[VLgradient_tape/model/bert/encoder/layer_6/output/dropout_21/dropout/Mul_2:Mul"Mul"pk^gradient_tape/model/bert/encoder/layer_1/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"T	O	7Adam/Adam/update_39/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ojUmodel/bert/encoder/layer_7/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Imodel/bert/encoder/layer_0/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"rm`gradient_tape/model/bert/encoder/layer_9/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lgWgradient_tape/model/bert/encoder/layer_6/attention/self/transpose_1/transpose:Transpose"	Transpose"UP8Adam/Adam/update_173/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"LG9model/bert/encoder/layer_9/attention/self/Softmax:Softmax"Softmax"ZUKgradient_tape/model/bert/encoder/layer_4/attention/self/truediv/RealDiv:Mul"Mul"lgSgradient_tape/model/bert/encoder/layer_1/attention/self/MatMul/MatMul:BatchMatMulV2"BatchMatMulV2"9
4
)sparse_categorical_crossentropy/Cast:Cast"Cast"pk^gradient_tape/model/bert/encoder/layer_6/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_5/attention/self/sub:Sub"Sub"*%Adam/gradients/AddN_6:AddN"AddN"TO7Adam/Adam/update_77/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"QLAmodel/bert/encoder/layer_8/output/LayerNorm/moments/variance:Mean"Mean"WRGmodel/bert/encoder/layer_0/attention/output/dropout_2/dropout/Cast:Cast"Cast"+&Adam/Adam/update/add:AddV2"AddV2"p	k	Xmodel/bert/encoder/layer_8/attention/output/dropout_26/dropout/GreaterEqual:GreaterEqual"GreaterEqual"qlWmodel/bert/encoder/layer_2/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWgradient_tape/model/bert/encoder/layer_4/attention/self/transpose_1/transpose:Transpose"	Transpose"]XMgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/Tile_1:Tile"Tile"JE7model/bert/encoder/layer_4/intermediate/BiasAdd:BiasAdd"BiasAdd"g"c"Wgradient_tape/model/bert/encoder/layer_10/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"B=3model/bert/encoder/layer_6/output/LayerNorm/mul:Mul"Mul"UP8Adam/Adam/update_177/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"RMCgradient_tape/model/bert/encoder/layer_3/intermediate/mul_2/Mul:Mul"Mul"[VLgradient_tape/model/bert/encoder/layer_8/output/dropout_27/dropout/Mul_2:Mul"Mul"ID8model/bert/encoder/layer_11/output/LayerNorm/add_1:AddV2"AddV2"^QZQQgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"TO?model/bert/encoder/layer_9/attention/self/transpose_1:Transpose"	Transpose"W
R
>model/bert/encoder/layer_2/attention/self/MatMul:BatchMatMulV2"BatchMatMulV2"+&Adam/gradients/AddN_48:AddN"AddN">9/model/bert/encoder/layer_7/intermediate/Pow:Mul"Mul"'"ValidateInputTypeAndPlacement"lgWgradient_tape/model/bert/encoder/layer_1/attention/self/transpose_2/transpose:Transpose"	Transpose"VQGgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul_2/Mul:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_0/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"83)model/bert/encoder/layer_1/output/Add:Add"Add"hcVgradient_tape/model/bert/encoder/layer_4/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"@;1model/bert/encoder/layer_5/intermediate/mul_3:Mul"Mul"gbUgradient_tape/model/bert/encoder/layer_10/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"'"Adam/Adam/update/mul:Mul"Mul"R
M
=model/bert/encoder/layer_8/attention/self/transpose:Transpose"	Transpose"UP8Adam/Adam/update_126/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"VQDgradient_tape/model/bert/encoder/layer_4/intermediate/Pow/Pow:Square"Square"ojUmodel/bert/encoder/layer_2/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"PKAgradient_tape/model/bert/encoder/layer_7/attention/self/mul_1:Mul"Mul"L
G
9model/bert/encoder/layer_4/attention/self/Softmax:Softmax"Softmax"FA5model/bert/embeddings/position_embeddings/Slice:Slice"Slice"TO?model/bert/encoder/layer_6/attention/self/transpose_1:Transpose"	Transpose"mhXgradient_tape/model/bert/encoder/layer_10/attention/self/transpose_3/transpose:Transpose"	Transpose"`	[	Qgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul_2/Sum:Sum"Sum"lgUgradient_tape/model/bert/encoder/layer_9/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"VsRsIgradient_tape/model/bert/encoder/layer_4/output/LayerNorm/mul_1/Mul_1:Mul"Mul"snagradient_tape/model/bert/encoder/layer_11/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"+&Adam/gradients/AddN_57:AddN"AddN"]	X	Mgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/moments/Tile_1:Tile"Tile"UPEmodel/bert/encoder/layer_1/attention/self/dropout_4/dropout/Cast:Cast"Cast"^YOgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/sub/Neg:Neg"Neg"UP8Adam/Adam/update_121/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam">9/model/bert/encoder/layer_1/intermediate/Pow:Mul"Mul"mhXgradient_tape/model/bert/encoder/layer_11/attention/self/transpose_1/transpose:Transpose"	Transpose"Q
L
?model/bert/encoder/layer_0/intermediate/Tensordot/MatMul:MatMul"MatMul"MH=model/bert/encoder/layer_8/output/LayerNorm/moments/mean:Mean"Mean"niUgradient_tape/model/bert/encoder/layer_5/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"R	M	Cgradient_tape/model/bert/encoder/layer_1/intermediate/mul_2/Mul:Mul"Mul"c^Imodel/bert/encoder/layer_8/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"lgWgradient_tape/model/bert/encoder/layer_9/attention/self/transpose_3/transpose:Transpose"	Transpose"up^gradient_tape/model/bert/encoder/layer_10/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"UQHgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul_2/Sum:Sum"Sum"RMAmodel/bert/encoder/layer_4/attention/output/LayerNorm/add_1:AddV2"AddV2"?:0model/bert/encoder/layer_11/intermediate/Pow:Mul"Mul"[VGgradient_tape/model/bert/encoder/layer_9/intermediate/TanhGrad:TanhGrad"TanhGrad"d_Ugradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/mul_1:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_10/attention/output/dropout_32/dropout/Mul:Mul"Mul"TO7Adam/Adam/update_65/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP8Adam/Adam/update_138/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Adam/add:AddV2"AddV2"o	j	Umodel/bert/encoder/layer_9/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"rm`gradient_tape/model/bert/encoder/layer_3/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TO?model/bert/encoder/layer_0/attention/self/transpose_1:Transpose"	Transpose"^YOgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/truediv_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_8/intermediate/mul_3/Mul_1:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/mul/Mul:Mul"Mul"LG=model/bert/encoder/layer_7/attention/output/LayerNorm/mul:Mul"Mul" TFE_DeleteTensorHandle"ZUKgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/mul_1:Mul"Mul"JE7model/bert/encoder/layer_8/intermediate/BiasAdd:BiasAdd"BiasAdd">9/model/bert/encoder/layer_1/intermediate/mul:Mul"Mul"i	d	Omodel/bert/encoder/layer_7/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"wr_gradient_tape/model/bert/embeddings/word_embeddings/embedding_lookup/strided_slice:StridedSlice"StridedSlice"ojWmodel/bert/encoder/layer_10/attention/self/dropout_31/dropout/GreaterEqual:GreaterEqual"GreaterEqual"R?N?Egradient_tape/model/bert/encoder/layer_6/output/LayerNorm/sub/Neg:Neg"Neg"ZUKgradient_tape/model/bert/encoder/layer_0/attention/self/truediv/RealDiv:Mul"Mul"mhSmodel/bert/encoder/layer_8/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_148/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"]XMgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/Tile_1:Tile"Tile"pkVmodel/bert/encoder/layer_11/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idOmodel/bert/encoder/layer_3/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"83)model/bert/encoder/layer_5/output/Add:Add"Add"ni\gradient_tape/model/bert/encoder/layer_2/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"faTgradient_tape/model/bert/encoder/layer_9/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"ZUKgradient_tape/model/bert/encoder/layer_8/attention/self/truediv/RealDiv:Mul"Mul")$EagerLocalExecute: WriteSummary"M
H
=model/bert/encoder/layer_2/output/LayerNorm/moments/mean:Mean"Mean"*%Adam/gradients/AddN_3:AddN"AddN"YT@model/bert/encoder/layer_0/attention/self/MatMul_1:BatchMatMulV2"BatchMatMulV2">9/gradient_tape/model/bert/embeddings/add/Sum:Sum"Sum"UP@model/bert/encoder/layer_11/attention/self/transpose_2:Transpose"	Transpose"gbMmodel/bert/encoder/layer_1/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp">
9
/model/bert/encoder/layer_2/intermediate/mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_4/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"`[Qgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul_2/Mul:Mul"Mul"&!IteratorGetNextOp::DoCompute"LG=model/bert/encoder/layer_1/attention/output/LayerNorm/mul:Mul"Mul"ojUmodel/bert/encoder/layer_5/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"@;1model/bert/encoder/layer_9/intermediate/mul_1:Mul"Mul"jeUgradient_tape/model/bert/encoder/layer_4/attention/self/transpose/transpose:Transpose"	Transpose"NI>model/bert/encoder/layer_7/output/dropout_24/dropout/Cast:Cast"Cast"D?5model/bert/encoder/layer_8/output/LayerNorm/mul_1:Mul"Mul"lgWgradient_tape/model/bert/encoder/layer_5/attention/self/transpose_2/transpose:Transpose"	Transpose"ojUmodel/bert/encoder/layer_4/attention/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"PLLLCgradient_tape/model/bert/encoder/layer_6/intermediate/mul_1/Mul:Mul"Mul"+&Adam/gradients/AddN_22:AddN"AddN"PKAgradient_tape/model/bert/encoder/layer_5/attention/self/mul_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_9/intermediate/mul_3/Mul_1:Mul"Mul"M
H
=model/bert/encoder/layer_4/output/LayerNorm/moments/mean:Mean"Mean"XSIgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul_1/Mul_1:Mul"Mul"mhXgradient_tape/model/bert/encoder/layer_11/attention/self/transpose_3/transpose:Transpose"	Transpose"HC)AssignAddVariableOp_1:AssignAddVariableOp"AssignAddVariableOp"gbWgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"TO?model/bert/encoder/layer_0/attention/self/transpose_3:Transpose"	Transpose"\WMgradient_tape/model/bert/encoder/layer_11/output/dropout_36/dropout/Mul_2:Mul"Mul"hcYgradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul:Mul"Mul"TO?model/bert/encoder/layer_7/attention/self/transpose_3:Transpose"	Transpose"lgWgradient_tape/model/bert/encoder/layer_8/attention/self/transpose_1/transpose:Transpose"	Transpose"OJ@gradient_tape/model/bert/encoder/layer_11/attention/self/mul:Mul"Mul"ojUmodel/bert/encoder/layer_4/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"niVmodel/bert/encoder/layer_6/attention/self/dropout_19/dropout/GreaterEqual:GreaterEqual"GreaterEqual"mhSmodel/bert/encoder/layer_6/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"B=3model/bert/encoder/layer_9/attention/output/Add:Add"Add"RMCgradient_tape/model/bert/encoder/layer_8/intermediate/Pow/mul_1:Mul"Mul"RnNn7Adam/Adam/update_90/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UP@model/bert/encoder/layer_10/attention/self/transpose_2:Transpose"	Transpose"b]Mgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"VQGgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul_2/Mul:Mul"Mul"r	m	[gradient_tape/model/bert/encoder/layer_2/attention/self/key/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"RMCgradient_tape/model/bert/encoder/layer_2/intermediate/Pow/mul_1:Mul"Mul"JE7model/bert/encoder/layer_5/output/dense/BiasAdd:BiasAdd"BiasAdd"V	Q	Ggradient_tape/model/bert/encoder/layer_3/output/LayerNorm/mul/Mul_1:Mul"Mul"VQGgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul/Sum_1:Sum"Sum" EagerExecute: Identity"+&Adam/gradients/AddN_68:AddN"AddN"ojVgradient_tape/model/bert/encoder/layer_11/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"LG9model/bert/encoder/layer_0/attention/self/Softmax:Softmax"Softmax"YT@model/dropout/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"D?5model/bert/encoder/layer_4/output/LayerNorm/mul_2:Mul"Mul"UP8Adam/Adam/update_105/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VLgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/mul_1:Mul"Mul"T	O	Egradient_tape/model/bert/encoder/layer_1/intermediate/mul_3/Mul_1:Mul"Mul":5IteratorGetNext:IteratorGetNext"IteratorGetNext"UP8Adam/Adam/update_147/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"YTJgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/moments/Mul:Mul"Mul"FB.Adam/Adam/update/ReadVariableOp:ReadVariableOp"ReadVariableOp"VQGgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul/Sum_1:Sum"Sum"WRGmodel/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean:Mean"Mean"lgUgradient_tape/model/bert/encoder/layer_3/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_16/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"<
7
+model/bert/embeddings/LayerNorm/Rsqrt:Rsqrt"Rsqrt"c^Ngradient_tape/model/bert/encoder/layer_11/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"+&Adam/gradients/AddN_31:AddN"AddN"XSIgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul_2/Mul_1:Mul"Mul"XSIgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/moments/sub:Sub"Sub"XSFmodel/bert/encoder/layer_10/attention/self/key/Tensordot/MatMul:MatMul"MatMul"pkWgradient_tape/model/bert/encoder/layer_2/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"p	k	Xmodel/bert/encoder/layer_5/attention/output/dropout_17/dropout/GreaterEqual:GreaterEqual"GreaterEqual"UP8Adam/Adam/update_195/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"TO?model/bert/encoder/layer_5/attention/self/transpose_2:Transpose"	Transpose"V*R*Igradient_tape/model/bert/encoder/layer_8/output/LayerNorm/mul_1/Mul_1:Mul"Mul"UPFmodel/bert/encoder/layer_7/attention/self/dropout_22/dropout/Mul_1:Mul"Mul"b]Sgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"UP8Adam/Adam/update_137/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"ArgMax:ArgMax"ArgMax"snYmodel/bert/encoder/layer_3/attention/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"fYbYVgradient_tape/model/bert/encoder/layer_5/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"TOAmodel/bert/encoder/layer_9/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"V
Q
Gmodel/bert/encoder/layer_2/attention/output/dropout_8/dropout/Mul_1:Mul"Mul"QL?model/bert/encoder/layer_7/output/dense/Tensordot/MatMul:MatMul"MatMul"+&LogicalAnd:LogicalAnd"
LogicalAnd"VQGgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul/Mul_1:Mul"Mul"\WMgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/truediv:Mul"Mul"JE;gradient_tape/model/bert/embeddings/LayerNorm/mul/Sum_1:Sum"Sum"YTGmodel/bert/encoder/layer_2/attention/self/query/Tensordot/MatMul:MatMul"MatMul"VQGgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul_2/Sum:Sum"Sum"hcTgradient_tape/model/bert/embeddings/word_embeddings/embedding_lookup/concat:ConcatV2"ConcatV2"FA5model/bert/encoder/layer_5/output/LayerNorm/add:AddV2"AddV2"b]Sgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"up^gradient_tape/model/bert/encoder/layer_10/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"H
C
7model/bert/encoder/layer_2/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"1,!model/dropout_1/dropout/Cast:Cast"Cast"NI?model/bert/encoder/layer_5/attention/output/LayerNorm/mul_2:Mul"Mul"+&Adam/gradients/AddN_36:AddN"AddN"W
R
Gmodel/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean:Mean"Mean"RM?model/bert/encoder/layer_3/attention/self/value/BiasAdd:BiasAdd"BiasAdd"T	O	7Adam/Adam/update_55/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"^YOgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/mul/Sum:Sum"Sum"R{N{7Adam/Adam/update_67/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Adam/sub_1:Sub"Sub"WRHgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul_1/Mul:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/moments/mul_1:Mul"Mul"R	M	Cgradient_tape/model/bert/encoder/layer_1/intermediate/Pow/mul_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/sub/Sum:Sum"Sum"to]gradient_tape/model/bert/encoder/layer_6/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"c^Tgradient_tape/model/bert/encoder/layer_4/attention/output/dropout_14/dropout/Mul:Mul"Mul"QL?model/bert/encoder/layer_1/output/dense/Tensordot/MatMul:MatMul"MatMul"A<2model/bert/encoder/layer_11/intermediate/mul_1:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/sub/Sum:Sum"Sum">
9
/model/bert/encoder/layer_4/intermediate/Pow:Mul"Mul"RM?model/bert/encoder/layer_9/attention/self/query/BiasAdd:BiasAdd"BiasAdd"XSIgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/Mul:Mul"Mul"JE;gradient_tape/model/bert/embeddings/dropout/dropout/Mul:Mul"Mul"oj]gradient_tape/model/bert/encoder/layer_11/attention/self/query/Tensordot/MatMul/MatMul:MatMul"MatMul"UP8Adam/Adam/update_145/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"jefeWgradient_tape/model/bert/encoder/layer_5/attention/output/LayerNorm/RsqrtGrad:RsqrtGrad"	RsqrtGrad"YTGmodel/bert/encoder/layer_5/attention/self/value/Tensordot/MatMul:MatMul"MatMul"D?*div_no_nan_1/ReadVariableOp:ReadVariableOp"ReadVariableOp"RM@model/bert/encoder/layer_11/output/dense/Tensordot/MatMul:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_0/attention/self/dropout_1/dropout/Mul:Mul"Mul"SNDmodel/bert/encoder/layer_7/attention/self/dropout_22/dropout/Mul:Mul"Mul"ni\gradient_tape/model/bert/encoder/layer_1/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"+&Adam/gradients/AddN_59:AddN"AddN"TOEgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/sub/Neg:Neg"Neg"`	[	Qgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul/Sum_1:Sum"Sum"PKAgradient_tape/model/bert/encoder/layer_3/attention/self/mul_1:Mul"Mul"TOAmodel/bert/encoder/layer_0/attention/output/dense/BiasAdd:BiasAdd"BiasAdd"hcVgradient_tape/model/bert/encoder/layer_3/intermediate/Tensordot/MatMul/MatMul_1:MatMul"MatMul"`[Qgradient_tape/model/bert/encoder/layer_8/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/moments/mul_1:Mul"Mul"@;1model/bert/encoder/layer_7/intermediate/mul_2:Mul"Mul"% EagerLocalExecute: Identity"b]Sgradient_tape/model/bert/encoder/layer_7/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"TO?model/bert/encoder/layer_9/attention/self/transpose_2:Transpose"	Transpose"JE7model/bert/encoder/layer_1/output/dense/BiasAdd:BiasAdd"BiasAdd"b	]	Sgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul_2/Mul_1:Mul"Mul"XSHmodel/bert/encoder/layer_6/attention/output/dropout_20/dropout/Cast:Cast"Cast"oj]gradient_tape/model/bert/encoder/layer_10/attention/self/key/Tensordot/MatMul/MatMul_1:MatMul"MatMul"eaMmodel/bert/encoder/layer_6/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"WRHgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul/Mul_1:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_7/intermediate/mul_3/Mul:Mul"Mul"rm`gradient_tape/model/bert/encoder/layer_0/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"WREmodel/bert/encoder/layer_6/attention/self/key/Tensordot/MatMul:MatMul"MatMul"e`Ugradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/moments/Tile:Tile"Tile"hcYgradient_tape/model/bert/encoder/layer_9/attention/output/LayerNorm/moments/truediv_1:Mul"Mul"UP8Adam/Adam/update_109/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"[VGgradient_tape/model/bert/encoder/layer_7/intermediate/TanhGrad:TanhGrad"TanhGrad"LG=model/bert/encoder/layer_10/output/dropout_33/dropout/Mul:Mul"Mul"P
K
=model/bert/encoder/layer_3/attention/self/key/BiasAdd:BiasAdd"BiasAdd"mh[gradient_tape/model/bert/encoder/layer_11/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"[VKmodel/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance:Mean"Mean"ojWmodel/bert/encoder/layer_0/attention/output/dropout_2/dropout/GreaterEqual:GreaterEqual"GreaterEqual"E@6model/bert/encoder/layer_11/output/LayerNorm/mul_2:Mul"Mul"p
k
Vmodel/bert/encoder/layer_11/attention/self/key/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"TOEgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/sub/Sum:Sum"Sum"ParallelMapProduce"S!O!8Adam/Adam/update_176/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"@;1model/bert/encoder/layer_1/intermediate/mul_2:Mul"Mul"faLmodel/bert/encoder/layer_11/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"83)model/bert/encoder/layer_9/output/Add:Add"Add"TOEgradient_tape/model/bert/encoder/layer_3/intermediate/mul_3/Mul_1:Mul"Mul"qlXgradient_tape/model/bert/encoder/layer_10/attention/self/MatMul_1/MatMul_1:BatchMatMulV2"BatchMatMulV2"QL>model/bert/encoder/layer_11/attention/self/key/BiasAdd:BiasAdd"BiasAdd"[VKgradient_tape/model/bert/encoder/layer_8/output/LayerNorm/moments/Tile:Tile"Tile"NI?gradient_tape/model/bert/encoder/layer_0/attention/self/Sum:Sum"Sum"e`Kmodel/bert/encoder/layer_3/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"VTRTIgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/moments/sub:Sub"Sub"B=1model/bert/encoder/layer_0/intermediate/add:AddV2"AddV2"hcXgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"niVmodel/bert/encoder/layer_7/attention/self/dropout_22/dropout/GreaterEqual:GreaterEqual"GreaterEqual"P
K
=model/bert/encoder/layer_5/attention/self/key/BiasAdd:BiasAdd"BiasAdd"TO7Adam/Adam/update_28/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPFgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/mul/Sum:Sum"Sum"FA5model/bert/encoder/layer_7/output/LayerNorm/add:AddV2"AddV2"c^Tgradient_tape/model/bert/encoder/layer_6/attention/output/dropout_20/dropout/Mul:Mul"Mul"PK?model/bert/encoder/layer_0/attention/output/LayerNorm/add:AddV2"AddV2"+&Adam/gradients/AddN_70:AddN"AddN"T
O
?model/bert/encoder/layer_1/attention/self/transpose_2:Transpose"	Transpose"TO7Adam/Adam/update_26/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"faJgradient_tape/model/lambda/strided_slice/StridedSliceGrad:StridedSliceGrad"StridedSliceGrad"PK?model/bert/encoder/layer_7/attention/output/LayerNorm/add:AddV2"AddV2"c^Imodel/bert/encoder/layer_4/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"^YOgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/moments/truediv_1:Mul"Mul"ParallelMapConsume"YT?model/bert/embeddings/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp">9/model/bert/encoder/layer_9/intermediate/Pow:Mul"Mul"[	V	Kgradient_tape/model/bert/encoder/layer_3/output/LayerNorm/moments/Tile:Tile"Tile"jvfvUgradient_tape/model/bert/encoder/layer_4/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"\WHgradient_tape/model/bert/encoder/layer_10/intermediate/TanhGrad:TanhGrad"TanhGrad"niUgradient_tape/model/bert/encoder/layer_3/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"[VLgradient_tape/model/bert/encoder/layer_7/output/dropout_24/dropout/Mul_2:Mul"Mul"T	O	7Adam/Adam/update_32/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"mhUmodel/bert/encoder/layer_1/attention/self/dropout_4/dropout/GreaterEqual:GreaterEqual"GreaterEqual"B=3model/bert/encoder/layer_5/output/LayerNorm/mul:Mul"Mul"l	g	Ugradient_tape/model/bert/encoder/layer_3/intermediate/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"to]gradient_tape/model/bert/encoder/layer_0/attention/self/query/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"gbOmodel/bert/encoder/layer_10/output/dropout_33/dropout/GreaterEqual:GreaterEqual"GreaterEqual"niUgradient_tape/model/bert/encoder/layer_2/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"UP8Adam/Adam/update_164/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"WRGmodel/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean:Mean"Mean"{gmodel/bert/encoder/layer_5/attention/self/dropout_16/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"RMAmodel/bert/encoder/layer_5/attention/output/LayerNorm/add_1:AddV2"AddV2"ni\gradient_tape/model/bert/encoder/layer_5/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"c^Tgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/mul_1/Mul_1:Mul"Mul"`	[	Qgradient_tape/model/bert/encoder/layer_1/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"qlWmodel/bert/encoder/layer_7/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"c^Imodel/bert/encoder/layer_2/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"pk^gradient_tape/model/bert/encoder/layer_8/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_181/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"gcOmodel/bert/encoder/layer_6/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"A<2model/bert/encoder/layer_11/intermediate/mul_3:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_9/intermediate/mul_2/Mul:Mul"Mul">9/model/bert/encoder/layer_9/intermediate/mul:Mul"Mul"faTgradient_tape/model/bert/encoder/layer_3/intermediate/Tensordot/MatMul/MatMul:MatMul"MatMul"NI?gradient_tape/model/bert/encoder/layer_3/attention/self/sub:Sub"Sub"R
M
?model/bert/encoder/layer_0/attention/self/value/BiasAdd:BiasAdd"BiasAdd"_ZPgradient_tape/model/bert/encoder/layer_11/attention/output/LayerNorm/sub/Sum:Sum"Sum"faTgradient_tape/model/bert/encoder/layer_4/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"lgUgradient_tape/model/bert/encoder/layer_9/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_14/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"Mul:Mul"Mul"TOEgradient_tape/model/bert/encoder/layer_1/output/LayerNorm/mul/Mul:Mul"Mul"q	l	Wmodel/bert/encoder/layer_7/attention/self/value/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"e`Mmodel/bert/encoder/layer_1/output/dropout_6/dropout/GreaterEqual:GreaterEqual"GreaterEqual"ojUmodel/bert/encoder/layer_6/attention/self/query/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"pk^gradient_tape/model/bert/encoder/layer_2/attention/self/query/Tensordot/MatMul/MatMul_1:MatMul"MatMul"UP8Adam/Adam/update_188/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"D?5model/bert/encoder/layer_5/output/LayerNorm/mul_2:Mul"Mul"a2]2Tgradient_tape/model/bert/encoder/layer_8/attention/output/dropout_26/dropout/Mul:Mul"Mul"~yamodel/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference:SquaredDifference"SquaredDifference"TO7Adam/Adam/update_83/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"VQGgradient_tape/model/bert/encoder/layer_7/output/LayerNorm/mul_2/Sum:Sum"Sum"NI?model/bert/encoder/layer_8/attention/output/LayerNorm/mul_2:Mul"Mul"`[Qgradient_tape/model/bert/encoder/layer_2/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"LG=model/bert/encoder/layer_9/attention/output/LayerNorm/mul:Mul"Mul"N
I
?model/bert/encoder/layer_2/attention/output/LayerNorm/mul_1:Mul"Mul"^YOgradient_tape/model/bert/encoder/layer_4/attention/output/LayerNorm/mul/Sum:Sum"Sum"WRHmodel/bert/encoder/layer_6/attention/output/dropout_20/dropout/Mul_1:Mul"Mul"1,WriteSummary:WriteSummary"WriteSummary"to]gradient_tape/model/bert/encoder/layer_3/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"TO7Adam/Adam/update_88/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"xs_model/bert/encoder/layer_9/output/dropout_30/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"LG=model/bert/encoder/layer_6/attention/output/LayerNorm/sub:Sub"Sub"faTgradient_tape/model/bert/encoder/layer_0/output/dense/Tensordot/MatMul/MatMul:MatMul"MatMul"D?5model/bert/encoder/layer_6/attention/self/truediv:Mul"Mul"UP8Adam/Adam/update_152/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"R
M
=model/bert/encoder/layer_4/attention/self/transpose:Transpose"	Transpose"VQFmodel/bert/encoder/layer_4/attention/self/dropout_13/dropout/Cast:Cast"Cast"B=3model/bert/encoder/layer_5/output/LayerNorm/sub:Sub"Sub"idOmodel/bert/encoder/layer_4/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_106/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"C>4model/bert/encoder/layer_10/output/LayerNorm/sub:Sub"Sub"gbMmodel/bert/encoder/layer_5/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"PKAgradient_tape/model/bert/encoder/layer_3/intermediate/Pow/mul:Mul"Mul"h	c	Vgradient_tape/model/bert/encoder/layer_2/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"lgZgradient_tape/model/bert/encoder/layer_9/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"\CXCOgradient_tape/model/bert/encoder/layer_6/output/LayerNorm/moments/truediv_1:Mul"Mul"SN6Adam/Adam/update_7/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_14:AddN"AddN"ni\gradient_tape/model/bert/encoder/layer_3/attention/self/value/Tensordot/MatMul/MatMul:MatMul"MatMul"^YOgradient_tape/model/bert/encoder/layer_6/attention/output/LayerNorm/mul/Sum:Sum"Sum"VQGgradient_tape/model/bert/encoder/layer_5/output/LayerNorm/mul/Sum_1:Sum"Sum"lgUgradient_tape/model/bert/encoder/layer_1/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"HC7model/bert/encoder/layer_1/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"94*model/bert/encoder/layer_11/output/Add:Add"Add"\WMgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/truediv:Mul"Mul"Q
L
?model/bert/encoder/layer_4/output/dense/Tensordot/MatMul:MatMul"MatMul"D?5sparse_categorical_crossentropy/weighted_loss/Sum:Sum"Sum"UP8Adam/Adam/update_134/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"qlWmodel/bert/encoder/layer_4/attention/self/query/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"\WLgradient_tape/model/bert/encoder/layer_10/output/LayerNorm/moments/Tile:Tile"Tile"+&Adam/gradients/AddN_24:AddN"AddN"pmlm`gradient_tape/model/bert/encoder/layer_5/attention/output/dense/Tensordot/MatMul/MatMul_1:MatMul"MatMul"VQDgradient_tape/model/bert/encoder/layer_5/intermediate/Pow/Pow:Square"Square"ID8model/bert/encoder/layer_11/output/LayerNorm/Rsqrt:Rsqrt"Rsqrt"LG=model/bert/encoder/layer_1/attention/output/LayerNorm/sub:Sub"Sub"VQGgradient_tape/model/bert/encoder/layer_0/output/LayerNorm/mul/Sum_1:Sum"Sum"lgZgradient_tape/model/bert/encoder/layer_5/attention/self/key/Tensordot/MatMul/MatMul:MatMul"MatMul"YTJgradient_tape/model/bert/encoder/layer_7/output/dropout_24/dropout/Mul:Mul"Mul"KF1model/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"T	O	7Adam/Adam/update_37/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"+&Adam/gradients/AddN_63:AddN"AddN"RM?model/bert/encoder/layer_3/attention/self/query/BiasAdd:BiasAdd"BiasAdd"lgWgradient_tape/model/bert/encoder/layer_3/attention/self/transpose_3/transpose:Transpose"	Transpose"T	O	7Adam/Adam/update_64/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"to]gradient_tape/model/bert/encoder/layer_1/attention/self/value/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"[VImodel/bert/encoder/layer_6/attention/output/dense/Tensordot/MatMul:MatMul"MatMul"yt`model/bert/encoder/layer_10/output/dropout_33/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform".)model/dropout_1/dropout/Mul:Mul"Mul"D?5model/bert/encoder/layer_9/output/LayerNorm/mul_2:Mul"Mul"B=3model/bert/encoder/layer_1/output/LayerNorm/mul:Mul"Mul"p	k	^gradient_tape/model/bert/encoder/layer_2/attention/self/value/Tensordot/MatMul/MatMul_1:MatMul"MatMul"e`Kmodel/bert/encoder/layer_1/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp"TOEgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/mul/Sum:Sum"Sum"miUmodel/bert/encoder/layer_7/attention/self/value/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"idOmodel/bert/encoder/layer_9/output/dense/Tensordot/ReadVariableOp:ReadVariableOp"ReadVariableOp"hcNmodel/bert/encoder/layer_10/output/dense/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"ZUKgradient_tape/model/bert/encoder/layer_10/output/dropout_33/dropout/Mul:Mul"Mul"[VBmodel/dropout_1/dropout/random_uniform/RandomUniform:RandomUniform"RandomUniform"gbMmodel/bert/encoder/layer_2/intermediate/BiasAdd/ReadVariableOp:ReadVariableOp"ReadVariableOp"HC7model/bert/encoder/layer_2/output/LayerNorm/add_1:AddV2"AddV2"NI?gradient_tape/model/bert/encoder/layer_1/attention/self/mul:Mul"Mul"niUgradient_tape/model/bert/encoder/layer_9/attention/self/MatMul/MatMul_1:BatchMatMulV2"BatchMatMulV2"WRHgradient_tape/model/bert/encoder/layer_11/output/LayerNorm/mul/Sum_1:Sum"Sum"lgUgradient_tape/model/bert/encoder/layer_0/output/dense/BiasAdd/BiasAddGrad:BiasAddGrad"BiasAddGrad"U
P
Fmodel/bert/encoder/layer_4/attention/self/dropout_13/dropout/Mul_1:Mul"Mul"UP8Adam/Adam/update_163/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"UPFmodel/bert/encoder/layer_3/attention/self/dropout_10/dropout/Mul_1:Mul"Mul":5"model/dense_1/BiasAdd:_FusedMatMul"_FusedMatMul"mhSmodel/bert/encoder/layer_1/attention/output/LayerNorm/ReadVariableOp:ReadVariableOp"ReadVariableOp"A
<
1model/bert/embeddings/LayerNorm/moments/mean:Mean"Mean"TO7Adam/Adam/update_41/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"a\Rgradient_tape/model/bert/encoder/layer_10/attention/output/LayerNorm/mul/Mul_1:Mul"Mul"KF<model/bert/encoder/layer_3/output/dropout_12/dropout/Mul:Mul"Mul"S)O)8Adam/Adam/update_151/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"QLAmodel/bert/encoder/layer_1/output/LayerNorm/moments/variance:Mean"Mean"gbWgradient_tape/model/bert/encoder/layer_0/attention/output/LayerNorm/moments/Tile_1:Tile"Tile"`[Qgradient_tape/model/bert/encoder/layer_3/attention/output/LayerNorm/mul_1/Mul:Mul"Mul"]XMgradient_tape/model/bert/encoder/layer_9/output/LayerNorm/moments/Tile_1:Tile"Tile"B=(div_no_nan/ReadVariableOp:ReadVariableOp"ReadVariableOp"UP8Adam/Adam/update_141/ResourceApplyAdam:ResourceApplyAdam"ResourceApplyAdam"e`Kmodel/bert/encoder/layer_4/output/LayerNorm/ReadVariableOp_1:ReadVariableOp"ReadVariableOp")\%\Adam/gradients/AddN_45:AddN"AddN"LG=model/bert/encoder/layer_0/output/dropout_3/dropout/Mul_1:Mul"Mul"d_Ugradient_tape/model/bert/encoder/layer_11/attention/output/dropout_35/dropout/Mul:Mul"Mul"RMCgradient_tape/model/bert/encoder/layer_4/intermediate/mul_3/Mul:Mul"Mul"RM=model/bert/encoder/layer_1/attention/self/transpose:Transpose"	Transpose"Y
T
Gmodel/bert/encoder/layer_8/attention/self/query/Tensordot/MatMul:MatMul"MatMul*
element_id*
_c*autotune*	parent_id*
id*_ct*iter_num*tf_function_call*
_p*tracing_count*notTraced-nonXla*		deterministic*true*_pt*

parallelism*	step_name*group_id*selected_group_ids*is_eager"DESKTOP-Q9TBK68